{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OCy7k6P7XHM6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wfdb\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import pywt\n",
    "import pywt.data\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image,ImageEnhance\n",
    "from scipy import fftpack\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.signal as signal\n",
    "from wfdb import processing\n",
    "from itertools import combinations\n",
    "import ast\n",
    "import wfdb\n",
    "#from scipy.signal.filter_design import zpk2sos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aRfRcqshbMD"
   },
   "source": [
    "Extract Lead v1 from the 12-Leads ECG Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 먼저 모든 데이터 한 파일에 몰아넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_LeadV1_Numpy():\n",
    "\n",
    "    for myloop in range(1, 21839, 1):\n",
    "        five_digit_value = '%05d' % myloop\n",
    "        signals, fields = wfdb.rdsamp(\"/home/ines/code/ptb-xl/data/\" + five_digit_value + \"_lr\", channels=[6],sampto=1000)\n",
    "\n",
    "        signals = signals.tolist()\n",
    "        # print(signals)\n",
    "\n",
    "        newest = [i[0] for i in signals]\n",
    "        X = [i for i in newest if i != 0.0]\n",
    "        X = np.array(X)\n",
    "        np.save(\"/home/ines/code/ptb-xl/Dest/\" + five_digit_value + '.npy', X)  # save\n",
    "\n",
    "Get_LeadV1_Numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JOf5q0jhhwz"
   },
   "source": [
    "Numpy Files distruction to classes (with the help of CSV file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w47WOafzhrir"
   },
   "source": [
    "Denoising Numpy Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "bapCIOR_e3uE"
   },
   "outputs": [],
   "source": [
    "def Numpy_Denoise():\n",
    "\n",
    "    # 신호의 평균 절대 편차를 계산\n",
    "    def madev(d, axis=None):\n",
    "        \"\"\" Mean absolute deviation of a signal \"\"\"\n",
    "        return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "    # 웨이블릿 변환을 사용하여 신호에서 노이즈를 제거하는 함수\n",
    "    # 쌍직교 함수\n",
    "    # 레벨1로 웨이블릿 변환\n",
    "    def wavelet_denoising(x, wavelet='bior3.1', level=1):\n",
    "        # coeff: 웨이블릿 변환을 통해 계산된 근사 계수와 세부 계수를 저장하는 변수\n",
    "        coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "        # 세부 계수의 평균 절대 편차를 계산하여 노이즈의 크기를 추정하는 데 사용\n",
    "        sigma = (1 / 0.6745) * madev(coeff[-level])\n",
    "        # uthresh: 임계값으로, 노이즈의 크기를 기반으로 계산\n",
    "        uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n",
    "        coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "        # Multilevel reconstruction using waverec\n",
    "        # wavelet: Wavelet object or name string\n",
    "        return pywt.waverec(coeff, wavelet, mode='per')\n",
    "\n",
    "    # 20446\n",
    "    src_dir = \"/home/ines/code/ptb-xl/source/\"\n",
    "    dest_dir = \"/home/ines/code/ptb-xl/dest/\"\n",
    "\n",
    "    # 반복문을 통해 모든 .npy 파일에 대해 노이즈 제거를 수행합니다. 각 파일을 웨이블릿 변환을 통해 필터링하고 새로운 파일로 저장\n",
    "    for file in glob.iglob(src_dir + '**/*.npy', recursive=True):\n",
    "        existing_file_name = Path(file).stem\n",
    "        new_file_name = existing_file_name[:5]\n",
    "\n",
    "        signal = np.load(file)\n",
    "\n",
    "        # wavelist=['bior1.3','bior2.8','bior3.1','bior3.9','db2','db8','rbio1.5','sym6','sym8']\n",
    "        wavelist = ['bior3.1']\n",
    "\n",
    "\n",
    "        for wav in wavelist:\n",
    "            filtered = wavelet_denoising(signal, wavelet=wav, level=1)\n",
    "            np.save(dest_dir+new_file_name+'.npy', filtered) # save\n",
    "\n",
    "Numpy_Denoise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBoajuT8huEP"
   },
   "source": [
    "Frequency Filtration to reduce data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Freq_Filteration():\n",
    "    #### https://scipy-lectures.org/intro/scipy/auto_examples/plot_fftpack.html\n",
    "\n",
    "    src_dir = \"/home/ines/code/ptb-xl/source_denoise/\"\n",
    "    dest_dir = \"/home/ines/code/ptb-xl/source_filter/\"\n",
    "\n",
    "    for file in glob.iglob(src_dir + '**/*.npy', recursive=True):\n",
    "\n",
    "        #Extracting File Name\n",
    "        existing_file_name = Path(file).stem\n",
    "        new_file_name = existing_file_name[:7]\n",
    "\n",
    "        #Load the file\n",
    "        x = np.load(file)  # 17876_lr\n",
    "\n",
    "        # The FFT of the signal\n",
    "        sig_fft = fftpack.fft(x)\n",
    "\n",
    "        # The corresponding frequencies\n",
    "        sample_freq = fftpack.fftfreq(x.size, d=0.02)\n",
    "\n",
    "        #The original signal copy\n",
    "        high_freq_fft = sig_fft.copy()\n",
    "        high_freq_fft = np.delete(high_freq_fft, np.where(np.abs(sample_freq > 2)))\n",
    "\n",
    "        #Taking Inverse of FFT\n",
    "        filtered_sig = fftpack.ifft(high_freq_fft)\n",
    "        print(len(filtered_sig))\n",
    "\n",
    "        #Saving resultant filtered signal into npy\n",
    "        np.save(dest_dir+new_file_name+\".npy\", filtered_sig)\n",
    "    \n",
    "Freq_Filteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIDoHSG5hzGP"
   },
   "source": [
    "Spectrograms Using STFT (Scipy Library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한 번에 돌리기엔 너무 많아서 따로 파일 두고 8000개 씩 돌림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "roQ_Uvm2Xcva"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130760/2464692961.py:17: UserWarning: Input data is complex, switching to return_onesided=False\n",
      "  f, t, Zxx = signal.stft(x, nfft=9, nperseg=9, noverlap=5, window='hann') #NFFT calculate by N base Log 2 with x=len(x)\n",
      "/tmp/ipykernel_130760/2464692961.py:21: UserWarning: The input coordinates to pcolormesh are interpreted as cell centers, but are not monotonically increasing or decreasing. This may lead to incorrectly calculated cell edges, in which case, please supply explicit cell edges to pcolormesh.\n",
      "  plt.pcolormesh(t, f, np.abs(Zxx), cmap=\"gray_r\")\n"
     ]
    }
   ],
   "source": [
    "def Draw_Spectrogram():\n",
    "    \n",
    "    src_dir = \"/home/ines/code/ptb-xl/source_filter/3000/\"\n",
    "    dest_dir = \"/home/ines/code/ptb-xl/source_spec/\"\n",
    "\n",
    "\n",
    "    for file in glob.iglob(src_dir + '**/*.npy', recursive=True):\n",
    "        # Extracting File Name\n",
    "        existing_file_name = Path(file).stem\n",
    "        new_file_name = existing_file_name[:7]   \n",
    "\n",
    "        #Loading file\n",
    "        x = np.load(file)   \n",
    "        print(len(x))\n",
    "\n",
    "        #applying STFT transformation\n",
    "        f, t, Zxx = signal.stft(x, nfft=9, nperseg=9, noverlap=5, window='hann') #NFFT calculate by N base Log 2 with x=len(x) \n",
    "        plt.figure(figsize=(1.15, 1.19))   \n",
    "\n",
    "        #plotting spectrogram\n",
    "        plt.pcolormesh(t, f, np.abs(Zxx), cmap=\"gray_r\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(dest_dir+ new_file_name + '.png',bbox_inches='tight',pad_inches=0)\n",
    "        plt.close('all')\n",
    "\n",
    "Draw_Spectrogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9THOfaY3h6BL"
   },
   "source": [
    "Raw Signal Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figsize 수정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "DYwIbFowXjKp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ines/anaconda3/envs/jyp/lib/python3.9/site-packages/matplotlib/cbook.py:1699: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return math.isfinite(val)\n",
      "/home/ines/anaconda3/envs/jyp/lib/python3.9/site-packages/matplotlib/cbook.py:1345: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.asarray(x, float)\n"
     ]
    }
   ],
   "source": [
    "# fig size 수정 필요\n",
    "\n",
    "def DrawGraphs():\n",
    "\n",
    "    src_dir = \"/home/ines/code/ptb-xl/source_filter/3000/\"\n",
    "    dest_dir = \"/home/ines/code/ptb-xl/source_gr\"\n",
    "\n",
    "    for file in glob.iglob(src_dir + '**/*.npy', recursive=True):\n",
    "        # Extracting File Name\n",
    "        existing_file_name = Path(file).stem\n",
    "        new_file_name = existing_file_name[:7]  \n",
    "\n",
    "        # Loading file\n",
    "        x = np.load(file)   \n",
    "        print(len(x))\n",
    "\n",
    "        plt.figure(figsize=(10, 10))   \n",
    "        plt.plot(x, 'gray')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # saving plots\n",
    "        plt.savefig(dest_dir + new_file_name + '.jpeg')\n",
    "        plt.close('all')\n",
    "\n",
    "        \n",
    "DrawGraphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2TH7Vhwh-cT"
   },
   "source": [
    "Two Data Augmentation Approaches on Spectrogram / Raw Signal Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어그맨테이션 데이터 아직 train, test set에 추가 안됨\n",
    "\n",
    "마지막 코드 보고 파일 명 00001_hFlip.png와 database.csv파일의 df_db['diagnostic_superclass']에 맞춰 파일 이동하면 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HorizontalFlip():\n",
    "    src_dir = \"/home/ines/code/ptb-xl/source_spec/\"\n",
    "    dest_dir = \"/home/ines/code/ptb-xl/source_flip/\"\n",
    "\n",
    "    for file in glob.iglob(src_dir + '**/*.png', recursive=True):\n",
    "        # Extracting File Name\n",
    "        existing_file_name = Path(file).stem\n",
    "        new_file_name = existing_file_name[:5]\n",
    "        print(file)\n",
    "        #opening Image and convert into 2-D\n",
    "        img = Image.open(file)\n",
    "        img = np.array(img)\n",
    "\n",
    "        # Flipping images with Numpy\n",
    "        flipped_img = np.fliplr(img)\n",
    "\n",
    "        img=Image.fromarray(flipped_img)\n",
    "        img.save(dest_dir+new_file_name+\"_hFlip\"+\".png\")\n",
    "        plt.close('all')\n",
    "\n",
    "def SetContrast():\n",
    "    src_dir = \"/home/ines/code/ptb-xl/source_spec/\"\n",
    "    dest_dir = \"/home/ines/code/ptb-xl/source_const/\"\n",
    "\n",
    "    for file in glob.iglob(src_dir + '**/*.png', recursive=True):\n",
    "        # Extracting File Name\n",
    "        existing_file_name = Path(file).stem\n",
    "        new_file_name = existing_file_name[:5]\n",
    "\n",
    "        # read the image\n",
    "        im = Image.open(file)\n",
    "\n",
    "        # image brightness enhancer\n",
    "        enhancer = ImageEnhance.Contrast(im)\n",
    "\n",
    "        factor = 1.7  # increase contrast\n",
    "        im_output = enhancer.enhance(factor)\n",
    "        im_output.save(dest_dir + new_file_name + \"_Contrast\" + \".png\")\n",
    "\n",
    "\n",
    "HorizontalFlip()\n",
    "SetContrast()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_test, X_train 파일 생성 후 라벨 파일(자동 생성)에 학습, 테스트 용 데이터 분류함\n",
    "\n",
    "- 문제점: label이 여럿으로 뜸\n",
    "\n",
    "ex) ['HYP', 'CD', 'MI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def distribute_images():\n",
    "    test_fold = 10\n",
    "    y_train = {}\n",
    "    y_test = {}\n",
    "    \n",
    "    # 데이터베이스(csv 파일) 로드\n",
    "    df_db = pd.read_csv('/home/ines/code/ptb-xl/ptbxl_database.csv', index_col='ecg_id')\n",
    "    df_db.scp_codes = df_db.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "    df_st = pd.read_csv('/home/ines/code/ptb-xl/scp_statements.csv', index_col=0)\n",
    "    df_st = df_st[df_st.diagnostic == 1]\n",
    "\n",
    "    def aggregate_diagnostic(y_dic):\n",
    "        tmp = []\n",
    "        for key in y_dic.keys():\n",
    "            if key in df_st.index:\n",
    "                tmp.append(df_st.loc[key].diagnostic_class)\n",
    "        return list(set(tmp))\n",
    "    \n",
    "    # Apply diagnostic superclass\n",
    "    df_db['diagnostic_superclass'] = df_db.scp_codes.apply(aggregate_diagnostic)\n",
    "    \n",
    "\n",
    "    # 이미지 파일(png) 및 레이블 식별 및 훈련/테스트 세트로 분배\n",
    "    for i in range(len(df_db)):\n",
    "        five_digit_value = '%05d' % i\n",
    "        filee_name = df_db.iloc[i][0]\n",
    "        five_digit_value = '%05d' % int(filee_name)\n",
    "        file_name = five_digit_value + \".png\"  # 이미지 파일 이름\n",
    "        class_name = df_db.iloc[i].diagnostic_superclass          # 레이블(class) 이름\n",
    "\n",
    "        source_dir = \"/home/ines/code/ptb-xl/source_spec/\" + file_name\n",
    "\n",
    "        train_dir = '/home/ines/code/ptb-xl/X_train/' + str(class_name) + '/'\n",
    "        test_dir = '/home/ines/code/ptb-xl/X_test/' + str(class_name) + '/'\n",
    "\n",
    "        \n",
    "        if df_db.iloc[i].strat_fold != 10:\n",
    "            if not os.path.exists(train_dir):\n",
    "                os.makedirs(train_dir)\n",
    "            \n",
    "            # 이미지 파일 이동 (파일이 이미 존재하지 않는 경우에만 이동)\n",
    "            destination_path = os.path.join(train_dir, file_name)\n",
    "            if not os.path.exists(source_dir):\n",
    "                print(f\"Warning: {source_dir} does not exist.\")\n",
    "            elif not os.path.exists(destination_path):\n",
    "                shutil.move(source_dir, destination_path)\n",
    "                y_train[five_digit_value] = df_db.iloc[i].diagnostic_superclass\n",
    "            else:\n",
    "                print(f\"Warning: {destination_path} already exists.\")\n",
    "            \n",
    "        else:\n",
    "            if not os.path.exists(test_dir):\n",
    "                os.makedirs(test_dir)\n",
    "            \n",
    "            # 이미지 파일 이동 (파일이 이미 존재하지 않는 경우에만 이동)\n",
    "            destination_path = os.path.join(test_dir, file_name)\n",
    "            if not os.path.exists(source_dir):\n",
    "                print(f\"Warning: {source_dir} does not exist.\")\n",
    "            elif not os.path.exists(destination_path):\n",
    "                shutil.move(source_dir, destination_path)\n",
    "                y_test[five_digit_value] = df_db.iloc[i].diagnostic_superclass\n",
    "            else:\n",
    "                print(f\"Warning: {destination_path} already exists.\")\n",
    "\n",
    "    return y_train, y_test\n",
    "            \n",
    "\n",
    "# 이미지 분배 함수 호출\n",
    "y_train, y_test = distribute_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: 16017\n",
      "y_test: 1814\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"y_train:\", len(y_train))\n",
    "print(\"y_test:\", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "test_fold = 10\n",
    "\n",
    "def distribute_images():\n",
    "    # 데이터베이스(csv 파일) 로드\n",
    "    df_db = pd.read_csv('/home/ines/code/ptb-xl/ptbxl_database.csv', index_col='ecg_id')\n",
    "    df_db.scp_codes = df_db.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "    df_st = pd.read_csv('/home/ines/code/ptb-xl/scp_statements.csv', index_col=0)\n",
    "    df_st = df_st[df_st.diagnostic == 1]\n",
    "\n",
    "    def aggregate_diagnostic(y_dic):\n",
    "        tmp = []\n",
    "        for key in y_dic.keys():\n",
    "            if key in df_st.index:\n",
    "                tmp.append(df_st.loc[key].diagnostic_class)\n",
    "        return list(set(tmp))\n",
    "    \n",
    "    # Apply diagnostic superclass\n",
    "    df_db['diagnostic_superclass'] = df_db.scp_codes.apply(aggregate_diagnostic)\n",
    "    print(df_db.strat_fold)\n",
    "    \n",
    "\n",
    "    # 이미지 파일(png) 및 레이블 식별 및 훈련/테스트 세트로 분배\n",
    "    for i in range(0, 21383, 1):\n",
    "        filee_name = df_db.iloc[i][0]\n",
    "        print(filee_name)\n",
    "        five_digit_value = '%05d' % int(filee_name)\n",
    "        file_name = five_digit_value + \".png\"  # 이미지 파일 이름\n",
    "        class_name = df_db.iloc[i].diagnostic_superclass          # 레이블(class) 이름\n",
    "\n",
    "        source_dir = \"/home/ines/code/ptb-xl/source_spec/\" + file_name\n",
    "        search_dir = '/home/ines/code/ptb-xl/dest/' + str(class_name) + '/'\n",
    "        dest_dir = search_dir\n",
    "\n",
    "        train_dir = '/home/ines/code/ptb-xl/X_train/' + str(class_name) + '/'\n",
    "        test_dir = '/home/ines/code/ptb-xl/X_test/' + str(class_name) + '/'\n",
    "\n",
    "        if df_db.iloc[i].strat_fold != 10:\n",
    "            if not os.path.exists(X_train):\n",
    "                os.makedirs(X_train)\n",
    "            \n",
    "            # 이미지 파일 이동\n",
    "            shutil.move(source_dir, X_train)\n",
    "            y_train = df_st[(df_st.strat_fold != test_fold)].diagnostic_superclass\n",
    "            \n",
    "        else:\n",
    "            if not os.path.exists(X_test):\n",
    "                os.makedirs(X_test)\n",
    "            \n",
    "            # 이미지 파일 이동\n",
    "            shutil.move(source_dir, X_test)\n",
    "            y_test = df_st[df_st.strat_fold == test_fold].diagnostic_superclass\n",
    "            \n",
    "        X_train = df_db[np.where(df_st.strat_fold != test_fold)]\n",
    "        y_train = df_st[(df_st.strat_fold != test_fold)].diagnostic_superclass\n",
    "        X_test = df_db[np.where(df_st.strat_fold == test_fold)]\n",
    "        y_test = df_st[df_st.strat_fold == test_fold].diagnostic_superclass\n",
    "        # 이미지 파일이 존재하는지 확인\n",
    "        if not os.path.exists(source_dir):\n",
    "            print(source_dir + \" not found.\")\n",
    "        else:\n",
    "            # 클래스별 디렉토리 생성\n",
    "            if not os.path.exists(search_dir):\n",
    "                os.makedirs(search_dir)\n",
    "            \n",
    "            # 이미지 파일 이동\n",
    "            shutil.move(source_dir, dest_dir)\n",
    "\n",
    "# 이미지 분배 함수 호출\n",
    "distribute_images()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# py 파일 참고\n",
    "# 마지막단 함수 구현 --> 라벨링 복수형 괜찮은지?\n",
    "# train test split\n",
    "\n",
    "\n",
    "# png파일 화질"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
