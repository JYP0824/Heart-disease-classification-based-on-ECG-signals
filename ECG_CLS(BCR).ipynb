{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6bb73d1-51cc-4b65-9076-fb85d4f49bec",
   "metadata": {},
   "source": [
    "## Normal Abnormal binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba016159-1df6-4aa6-b838-80516293c3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ines/code/ISOCC/data\n"
     ]
    }
   ],
   "source": [
    "cd /home/ines/code/ISOCC/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "981caf38-8ee8-49d2-a199-5f0b31abc118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import stft\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6a8c1-de5e-480d-8378-aae37690cc4a",
   "metadata": {},
   "source": [
    "## Hyper-param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19697e47-f180-4f34-842a-5b04a4a16341",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8481ee42-cdad-4993-8037-f39d4558966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4046, 188)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10506, 188)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal_df = pd.read_csv(\"ptbdb_abnormal.csv\", header=None)\n",
    "normal_df = pd.read_csv(\"ptbdb_normal.csv\", header=None)\n",
    "\n",
    "print(normal_df.shape)\n",
    "abnormal_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad023dba-492e-49c6-ac96-fba525a2309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  1.000000  0.900324  0.358590  0.051459  0.046596  0.126823  0.133306   \n",
      "1  1.000000  0.794681  0.375387  0.116883  0.000000  0.171923  0.283859   \n",
      "2  0.909029  0.791482  0.423169  0.186712  0.000000  0.007836  0.063032   \n",
      "3  1.000000  0.478893  0.056760  0.064176  0.081289  0.072732  0.055619   \n",
      "4  1.000000  0.867238  0.201360  0.099349  0.141336  0.120934  0.108516   \n",
      "\n",
      "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
      "0  0.119125  0.110616  0.113047  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1  0.293754  0.325912  0.345083  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2  0.077002  0.074957  0.077342  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3  0.048774  0.054478  0.041643  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4  0.096393  0.093436  0.100828  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "   186  187  \n",
      "0  0.0    0  \n",
      "1  0.0    0  \n",
      "2  0.0    0  \n",
      "3  0.0    0  \n",
      "4  0.0    0  \n",
      "\n",
      "[5 rows x 188 columns]\n",
      "shape:  (14552, 188)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14552 entries, 0 to 10505\n",
      "Columns: 188 entries, 0 to 187\n",
      "dtypes: float64(187), int64(1)\n",
      "memory usage: 21.0 MB\n"
     ]
    }
   ],
   "source": [
    "ECG_df = pd.concat([normal_df, abnormal_df])\n",
    "#ECG_df.columns = ECG_df.columns.astype(\"str\")\n",
    "ECG_df[187] = ECG_df[187].astype(\"int64\")\n",
    "print(ECG_df.head())\n",
    "print(\"shape: \", ECG_df.shape)\n",
    "ECG_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9c98543-3838-43c0-9e5f-452e0b742ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14552, 187) (14552, 1)\n"
     ]
    }
   ],
   "source": [
    "label = {1: \"Normal\", 0: \"Abnormal\"}\n",
    "X = ECG_df.loc[:, :186].to_numpy()\n",
    "y = ECG_df.loc[:, 187:187].to_numpy()\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7535333-c842-422c-bf07-49980faa2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    plt.plot(range(len(X[i])), X[i])\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('ECG Data')\n",
    "\n",
    "    # 이미지 저장\n",
    "    save_dir = \"/home/ines/code/ISOCC/wav_data\"\n",
    "    plt.savefig(os.path.join(save_dir, 'ecg_plot{}.png'.format(i)))\n",
    "    plt.close()\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86dd9a44-6838-43cd-b87c-bb10afcd929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Files saved in /home/ines/code/ISOCC/stft_data/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STFT 저장\n",
    "\n",
    "fs = 250  # 샘플링 빈도\n",
    "nperseg = 4  # 세그먼트당 샘플 수\n",
    "noverlap = nperseg // 2  # 중첩 샘플 수\n",
    "nfft = 8  # FFT 포인트 수\n",
    "\n",
    "save_path = '/home/ines/code/ISOCC/stft_data/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# 각 시리즈에 대해 STFT 실행 및 결과 저장\n",
    "i = 0\n",
    "for column in X:\n",
    "    f, t, Zxx = stft(column, fs=fs, nperseg=nperseg, noverlap=noverlap, nfft=nfft)\n",
    "    np.save(os.path.join(save_path, f'ECG_STFT_{i}.npy'), Zxx)\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    i += 1\n",
    "\n",
    "# 저장된 파일의 예시 경로 확인\n",
    "f'Files saved in {save_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e25ab8ce-d2c4-46cc-8465-451e2a73c6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 95])\n"
     ]
    }
   ],
   "source": [
    "file_paths = [os.path.join(save_path, f) for f in os.listdir(save_path) if f.endswith('.npy')]\n",
    "data = [np.load(f) for f in file_paths]\n",
    "\n",
    "tensor_data = [torch.tensor(d, dtype=torch.float32) for d in data]\n",
    "print(tensor_data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73a9e9fb-dfdc-43ca-947c-97d6b1b53928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11641, 1) (2911, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tensor_data, y, train_size=0.8, random_state=42\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f9b76bc-0bc4-4d22-8cf6-08c32dec39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, datas, label_arr):\n",
    "        self.datas = datas\n",
    "        self.label_arr = label_arr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.datas[idx]\n",
    "        label = self.label_arr[idx]\n",
    "        return data, label\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb605e8e-6c88-4394-acb8-fedd81c0f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 논문에서 .npy 불러올 때 사용한 코드\n",
    "# 참고용\n",
    "'''\n",
    "class TrainSet(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        self.train_data = np.load(os.path.join(folder, 'train.npy'))\n",
    "\n",
    "    # 주어진 ECG 신호에 대해 R 피크를 검출하는 함수, HeartPy 라이브러리를 사용하여 ECG 신호를 처리하고, 작업 데이터와 측정값을 반환\n",
    "    def checkR(self, ecg):\n",
    "        working_data, measures = hp.process(ecg, 500.0)\n",
    "        peak_list = working_data['peaklist']\n",
    "        return peak_list\n",
    "    \n",
    "    # 학습 데이터의 총 개수를 반환\n",
    "    def __len__(self):\n",
    "        return self.train_data.shape[0]\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "    # 주어진 인덱스에 해당하는 학습 데이터(time_instance)를 가져옵니다.\n",
    "    # 가져온 학습 데이터에서 첫 100개와 마지막 100개의 데이터를 제거하여 4900개의 데이터 포인트를 남깁니다. 이로써 총 4800개의 데이터 포인트로 이루어진 시간축 데이터\n",
    "        time_instance = self.train_data[index]\n",
    "        time_instance = time_instance[100:4900,:] #(4800, 12)\n",
    "       \n",
    "        # Short Time Fast Fourier Transform\n",
    "        # 500 is the sample rate of PTB-XL, 360 is the sample rate of MIT-BIH\n",
    "        # 스펙트로그램 데이터의 축을 재배치하여 (63, 78, 12)의 형태로 만듭니다. 여기서 (63, 78)는 STFT 결과의 스펙트로그램 크기이고, 12는 채널의 개수\n",
    "        f,t, Zxx = stft(time_instance.transpose(1,0),fs=500, window='hann',nperseg=125)\n",
    "        spectrogram_instance = np.abs(Zxx)  #(12, 63, 78)\n",
    "        spectrogram_instance = spectrogram_instance.transpose(1,2,0)     #(63, 78, 12)\n",
    "        return time_instance, spectrogram_instance\n",
    " \n",
    " \n",
    " \n",
    "class TestSet(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        self.test_data = np.load(os.path.join(folder, 'test.npy'))\n",
    "       \n",
    "    def __len__(self):\n",
    "        return self.test_data.shape[0]\n",
    "    \n",
    "    def checkR(self, ecg):\n",
    "        working_data, measures = hp.process(ecg, 500.0)\n",
    "        peak_list = working_data['peaklist']\n",
    "        return np.array(peak_list)\n",
    "   \n",
    "    def __getitem__(self, index):\n",
    "        time_instance = self.test_data[index]\n",
    "        r_index = self.checkR(time_instance[:,1])\n",
    "        time_instance = time_instance[100:4900,:]\n",
    "        # Short Time Fast Fourier Transform\n",
    "        f,t, Zxx = stft(time_instance.transpose(1,0),fs=500, window='hann',nperseg=125)\n",
    "        spectrogram_instance = np.abs(Zxx)  #(12, 63, 78)\n",
    "        spectrogram_instance = spectrogram_instance.transpose(1,2,0)     #(63, 78, 12)\n",
    "        return time_instance, spectrogram_instance, r_index\n",
    " '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc2837-e306-4158-8fdc-7c9e427aa2bb",
   "metadata": {},
   "source": [
    "- 입력값 = (batch_size, 5, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ef861-804f-4aee-a5da-08ef6c31e94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151dbf0b-987c-4762-bc92-401ff41335e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f686b233-96a0-46e2-b783-a92e706fc733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40aec3-d32d-4c99-9d59-f003a281751e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee20074-1a2a-4784-92b4-7d0bb368361a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366f19e-2c03-44be-a3a4-55860cec3826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c5eb0-8746-46b0-a9d8-a01fa3edf9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd3ecc0-c3d8-4ae9-81b6-e7924565e7c1",
   "metadata": {},
   "source": [
    "## BCResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ca4e026-89b4-494c-b8d5-4cfb5dda91cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023 Qualcomm Technologies, Inc.\n",
    "# All Rights Reserved.\n",
    "\n",
    "class SubSpectralNorm(nn.Module):\n",
    "    def __init__(self, num_features, spec_groups=16, affine=\"Sub\", batch=True, dim=2):\n",
    "        super().__init__()\n",
    "        self.spec_groups = spec_groups\n",
    "        self.affine_all = False\n",
    "        affine_norm = False\n",
    "        if (\n",
    "            affine == \"Sub\"\n",
    "        ):  # affine transform for each sub group. use affine of torch implementation\n",
    "            affine_norm = True\n",
    "        elif affine == \"All\":\n",
    "            self.affine_all = True\n",
    "            self.weight = nn.Parameter(torch.ones((1, num_features, 1, 1)))\n",
    "            self.bias = nn.Parameter(torch.zeros((1, num_features, 1, 1)))\n",
    "        if batch:\n",
    "            self.ssnorm = nn.BatchNorm2d(num_features * spec_groups, affine=affine_norm)\n",
    "        else:\n",
    "            self.ssnorm = nn.InstanceNorm2d(num_features * spec_groups, affine=affine_norm)\n",
    "        self.sub_dim = dim\n",
    "\n",
    "    def forward(self, x):  # when dim h is frequency dimension\n",
    "        if self.sub_dim in (3, -1):\n",
    "            x = x.transpose(2, 3)\n",
    "            x = x.contiguous()\n",
    "        b, c, h, w = x.size()\n",
    "        assert h % self.spec_groups == 0\n",
    "        x = x.view(b, c * self.spec_groups, h // self.spec_groups, w)\n",
    "        x = self.ssnorm(x)\n",
    "        x = x.view(b, c, h, w)\n",
    "        if self.affine_all:\n",
    "            x = x * self.weight + self.bias\n",
    "        if self.sub_dim in (3, -1):\n",
    "            x = x.transpose(2, 3)\n",
    "            x = x.contiguous()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b17ad808-7189-4a02-94a5-1c1b1d46293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023 Qualcomm Technologies, Inc.\n",
    "# All Rights Reserved.\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class ConvBNReLU(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_plane,\n",
    "        out_plane,\n",
    "        idx,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        groups=1,\n",
    "        use_dilation=False,\n",
    "        activation=True,\n",
    "        swish=False,\n",
    "        BN=True,\n",
    "        ssn=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        def get_padding(kernel_size, use_dilation):\n",
    "            rate = 1  # dilation rate\n",
    "            padding_len = (kernel_size - 1) // 2\n",
    "            if use_dilation and kernel_size > 1:\n",
    "                rate = int(2**self.idx)\n",
    "                padding_len = rate * padding_len\n",
    "            return padding_len, rate\n",
    "\n",
    "        self.idx = idx\n",
    "\n",
    "        # padding and dilation rate\n",
    "        if isinstance(kernel_size, (list, tuple)):\n",
    "            padding = []\n",
    "            rate = []\n",
    "            for k_size in kernel_size:\n",
    "                temp_padding, temp_rate = get_padding(k_size, use_dilation)\n",
    "                rate.append(temp_rate)\n",
    "                padding.append(temp_padding)\n",
    "        else:\n",
    "            padding, rate = get_padding(kernel_size, use_dilation)\n",
    "\n",
    "        # convbnrelu block\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            nn.Conv2d(in_plane, out_plane, kernel_size, stride, padding, rate, groups, bias=False)\n",
    "        )\n",
    "        if ssn:\n",
    "            layers.append(SubSpectralNorm(out_plane, 5))\n",
    "        elif BN:\n",
    "            layers.append(nn.BatchNorm2d(out_plane))\n",
    "        if swish:\n",
    "            layers.append(nn.SiLU(True))\n",
    "        elif activation:\n",
    "            layers.append(nn.ReLU(True))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class BCResBlock(nn.Module):\n",
    "    def __init__(self, in_plane, out_plane, idx, stride):\n",
    "        super().__init__()\n",
    "        self.transition_block = in_plane != out_plane\n",
    "        kernel_size = (3, 3)\n",
    "\n",
    "        # 2D part (f2)\n",
    "        layers = []\n",
    "        if self.transition_block:\n",
    "            layers.append(ConvBNReLU(in_plane, out_plane, idx, 1, 1))\n",
    "            in_plane = out_plane\n",
    "        layers.append(\n",
    "            ConvBNReLU(\n",
    "                in_plane,\n",
    "                out_plane,\n",
    "                idx,\n",
    "                (kernel_size[0], 1),\n",
    "                (stride[0], 1),\n",
    "                groups=in_plane,\n",
    "                ssn=True,\n",
    "                activation=False,\n",
    "            )\n",
    "        )\n",
    "        self.f2 = nn.Sequential(*layers)\n",
    "        self.avg_gpool = nn.AdaptiveAvgPool2d((1, None))\n",
    "\n",
    "        # 1D part (f1)\n",
    "        self.f1 = nn.Sequential(\n",
    "            ConvBNReLU(\n",
    "                out_plane,\n",
    "                out_plane,\n",
    "                idx,\n",
    "                (1, kernel_size[1]),\n",
    "                (1, stride[1]),\n",
    "                groups=out_plane,\n",
    "                swish=True,\n",
    "                use_dilation=True,\n",
    "            ),\n",
    "            nn.Conv2d(out_plane, out_plane, 1, bias=False),\n",
    "            nn.Dropout2d(0.1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 2D part\n",
    "        shortcut = x\n",
    "        x = self.f2(x)\n",
    "        aux_2d_res = x\n",
    "        x = self.avg_gpool(x)\n",
    "\n",
    "        # 1D part\n",
    "        x = self.f1(x)\n",
    "        x = x + aux_2d_res\n",
    "        if not self.transition_block:\n",
    "            x = x + shortcut\n",
    "        x = F.relu(x, True)\n",
    "        return x\n",
    "\n",
    "\n",
    "def BCBlockStage(num_layers, last_channel, cur_channel, idx, use_stride):\n",
    "    stage = nn.ModuleList()\n",
    "    channels = [last_channel] + [cur_channel] * num_layers\n",
    "    for i in range(num_layers):\n",
    "        stride = (2, 1) if use_stride and i == 0 else (1, 1)\n",
    "        stage.append(BCResBlock(channels[i], channels[i + 1], idx, stride))\n",
    "    return stage\n",
    "\n",
    "\n",
    "class BCResNets(nn.Module):\n",
    "    def __init__(self, base_c, num_classes=12):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.n = [2, 2, 4, 4]  # identical modules repeated n times\n",
    "        self.c = [\n",
    "            base_c * 2,\n",
    "            base_c,\n",
    "            int(base_c * 1.5),\n",
    "            base_c * 2,\n",
    "            int(base_c * 2.5),\n",
    "            base_c * 4,\n",
    "        ]  # num channels\n",
    "        self.s = [1, 2]  # stage using stride\n",
    "        self._build_network()\n",
    "\n",
    "    def _build_network(self):\n",
    "        # Head: (Conv-BN-ReLU)\n",
    "        self.cnn_head = nn.Sequential(\n",
    "            nn.Conv2d(1, self.c[0], 5, (2, 1), 2, bias=False),\n",
    "            nn.BatchNorm2d(self.c[0]),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Body: BC-ResBlocks\n",
    "        self.BCBlocks = nn.ModuleList([])\n",
    "        for idx, n in enumerate(self.n):\n",
    "            use_stride = idx in self.s\n",
    "            self.BCBlocks.append(BCBlockStage(n, self.c[idx], self.c[idx + 1], idx, use_stride))\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                self.c[-2], self.c[-2], (5, 5), bias=False, groups=self.c[-2], padding=(0, 2)\n",
    "            ),\n",
    "            nn.Conv2d(self.c[-2], self.c[-1], 1, bias=False),\n",
    "            nn.BatchNorm2d(self.c[-1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Conv2d(self.c[-1], self.num_classes, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_head(x)\n",
    "        for i, num_modules in enumerate(self.n):\n",
    "            for j in range(num_modules):\n",
    "                x = self.BCBlocks[i][j](x)\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(-1, x.shape[1])\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "jyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
