{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e88OLey6Bgd"
   },
   "source": [
    "# **Image Classification with Convolutional Neural Networks (CNNs)**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsTzc3oi726u"
   },
   "source": [
    "# **Building a Convolutional Neural Network with Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT2H7gBmACML"
   },
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "OCglDGFy8AhT",
    "outputId": "ebd8e8a1-250e-44d5-bd08-8a165139a39a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n",
    "import psutil\n",
    "import GPUtil\n",
    "\n",
    "import os,sys,humanize,psutil,GPUtil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import imageio\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwMflxlbAsfK"
   },
   "source": [
    "**Memory Utilization Checkup (Before/After Model Execution)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2bPbY1LEG_0",
    "outputId": "fb5e5f78-f535-4f74-915e-bf25d7e1b7fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in /home/ines/anaconda3/envs/jyp/lib/python3.9/site-packages (5.9.0)\n",
      "Requirement already satisfied: GPUtil in /home/ines/anaconda3/envs/jyp/lib/python3.9/site-packages (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "#CPU AND GPU LIBRARIES INSTALLATION (if you find error on import of psutil and GPUtil, please refer below)\n",
    "!pip install psutil\n",
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rnT_bgIWERmI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sys' has no attribute 'ram'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# CHECKING THE CPU AND GPU MEMORY\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Testing the psutil library for both CPU and RAM performance details\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(psutil\u001b[38;5;241m.\u001b[39mcpu_percent())\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpsutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mram\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(psutil\u001b[38;5;241m.\u001b[39mvirtual_memory()\u001b[38;5;241m.\u001b[39mpercent)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Testing the GPUtil library for both GPU performance details\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sys' has no attribute 'ram'"
     ]
    }
   ],
   "source": [
    "# CHECKING THE CPU AND GPU MEMORY\n",
    "\n",
    "# Testing the psutil library for both CPU and RAM performance details\n",
    "print(psutil.cpu_percent())\n",
    "print(psutil.sys.ram)\n",
    "print(psutil.virtual_memory().percent)\n",
    "# Testing the GPUtil library for both GPU performance details\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rwrm76EmJ2Fv",
    "outputId": "2c6abe31-7da2-49b3-f888-d0bfc63f886b"
   },
   "outputs": [],
   "source": [
    "#CPU MEMORY UTILIZATION\n",
    "\n",
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pgr9seSLdYf",
    "outputId": "098c34a9-beff-4d3a-b2ec-11c412c15673"
   },
   "outputs": [],
   "source": [
    "!grep MemTotal /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLQu663TLjBQ",
    "outputId": "1b2b200d-94fb-4838-f688-96d2f5acc765"
   },
   "outputs": [],
   "source": [
    "#GPU MEMORY UTILIZATION \n",
    "!nvidia-smi --query-gpu=memory.total --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fd_O6FIRJGtv",
    "outputId": "8ee3632f-aee1-4634-f181-48bab157cc53"
   },
   "outputs": [],
   "source": [
    "# Function\n",
    "def mem_report():\n",
    "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
    "  \n",
    "  GPUs = GPUtil.getGPUs()\n",
    "  for i, gpu in enumerate(GPUs):\n",
    "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
    "\n",
    "mem_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOyPVde22QGD"
   },
   "source": [
    "## **Let's Start with Model Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf7eW3HC9XVL"
   },
   "source": [
    "**Data Acquisition and ImageDataGenerator**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-0BfyGlJbx0l"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255) #Normalize the pixel values\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Hsimgs7aqt6G"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join('/home/ines/code/ptb-xl/X_train/')\n",
    "validation_dir = os.path.join('/home/ines/code/ptb-xl/X_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyvlF41oqxEP",
    "outputId": "4cfabfb0-9a59-492d-9e3e-287714f55f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23847 images belonging to 2 classes.\n",
      "Found 2198 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(64,64),\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(64,64),\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3yhwpN_-BaS"
   },
   "source": [
    "**Building the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FSzxq4KDtKN6"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "                                    \n",
    "    # First convolution layer \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(64, 64, 3),use_bias=True),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    # Second convolution layer \n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',use_bias=True),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "\n",
    "    # Third convolution layer \n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',use_bias=True),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    # Fourth convolution layer  \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',use_bias=True),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    # Flatten the pooled feature maps\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # Fully connected hidden layer\n",
    "    tf.keras.layers.Dense(8, activation='relu',use_bias=True),\n",
    "\n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid',activity_regularizer=regularizers.L1(0.001))   \n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QF4_GItOBHKI"
   },
   "source": [
    "**Printing Model Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HU0RFGLtNJb",
    "outputId": "08c30a3c-9036-4547-f6ec-6ffdd88b7e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          147520    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 520,401\n",
      "Trainable params: 520,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVYZ8VwKBQRC"
   },
   "source": [
    "**Optimizer Implementation and model training/validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RBN3GBMItPMH"
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import SensitivityAtSpecificity,SpecificityAtSensitivity,Recall,Precision\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy',SensitivityAtSpecificity(0.5),SpecificityAtSensitivity(0.5),Recall(0.5),Precision(0.5)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2Q0MPMwh3EgY"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_accuracy')>0.99): \n",
    "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f6gDG3dx9sJ",
    "outputId": "a394d933-66c2-4bb8-ab07-4fce74eb1682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 16:37:16.406861: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-04-08 16:37:16.428569: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3499910000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.6633 - accuracy: 0.6926 - sensitivity_at_specificity_1: 0.4602 - specificity_at_sensitivity_1: 0.4626 - recall_1: 0.9183 - precision_1: 0.7318 - val_loss: 0.4720 - val_accuracy: 0.8914 - val_sensitivity_at_specificity_1: 0.2971 - val_specificity_at_sensitivity_1: 0.2590 - val_recall_1: 1.0000 - val_precision_1: 0.8914\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89141, saving model to ECG_Spectrogram_Model.h5\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5805 - accuracy: 0.7389 - sensitivity_at_specificity_1: 0.5190 - specificity_at_sensitivity_1: 0.5188 - recall_1: 1.0000 - precision_1: 0.7389 - val_loss: 0.5288 - val_accuracy: 0.9039 - val_sensitivity_at_specificity_1: 0.3984 - val_specificity_at_sensitivity_1: 0.1220 - val_recall_1: 1.0000 - val_precision_1: 0.9039\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.89141 to 0.90391, saving model to ECG_Spectrogram_Model.h5\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5834 - accuracy: 0.7324 - sensitivity_at_specificity_1: 0.4910 - specificity_at_sensitivity_1: 0.5007 - recall_1: 1.0000 - precision_1: 0.7324 - val_loss: 0.4905 - val_accuracy: 0.8898 - val_sensitivity_at_specificity_1: 0.0088 - val_specificity_at_sensitivity_1: 0.3972 - val_recall_1: 1.0000 - val_precision_1: 0.8898\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.90391\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5794 - accuracy: 0.7359 - sensitivity_at_specificity_1: 0.5120 - specificity_at_sensitivity_1: 0.5189 - recall_1: 1.0000 - precision_1: 0.7359 - val_loss: 0.5172 - val_accuracy: 0.8977 - val_sensitivity_at_specificity_1: 0.0122 - val_specificity_at_sensitivity_1: 0.1527 - val_recall_1: 1.0000 - val_precision_1: 0.8977\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.90391\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5803 - accuracy: 0.7387 - sensitivity_at_specificity_1: 0.4944 - specificity_at_sensitivity_1: 0.4915 - recall_1: 1.0000 - precision_1: 0.7387 - val_loss: 0.5549 - val_accuracy: 0.8961 - val_sensitivity_at_specificity_1: 0.0000e+00 - val_specificity_at_sensitivity_1: 0.4211 - val_recall_1: 1.0000 - val_precision_1: 0.8961\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.90391\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5816 - accuracy: 0.7390 - sensitivity_at_specificity_1: 0.4826 - specificity_at_sensitivity_1: 0.4858 - recall_1: 1.0000 - precision_1: 0.7390 - val_loss: 0.5196 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_1: 0.0472 - val_specificity_at_sensitivity_1: 0.3824 - val_recall_1: 1.0000 - val_precision_1: 0.8938\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.90391\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5705 - accuracy: 0.7444 - sensitivity_at_specificity_1: 0.4817 - specificity_at_sensitivity_1: 0.4811 - recall_1: 1.0000 - precision_1: 0.7444 - val_loss: 0.5493 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_1: 0.4800 - val_specificity_at_sensitivity_1: 0.3984 - val_recall_1: 1.0000 - val_precision_1: 0.9000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.90391\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5838 - accuracy: 0.7311 - sensitivity_at_specificity_1: 0.5319 - specificity_at_sensitivity_1: 0.5279 - recall_1: 1.0000 - precision_1: 0.7311 - val_loss: 0.5282 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.4770 - val_specificity_at_sensitivity_1: 0.4934 - val_recall_1: 1.0000 - val_precision_1: 0.8813\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.90391\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5605 - accuracy: 0.7462 - sensitivity_at_specificity_1: 0.5621 - specificity_at_sensitivity_1: 0.5722 - recall_1: 1.0000 - precision_1: 0.7462 - val_loss: 0.4604 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.5840 - val_specificity_at_sensitivity_1: 0.5874 - val_recall_1: 1.0000 - val_precision_1: 0.8883\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.90391\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5715 - accuracy: 0.7274 - sensitivity_at_specificity_1: 0.6580 - specificity_at_sensitivity_1: 0.6315 - recall_1: 1.0000 - precision_1: 0.7274 - val_loss: 0.5707 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.5740 - val_specificity_at_sensitivity_1: 0.5894 - val_recall_1: 1.0000 - val_precision_1: 0.8820\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.90391\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5778 - accuracy: 0.7190 - sensitivity_at_specificity_1: 0.6656 - specificity_at_sensitivity_1: 0.5985 - recall_1: 1.0000 - precision_1: 0.7185 - val_loss: 0.4510 - val_accuracy: 0.8969 - val_sensitivity_at_specificity_1: 0.4625 - val_specificity_at_sensitivity_1: 0.4773 - val_recall_1: 1.0000 - val_precision_1: 0.8969\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.90391\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5328 - accuracy: 0.7579 - sensitivity_at_specificity_1: 0.7433 - specificity_at_sensitivity_1: 0.6733 - recall_1: 0.9939 - precision_1: 0.7529 - val_loss: 0.4350 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.5277 - val_specificity_at_sensitivity_1: 0.5385 - val_recall_1: 0.9868 - val_precision_1: 0.8891\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.90391\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.5237 - accuracy: 0.7762 - sensitivity_at_specificity_1: 0.7517 - specificity_at_sensitivity_1: 0.6716 - recall_1: 0.9841 - precision_1: 0.7677 - val_loss: 0.5222 - val_accuracy: 0.8000 - val_sensitivity_at_specificity_1: 0.5838 - val_specificity_at_sensitivity_1: 0.5672 - val_recall_1: 0.8665 - val_precision_1: 0.9060\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.90391\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4901 - accuracy: 0.7831 - sensitivity_at_specificity_1: 0.8663 - specificity_at_sensitivity_1: 0.7640 - recall_1: 0.9653 - precision_1: 0.7807 - val_loss: 0.4620 - val_accuracy: 0.8672 - val_sensitivity_at_specificity_1: 0.5655 - val_specificity_at_sensitivity_1: 0.5669 - val_recall_1: 0.9549 - val_precision_1: 0.9032\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.90391\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4773 - accuracy: 0.8039 - sensitivity_at_specificity_1: 0.7916 - specificity_at_sensitivity_1: 0.7209 - recall_1: 0.9794 - precision_1: 0.7996 - val_loss: 0.4204 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.5326 - val_specificity_at_sensitivity_1: 0.5137 - val_recall_1: 0.9938 - val_precision_1: 0.8867\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.90391\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4766 - accuracy: 0.8040 - sensitivity_at_specificity_1: 0.8211 - specificity_at_sensitivity_1: 0.7574 - recall_1: 0.9651 - precision_1: 0.8100 - val_loss: 0.4576 - val_accuracy: 0.8383 - val_sensitivity_at_specificity_1: 0.6074 - val_specificity_at_sensitivity_1: 0.6259 - val_recall_1: 0.9238 - val_precision_1: 0.8978\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.90391\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4411 - accuracy: 0.8161 - sensitivity_at_specificity_1: 0.9063 - specificity_at_sensitivity_1: 0.7967 - recall_1: 0.9759 - precision_1: 0.8116 - val_loss: 0.4572 - val_accuracy: 0.8422 - val_sensitivity_at_specificity_1: 0.6311 - val_specificity_at_sensitivity_1: 0.6176 - val_recall_1: 0.9274 - val_precision_1: 0.8992\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.90391\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4604 - accuracy: 0.8120 - sensitivity_at_specificity_1: 0.8839 - specificity_at_sensitivity_1: 0.7875 - recall_1: 0.9711 - precision_1: 0.8081 - val_loss: 0.4585 - val_accuracy: 0.8273 - val_sensitivity_at_specificity_1: 0.6353 - val_specificity_at_sensitivity_1: 0.6831 - val_recall_1: 0.9095 - val_precision_1: 0.8977\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.90391\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4387 - accuracy: 0.8152 - sensitivity_at_specificity_1: 0.9096 - specificity_at_sensitivity_1: 0.8242 - recall_1: 0.9611 - precision_1: 0.8179 - val_loss: 0.4287 - val_accuracy: 0.8578 - val_sensitivity_at_specificity_1: 0.6400 - val_specificity_at_sensitivity_1: 0.6525 - val_recall_1: 0.9552 - val_precision_1: 0.8925\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.90391\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4394 - accuracy: 0.8192 - sensitivity_at_specificity_1: 0.9049 - specificity_at_sensitivity_1: 0.8329 - recall_1: 0.9725 - precision_1: 0.8120 - val_loss: 0.3787 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.6359 - val_specificity_at_sensitivity_1: 0.6154 - val_recall_1: 0.9815 - val_precision_1: 0.8914\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.90391\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4096 - accuracy: 0.8312 - sensitivity_at_specificity_1: 0.9451 - specificity_at_sensitivity_1: 0.8568 - recall_1: 0.9765 - precision_1: 0.8277 - val_loss: 0.3726 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.6469 - val_specificity_at_sensitivity_1: 0.6324 - val_recall_1: 0.9790 - val_precision_1: 0.8960\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.90391\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4401 - accuracy: 0.8103 - sensitivity_at_specificity_1: 0.9029 - specificity_at_sensitivity_1: 0.8636 - recall_1: 0.9692 - precision_1: 0.8078 - val_loss: 0.4141 - val_accuracy: 0.8570 - val_sensitivity_at_specificity_1: 0.6508 - val_specificity_at_sensitivity_1: 0.6573 - val_recall_1: 0.9543 - val_precision_1: 0.8923\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.90391\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4213 - accuracy: 0.8260 - sensitivity_at_specificity_1: 0.9432 - specificity_at_sensitivity_1: 0.8439 - recall_1: 0.9608 - precision_1: 0.8285 - val_loss: 0.3657 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.6216 - val_specificity_at_sensitivity_1: 0.6454 - val_recall_1: 0.9877 - val_precision_1: 0.8921\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.90391\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4291 - accuracy: 0.8194 - sensitivity_at_specificity_1: 0.9176 - specificity_at_sensitivity_1: 0.8689 - recall_1: 0.9619 - precision_1: 0.8210 - val_loss: 0.4322 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_1: 0.7036 - val_specificity_at_sensitivity_1: 0.6984 - val_recall_1: 0.9168 - val_precision_1: 0.9105\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.90391\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4238 - accuracy: 0.8223 - sensitivity_at_specificity_1: 0.9418 - specificity_at_sensitivity_1: 0.8522 - recall_1: 0.9715 - precision_1: 0.8191 - val_loss: 0.4216 - val_accuracy: 0.8477 - val_sensitivity_at_specificity_1: 0.6888 - val_specificity_at_sensitivity_1: 0.7068 - val_recall_1: 0.9285 - val_precision_1: 0.9041\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.90391\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4159 - accuracy: 0.8272 - sensitivity_at_specificity_1: 0.9384 - specificity_at_sensitivity_1: 0.8533 - recall_1: 0.9650 - precision_1: 0.8282 - val_loss: 0.4171 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_1: 0.7138 - val_specificity_at_sensitivity_1: 0.7402 - val_recall_1: 0.9219 - val_precision_1: 0.9062\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.90391\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4195 - accuracy: 0.8195 - sensitivity_at_specificity_1: 0.9413 - specificity_at_sensitivity_1: 0.8576 - recall_1: 0.9514 - precision_1: 0.8254 - val_loss: 0.3739 - val_accuracy: 0.8758 - val_sensitivity_at_specificity_1: 0.6812 - val_specificity_at_sensitivity_1: 0.7037 - val_recall_1: 0.9721 - val_precision_1: 0.8976\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.90391\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4189 - accuracy: 0.8209 - sensitivity_at_specificity_1: 0.9446 - specificity_at_sensitivity_1: 0.8564 - recall_1: 0.9725 - precision_1: 0.8159 - val_loss: 0.3509 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.6649 - val_specificity_at_sensitivity_1: 0.7429 - val_recall_1: 0.9886 - val_precision_1: 0.8937\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.90391\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4049 - accuracy: 0.8282 - sensitivity_at_specificity_1: 0.9411 - specificity_at_sensitivity_1: 0.8758 - recall_1: 0.9789 - precision_1: 0.8229 - val_loss: 0.4041 - val_accuracy: 0.8453 - val_sensitivity_at_specificity_1: 0.6876 - val_specificity_at_sensitivity_1: 0.7075 - val_recall_1: 0.9426 - val_precision_1: 0.8893\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.90391\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4234 - accuracy: 0.8192 - sensitivity_at_specificity_1: 0.9052 - specificity_at_sensitivity_1: 0.8682 - recall_1: 0.9682 - precision_1: 0.8178 - val_loss: 0.3926 - val_accuracy: 0.8695 - val_sensitivity_at_specificity_1: 0.6976 - val_specificity_at_sensitivity_1: 0.7315 - val_recall_1: 0.9761 - val_precision_1: 0.8875\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.90391\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4164 - accuracy: 0.8307 - sensitivity_at_specificity_1: 0.9332 - specificity_at_sensitivity_1: 0.8592 - recall_1: 0.9720 - precision_1: 0.8263 - val_loss: 0.3737 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.7031 - val_specificity_at_sensitivity_1: 0.7031 - val_recall_1: 0.9670 - val_precision_1: 0.9013\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90391\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4488 - accuracy: 0.8057 - sensitivity_at_specificity_1: 0.9107 - specificity_at_sensitivity_1: 0.8318 - recall_1: 0.9557 - precision_1: 0.8130 - val_loss: 0.4974 - val_accuracy: 0.8258 - val_sensitivity_at_specificity_1: 0.6516 - val_specificity_at_sensitivity_1: 0.6970 - val_recall_1: 0.8972 - val_precision_1: 0.9075\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.90391\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4180 - accuracy: 0.8303 - sensitivity_at_specificity_1: 0.9188 - specificity_at_sensitivity_1: 0.8462 - recall_1: 0.9762 - precision_1: 0.8273 - val_loss: 0.3593 - val_accuracy: 0.8906 - val_sensitivity_at_specificity_1: 0.7559 - val_specificity_at_sensitivity_1: 0.7444 - val_recall_1: 0.9878 - val_precision_1: 0.8999\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.90391\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4236 - accuracy: 0.8209 - sensitivity_at_specificity_1: 0.9388 - specificity_at_sensitivity_1: 0.8715 - recall_1: 0.9841 - precision_1: 0.8086 - val_loss: 0.3619 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.7511 - val_specificity_at_sensitivity_1: 0.7622 - val_recall_1: 0.9771 - val_precision_1: 0.8917\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.90391\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3966 - accuracy: 0.8402 - sensitivity_at_specificity_1: 0.9469 - specificity_at_sensitivity_1: 0.8649 - recall_1: 0.9676 - precision_1: 0.8422 - val_loss: 0.5229 - val_accuracy: 0.8070 - val_sensitivity_at_specificity_1: 0.7073 - val_specificity_at_sensitivity_1: 0.7050 - val_recall_1: 0.8720 - val_precision_1: 0.9078\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.90391\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4466 - accuracy: 0.8047 - sensitivity_at_specificity_1: 0.9061 - specificity_at_sensitivity_1: 0.8526 - recall_1: 0.9724 - precision_1: 0.8001 - val_loss: 0.4542 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_1: 0.6800 - val_specificity_at_sensitivity_1: 0.6769 - val_recall_1: 0.9400 - val_precision_1: 0.9038\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.90391\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4073 - accuracy: 0.8342 - sensitivity_at_specificity_1: 0.9456 - specificity_at_sensitivity_1: 0.8571 - recall_1: 0.9804 - precision_1: 0.8275 - val_loss: 0.3341 - val_accuracy: 0.8969 - val_sensitivity_at_specificity_1: 0.7357 - val_specificity_at_sensitivity_1: 0.6825 - val_recall_1: 0.9887 - val_precision_1: 0.9056\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.90391\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4055 - accuracy: 0.8322 - sensitivity_at_specificity_1: 0.9565 - specificity_at_sensitivity_1: 0.8739 - recall_1: 0.9736 - precision_1: 0.8266 - val_loss: 0.3725 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.7195 - val_specificity_at_sensitivity_1: 0.7122 - val_recall_1: 0.9737 - val_precision_1: 0.8967\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.90391\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3978 - accuracy: 0.8302 - sensitivity_at_specificity_1: 0.9536 - specificity_at_sensitivity_1: 0.8943 - recall_1: 0.9692 - precision_1: 0.8280 - val_loss: 0.4482 - val_accuracy: 0.8422 - val_sensitivity_at_specificity_1: 0.7083 - val_specificity_at_sensitivity_1: 0.7465 - val_recall_1: 0.9236 - val_precision_1: 0.9014\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.90391\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4005 - accuracy: 0.8386 - sensitivity_at_specificity_1: 0.9578 - specificity_at_sensitivity_1: 0.8693 - recall_1: 0.9672 - precision_1: 0.8397 - val_loss: 0.3681 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.6996 - val_specificity_at_sensitivity_1: 0.7310 - val_recall_1: 0.9762 - val_precision_1: 0.8921\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.90391\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4010 - accuracy: 0.8406 - sensitivity_at_specificity_1: 0.9636 - specificity_at_sensitivity_1: 0.8530 - recall_1: 0.9722 - precision_1: 0.8368 - val_loss: 0.4246 - val_accuracy: 0.8445 - val_sensitivity_at_specificity_1: 0.7282 - val_specificity_at_sensitivity_1: 0.7413 - val_recall_1: 0.9340 - val_precision_1: 0.8954\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.90391\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3939 - accuracy: 0.8424 - sensitivity_at_specificity_1: 0.9461 - specificity_at_sensitivity_1: 0.8703 - recall_1: 0.9809 - precision_1: 0.8356 - val_loss: 0.3399 - val_accuracy: 0.8914 - val_sensitivity_at_specificity_1: 0.6582 - val_specificity_at_sensitivity_1: 0.6691 - val_recall_1: 0.9965 - val_precision_1: 0.8941\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.90391\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4075 - accuracy: 0.8313 - sensitivity_at_specificity_1: 0.9508 - specificity_at_sensitivity_1: 0.8646 - recall_1: 0.9817 - precision_1: 0.8226 - val_loss: 0.4464 - val_accuracy: 0.8375 - val_sensitivity_at_specificity_1: 0.7433 - val_specificity_at_sensitivity_1: 0.7561 - val_recall_1: 0.8989 - val_precision_1: 0.9195\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.90391\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3982 - accuracy: 0.8403 - sensitivity_at_specificity_1: 0.9354 - specificity_at_sensitivity_1: 0.8530 - recall_1: 0.9591 - precision_1: 0.8494 - val_loss: 0.3629 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.7314 - val_specificity_at_sensitivity_1: 0.7566 - val_recall_1: 0.9876 - val_precision_1: 0.8827\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.90391\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3808 - accuracy: 0.8482 - sensitivity_at_specificity_1: 0.9667 - specificity_at_sensitivity_1: 0.8869 - recall_1: 0.9823 - precision_1: 0.8408 - val_loss: 0.3647 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.7041 - val_specificity_at_sensitivity_1: 0.7376 - val_recall_1: 0.9842 - val_precision_1: 0.8925\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.90391\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3582 - accuracy: 0.8655 - sensitivity_at_specificity_1: 0.9875 - specificity_at_sensitivity_1: 0.8802 - recall_1: 0.9778 - precision_1: 0.8599 - val_loss: 0.3300 - val_accuracy: 0.8969 - val_sensitivity_at_specificity_1: 0.6785 - val_specificity_at_sensitivity_1: 0.7236 - val_recall_1: 0.9896 - val_precision_1: 0.9051\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.90391\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.4102 - accuracy: 0.8307 - sensitivity_at_specificity_1: 0.9547 - specificity_at_sensitivity_1: 0.8711 - recall_1: 0.9775 - precision_1: 0.8235 - val_loss: 0.4463 - val_accuracy: 0.8203 - val_sensitivity_at_specificity_1: 0.6780 - val_specificity_at_sensitivity_1: 0.6940 - val_recall_1: 0.8979 - val_precision_1: 0.9011\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.90391\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3944 - accuracy: 0.8322 - sensitivity_at_specificity_1: 0.9545 - specificity_at_sensitivity_1: 0.8730 - recall_1: 0.9616 - precision_1: 0.8347 - val_loss: 0.3770 - val_accuracy: 0.8656 - val_sensitivity_at_specificity_1: 0.7107 - val_specificity_at_sensitivity_1: 0.7574 - val_recall_1: 0.9572 - val_precision_1: 0.8990\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.90391\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3836 - accuracy: 0.8469 - sensitivity_at_specificity_1: 0.9790 - specificity_at_sensitivity_1: 0.8736 - recall_1: 0.9688 - precision_1: 0.8430 - val_loss: 0.3348 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.7153 - val_specificity_at_sensitivity_1: 0.7630 - val_recall_1: 0.9886 - val_precision_1: 0.8963\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.90391\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3913 - accuracy: 0.8435 - sensitivity_at_specificity_1: 0.9627 - specificity_at_sensitivity_1: 0.8592 - recall_1: 0.9842 - precision_1: 0.8335 - val_loss: 0.3911 - val_accuracy: 0.8680 - val_sensitivity_at_specificity_1: 0.7049 - val_specificity_at_sensitivity_1: 0.7297 - val_recall_1: 0.9726 - val_precision_1: 0.8886\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.90391\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3596 - accuracy: 0.8555 - sensitivity_at_specificity_1: 0.9761 - specificity_at_sensitivity_1: 0.9181 - recall_1: 0.9664 - precision_1: 0.8559 - val_loss: 0.4085 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_1: 0.7080 - val_specificity_at_sensitivity_1: 0.7353 - val_recall_1: 0.9388 - val_precision_1: 0.8980\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.90391\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3961 - accuracy: 0.8392 - sensitivity_at_specificity_1: 0.9587 - specificity_at_sensitivity_1: 0.8647 - recall_1: 0.9731 - precision_1: 0.8345 - val_loss: 0.3754 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.7249 - val_specificity_at_sensitivity_1: 0.7823 - val_recall_1: 0.9740 - val_precision_1: 0.9066\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.90391\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3967 - accuracy: 0.8363 - sensitivity_at_specificity_1: 0.9681 - specificity_at_sensitivity_1: 0.8776 - recall_1: 0.9660 - precision_1: 0.8334 - val_loss: 0.3542 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.7741 - val_specificity_at_sensitivity_1: 0.7752 - val_recall_1: 0.9800 - val_precision_1: 0.9010\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.90391\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4156 - accuracy: 0.8251 - sensitivity_at_specificity_1: 0.9583 - specificity_at_sensitivity_1: 0.8566 - recall_1: 0.9678 - precision_1: 0.8217 - val_loss: 0.3854 - val_accuracy: 0.8602 - val_sensitivity_at_specificity_1: 0.7227 - val_specificity_at_sensitivity_1: 0.7302 - val_recall_1: 0.9333 - val_precision_1: 0.9135\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.90391\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3826 - accuracy: 0.8485 - sensitivity_at_specificity_1: 0.9807 - specificity_at_sensitivity_1: 0.8843 - recall_1: 0.9728 - precision_1: 0.8423 - val_loss: 0.4571 - val_accuracy: 0.8016 - val_sensitivity_at_specificity_1: 0.7358 - val_specificity_at_sensitivity_1: 0.7737 - val_recall_1: 0.8670 - val_precision_1: 0.9067\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.90391\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3667 - accuracy: 0.8546 - sensitivity_at_specificity_1: 0.9869 - specificity_at_sensitivity_1: 0.9032 - recall_1: 0.9697 - precision_1: 0.8508 - val_loss: 0.5477 - val_accuracy: 0.7430 - val_sensitivity_at_specificity_1: 0.6992 - val_specificity_at_sensitivity_1: 0.7273 - val_recall_1: 0.8004 - val_precision_1: 0.8992\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.90391\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3939 - accuracy: 0.8372 - sensitivity_at_specificity_1: 0.9678 - specificity_at_sensitivity_1: 0.8867 - recall_1: 0.9507 - precision_1: 0.8472 - val_loss: 0.3603 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.7049 - val_specificity_at_sensitivity_1: 0.6777 - val_recall_1: 0.9758 - val_precision_1: 0.9048\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.90391\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3672 - accuracy: 0.8543 - sensitivity_at_specificity_1: 0.9726 - specificity_at_sensitivity_1: 0.8855 - recall_1: 0.9824 - precision_1: 0.8464 - val_loss: 0.3593 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.7348 - val_specificity_at_sensitivity_1: 0.7231 - val_recall_1: 0.9765 - val_precision_1: 0.9049\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.90391\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3620 - accuracy: 0.8631 - sensitivity_at_specificity_1: 0.9657 - specificity_at_sensitivity_1: 0.8844 - recall_1: 0.9792 - precision_1: 0.8593 - val_loss: 0.4758 - val_accuracy: 0.7898 - val_sensitivity_at_specificity_1: 0.6888 - val_specificity_at_sensitivity_1: 0.7315 - val_recall_1: 0.8630 - val_precision_1: 0.8954\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.90391\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3825 - accuracy: 0.8427 - sensitivity_at_specificity_1: 0.9730 - specificity_at_sensitivity_1: 0.8829 - recall_1: 0.9603 - precision_1: 0.8463 - val_loss: 0.3172 - val_accuracy: 0.8992 - val_sensitivity_at_specificity_1: 0.7491 - val_specificity_at_sensitivity_1: 0.7727 - val_recall_1: 0.9991 - val_precision_1: 0.8996\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.90391\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3741 - accuracy: 0.8535 - sensitivity_at_specificity_1: 0.9824 - specificity_at_sensitivity_1: 0.8885 - recall_1: 0.9840 - precision_1: 0.8419 - val_loss: 0.3702 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.7281 - val_specificity_at_sensitivity_1: 0.7574 - val_recall_1: 0.9720 - val_precision_1: 0.8946\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.90391\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3464 - accuracy: 0.8660 - sensitivity_at_specificity_1: 0.9875 - specificity_at_sensitivity_1: 0.8907 - recall_1: 0.9685 - precision_1: 0.8665 - val_loss: 0.3798 - val_accuracy: 0.8703 - val_sensitivity_at_specificity_1: 0.7039 - val_specificity_at_sensitivity_1: 0.7630 - val_recall_1: 0.9651 - val_precision_1: 0.8976\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.90391\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3562 - accuracy: 0.8508 - sensitivity_at_specificity_1: 0.9839 - specificity_at_sensitivity_1: 0.9292 - recall_1: 0.9756 - precision_1: 0.8436 - val_loss: 0.3858 - val_accuracy: 0.8672 - val_sensitivity_at_specificity_1: 0.7283 - val_specificity_at_sensitivity_1: 0.7533 - val_recall_1: 0.9779 - val_precision_1: 0.8840\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.90391\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3465 - accuracy: 0.8674 - sensitivity_at_specificity_1: 0.9873 - specificity_at_sensitivity_1: 0.9013 - recall_1: 0.9762 - precision_1: 0.8628 - val_loss: 0.3656 - val_accuracy: 0.8648 - val_sensitivity_at_specificity_1: 0.7454 - val_specificity_at_sensitivity_1: 0.7660 - val_recall_1: 0.9640 - val_precision_1: 0.8927\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.90391\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3383 - accuracy: 0.8733 - sensitivity_at_specificity_1: 0.9898 - specificity_at_sensitivity_1: 0.9113 - recall_1: 0.9854 - precision_1: 0.8659 - val_loss: 0.3506 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.7419 - val_specificity_at_sensitivity_1: 0.7895 - val_recall_1: 0.9773 - val_precision_1: 0.8982\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.90391\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3536 - accuracy: 0.8557 - sensitivity_at_specificity_1: 0.9932 - specificity_at_sensitivity_1: 0.9164 - recall_1: 0.9641 - precision_1: 0.8544 - val_loss: 0.3260 - val_accuracy: 0.8898 - val_sensitivity_at_specificity_1: 0.7674 - val_specificity_at_sensitivity_1: 0.8182 - val_recall_1: 0.9861 - val_precision_1: 0.9006\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.90391\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3724 - accuracy: 0.8539 - sensitivity_at_specificity_1: 0.9853 - specificity_at_sensitivity_1: 0.8844 - recall_1: 0.9765 - precision_1: 0.8450 - val_loss: 0.4339 - val_accuracy: 0.8531 - val_sensitivity_at_specificity_1: 0.7114 - val_specificity_at_sensitivity_1: 0.7519 - val_recall_1: 0.9372 - val_precision_1: 0.9026\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.90391\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3793 - accuracy: 0.8466 - sensitivity_at_specificity_1: 0.9788 - specificity_at_sensitivity_1: 0.8967 - recall_1: 0.9666 - precision_1: 0.8443 - val_loss: 0.3304 - val_accuracy: 0.8898 - val_sensitivity_at_specificity_1: 0.7031 - val_specificity_at_sensitivity_1: 0.7926 - val_recall_1: 0.9930 - val_precision_1: 0.8953\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.90391\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3707 - accuracy: 0.8547 - sensitivity_at_specificity_1: 0.9615 - specificity_at_sensitivity_1: 0.8665 - recall_1: 0.9872 - precision_1: 0.8461 - val_loss: 0.4235 - val_accuracy: 0.8273 - val_sensitivity_at_specificity_1: 0.7305 - val_specificity_at_sensitivity_1: 0.7566 - val_recall_1: 0.9176 - val_precision_1: 0.8899\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.90391\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3689 - accuracy: 0.8503 - sensitivity_at_specificity_1: 0.9708 - specificity_at_sensitivity_1: 0.9040 - recall_1: 0.9640 - precision_1: 0.8524 - val_loss: 0.3778 - val_accuracy: 0.8695 - val_sensitivity_at_specificity_1: 0.7266 - val_specificity_at_sensitivity_1: 0.7842 - val_recall_1: 0.9676 - val_precision_1: 0.8947\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.90391\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3701 - accuracy: 0.8533 - sensitivity_at_specificity_1: 0.9730 - specificity_at_sensitivity_1: 0.8557 - recall_1: 0.9762 - precision_1: 0.8516 - val_loss: 0.3353 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.7459 - val_specificity_at_sensitivity_1: 0.8074 - val_recall_1: 0.9913 - val_precision_1: 0.8944\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.90391\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3420 - accuracy: 0.8663 - sensitivity_at_specificity_1: 0.9897 - specificity_at_sensitivity_1: 0.9236 - recall_1: 0.9846 - precision_1: 0.8551 - val_loss: 0.3869 - val_accuracy: 0.8516 - val_sensitivity_at_specificity_1: 0.7506 - val_specificity_at_sensitivity_1: 0.8080 - val_recall_1: 0.9264 - val_precision_1: 0.9106\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.90391\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3679 - accuracy: 0.8517 - sensitivity_at_specificity_1: 0.9898 - specificity_at_sensitivity_1: 0.8990 - recall_1: 0.9635 - precision_1: 0.8512 - val_loss: 0.3432 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.7792 - val_specificity_at_sensitivity_1: 0.7972 - val_recall_1: 0.9921 - val_precision_1: 0.8896\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.90391\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3504 - accuracy: 0.8624 - sensitivity_at_specificity_1: 0.9943 - specificity_at_sensitivity_1: 0.9159 - recall_1: 0.9804 - precision_1: 0.8501 - val_loss: 0.3627 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_1: 0.7520 - val_specificity_at_sensitivity_1: 0.7926 - val_recall_1: 0.9563 - val_precision_1: 0.8968\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.90391\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3552 - accuracy: 0.8657 - sensitivity_at_specificity_1: 0.9909 - specificity_at_sensitivity_1: 0.8767 - recall_1: 0.9694 - precision_1: 0.8651 - val_loss: 0.3891 - val_accuracy: 0.8672 - val_sensitivity_at_specificity_1: 0.7729 - val_specificity_at_sensitivity_1: 0.8611 - val_recall_1: 0.9657 - val_precision_1: 0.8933\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.90391\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3445 - accuracy: 0.8675 - sensitivity_at_specificity_1: 0.9882 - specificity_at_sensitivity_1: 0.9082 - recall_1: 0.9762 - precision_1: 0.8638 - val_loss: 0.3660 - val_accuracy: 0.8719 - val_sensitivity_at_specificity_1: 0.7169 - val_specificity_at_sensitivity_1: 0.7770 - val_recall_1: 0.9720 - val_precision_1: 0.8936\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.90391\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3524 - accuracy: 0.8640 - sensitivity_at_specificity_1: 0.9899 - specificity_at_sensitivity_1: 0.9107 - recall_1: 0.9774 - precision_1: 0.8570 - val_loss: 0.3615 - val_accuracy: 0.8648 - val_sensitivity_at_specificity_1: 0.7334 - val_specificity_at_sensitivity_1: 0.8529 - val_recall_1: 0.9537 - val_precision_1: 0.9009\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.90391\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3308 - accuracy: 0.8720 - sensitivity_at_specificity_1: 0.9932 - specificity_at_sensitivity_1: 0.9205 - recall_1: 0.9770 - precision_1: 0.8669 - val_loss: 0.3868 - val_accuracy: 0.8484 - val_sensitivity_at_specificity_1: 0.7594 - val_specificity_at_sensitivity_1: 0.7820 - val_recall_1: 0.9320 - val_precision_1: 0.9021\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.90391\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3318 - accuracy: 0.8732 - sensitivity_at_specificity_1: 0.9916 - specificity_at_sensitivity_1: 0.9207 - recall_1: 0.9768 - precision_1: 0.8670 - val_loss: 0.4016 - val_accuracy: 0.8438 - val_sensitivity_at_specificity_1: 0.7341 - val_specificity_at_sensitivity_1: 0.8295 - val_recall_1: 0.9123 - val_precision_1: 0.9138\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.90391\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3657 - accuracy: 0.8487 - sensitivity_at_specificity_1: 0.9784 - specificity_at_sensitivity_1: 0.9028 - recall_1: 0.9584 - precision_1: 0.8526 - val_loss: 0.3173 - val_accuracy: 0.8891 - val_sensitivity_at_specificity_1: 0.8287 - val_specificity_at_sensitivity_1: 0.8676 - val_recall_1: 0.9904 - val_precision_1: 0.8964\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.90391\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3514 - accuracy: 0.8596 - sensitivity_at_specificity_1: 0.9885 - specificity_at_sensitivity_1: 0.9187 - recall_1: 0.9772 - precision_1: 0.8516 - val_loss: 0.3837 - val_accuracy: 0.8656 - val_sensitivity_at_specificity_1: 0.7621 - val_specificity_at_sensitivity_1: 0.8345 - val_recall_1: 0.9648 - val_precision_1: 0.8924\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.90391\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3290 - accuracy: 0.8779 - sensitivity_at_specificity_1: 0.9941 - specificity_at_sensitivity_1: 0.9078 - recall_1: 0.9776 - precision_1: 0.8747 - val_loss: 0.3611 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.7333 - val_specificity_at_sensitivity_1: 0.7287 - val_recall_1: 0.9722 - val_precision_1: 0.9039\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.90391\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3531 - accuracy: 0.8628 - sensitivity_at_specificity_1: 0.9895 - specificity_at_sensitivity_1: 0.9131 - recall_1: 0.9815 - precision_1: 0.8531 - val_loss: 0.3623 - val_accuracy: 0.8648 - val_sensitivity_at_specificity_1: 0.8003 - val_specificity_at_sensitivity_1: 0.7744 - val_recall_1: 0.9564 - val_precision_1: 0.8992\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.90391\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3276 - accuracy: 0.8718 - sensitivity_at_specificity_1: 0.9966 - specificity_at_sensitivity_1: 0.9139 - recall_1: 0.9763 - precision_1: 0.8670 - val_loss: 0.3633 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_1: 0.8238 - val_specificity_at_sensitivity_1: 0.8129 - val_recall_1: 0.9667 - val_precision_1: 0.8946\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.90391\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3418 - accuracy: 0.8574 - sensitivity_at_specificity_1: 0.9929 - specificity_at_sensitivity_1: 0.9305 - recall_1: 0.9715 - precision_1: 0.8507 - val_loss: 0.3874 - val_accuracy: 0.8398 - val_sensitivity_at_specificity_1: 0.7538 - val_specificity_at_sensitivity_1: 0.7550 - val_recall_1: 0.9415 - val_precision_1: 0.8844\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.90391\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3494 - accuracy: 0.8588 - sensitivity_at_specificity_1: 0.9871 - specificity_at_sensitivity_1: 0.9152 - recall_1: 0.9647 - precision_1: 0.8614 - val_loss: 0.3610 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.7827 - val_specificity_at_sensitivity_1: 0.8378 - val_recall_1: 0.9867 - val_precision_1: 0.8886\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.90391\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3572 - accuracy: 0.8634 - sensitivity_at_specificity_1: 0.9884 - specificity_at_sensitivity_1: 0.8876 - recall_1: 0.9785 - precision_1: 0.8568 - val_loss: 0.3936 - val_accuracy: 0.8680 - val_sensitivity_at_specificity_1: 0.7613 - val_specificity_at_sensitivity_1: 0.8030 - val_recall_1: 0.9591 - val_precision_1: 0.9002\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.90391\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3421 - accuracy: 0.8762 - sensitivity_at_specificity_1: 0.9928 - specificity_at_sensitivity_1: 0.9126 - recall_1: 0.9792 - precision_1: 0.8659 - val_loss: 0.3229 - val_accuracy: 0.8906 - val_sensitivity_at_specificity_1: 0.7467 - val_specificity_at_sensitivity_1: 0.8074 - val_recall_1: 0.9939 - val_precision_1: 0.8954\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.90391\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3710 - accuracy: 0.8584 - sensitivity_at_specificity_1: 0.9905 - specificity_at_sensitivity_1: 0.8950 - recall_1: 0.9801 - precision_1: 0.8480 - val_loss: 0.4204 - val_accuracy: 0.8289 - val_sensitivity_at_specificity_1: 0.7750 - val_specificity_at_sensitivity_1: 0.7391 - val_recall_1: 0.9037 - val_precision_1: 0.9045\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.90391\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3621 - accuracy: 0.8566 - sensitivity_at_specificity_1: 0.9934 - specificity_at_sensitivity_1: 0.9011 - recall_1: 0.9690 - precision_1: 0.8519 - val_loss: 0.3419 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.8025 - val_specificity_at_sensitivity_1: 0.8227 - val_recall_1: 0.9877 - val_precision_1: 0.8907\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.90391\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3452 - accuracy: 0.8658 - sensitivity_at_specificity_1: 0.9930 - specificity_at_sensitivity_1: 0.9193 - recall_1: 0.9857 - precision_1: 0.8527 - val_loss: 0.4033 - val_accuracy: 0.8320 - val_sensitivity_at_specificity_1: 0.7642 - val_specificity_at_sensitivity_1: 0.7842 - val_recall_1: 0.9124 - val_precision_1: 0.9005\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.90391\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3497 - accuracy: 0.8640 - sensitivity_at_specificity_1: 0.9893 - specificity_at_sensitivity_1: 0.9100 - recall_1: 0.9653 - precision_1: 0.8629 - val_loss: 0.3328 - val_accuracy: 0.8953 - val_sensitivity_at_specificity_1: 0.7825 - val_specificity_at_sensitivity_1: 0.8333 - val_recall_1: 0.9879 - val_precision_1: 0.9048\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.90391\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3263 - accuracy: 0.8782 - sensitivity_at_specificity_1: 0.9919 - specificity_at_sensitivity_1: 0.9266 - recall_1: 0.9845 - precision_1: 0.8708 - val_loss: 0.3181 - val_accuracy: 0.8922 - val_sensitivity_at_specificity_1: 0.7634 - val_specificity_at_sensitivity_1: 0.8115 - val_recall_1: 0.9845 - val_precision_1: 0.9048\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.90391\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3540 - accuracy: 0.8576 - sensitivity_at_specificity_1: 0.9798 - specificity_at_sensitivity_1: 0.9077 - recall_1: 0.9775 - precision_1: 0.8516 - val_loss: 0.3387 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.7810 - val_specificity_at_sensitivity_1: 0.8209 - val_recall_1: 0.9791 - val_precision_1: 0.8969\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.90391\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3216 - accuracy: 0.8763 - sensitivity_at_specificity_1: 0.9953 - specificity_at_sensitivity_1: 0.9246 - recall_1: 0.9832 - precision_1: 0.8665 - val_loss: 0.3588 - val_accuracy: 0.8781 - val_sensitivity_at_specificity_1: 0.7308 - val_specificity_at_sensitivity_1: 0.7941 - val_recall_1: 0.9729 - val_precision_1: 0.8990\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.90391\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3817 - accuracy: 0.8470 - sensitivity_at_specificity_1: 0.9863 - specificity_at_sensitivity_1: 0.8705 - recall_1: 0.9595 - precision_1: 0.8539 - val_loss: 0.3421 - val_accuracy: 0.8703 - val_sensitivity_at_specificity_1: 0.7635 - val_specificity_at_sensitivity_1: 0.8134 - val_recall_1: 0.9651 - val_precision_1: 0.8977\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.90391\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3141 - accuracy: 0.8801 - sensitivity_at_specificity_1: 0.9968 - specificity_at_sensitivity_1: 0.9453 - recall_1: 0.9778 - precision_1: 0.8734 - val_loss: 0.3434 - val_accuracy: 0.8781 - val_sensitivity_at_specificity_1: 0.8117 - val_specificity_at_sensitivity_1: 0.8261 - val_recall_1: 0.9790 - val_precision_1: 0.8944\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.90391\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3301 - accuracy: 0.8688 - sensitivity_at_specificity_1: 0.9952 - specificity_at_sensitivity_1: 0.9121 - recall_1: 0.9773 - precision_1: 0.8622 - val_loss: 0.4084 - val_accuracy: 0.8320 - val_sensitivity_at_specificity_1: 0.7204 - val_specificity_at_sensitivity_1: 0.8258 - val_recall_1: 0.9138 - val_precision_1: 0.9004\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.90391\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3391 - accuracy: 0.8682 - sensitivity_at_specificity_1: 0.9906 - specificity_at_sensitivity_1: 0.9388 - recall_1: 0.9704 - precision_1: 0.8644 - val_loss: 0.3430 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.7375 - val_specificity_at_sensitivity_1: 0.7883 - val_recall_1: 0.9860 - val_precision_1: 0.8959\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.90391\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3274 - accuracy: 0.8734 - sensitivity_at_specificity_1: 0.9908 - specificity_at_sensitivity_1: 0.9327 - recall_1: 0.9805 - precision_1: 0.8670 - val_loss: 0.3547 - val_accuracy: 0.8695 - val_sensitivity_at_specificity_1: 0.7898 - val_specificity_at_sensitivity_1: 0.7972 - val_recall_1: 0.9719 - val_precision_1: 0.8911\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.90391\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3371 - accuracy: 0.8681 - sensitivity_at_specificity_1: 0.9935 - specificity_at_sensitivity_1: 0.9179 - recall_1: 0.9669 - precision_1: 0.8650 - val_loss: 0.3730 - val_accuracy: 0.8617 - val_sensitivity_at_specificity_1: 0.7656 - val_specificity_at_sensitivity_1: 0.8672 - val_recall_1: 0.9462 - val_precision_1: 0.9046\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.90391\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3107 - accuracy: 0.8750 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9396 - recall_1: 0.9617 - precision_1: 0.8760 - val_loss: 0.3170 - val_accuracy: 0.8906 - val_sensitivity_at_specificity_1: 0.8022 - val_specificity_at_sensitivity_1: 0.8443 - val_recall_1: 0.9793 - val_precision_1: 0.9072\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.90391\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3430 - accuracy: 0.8649 - sensitivity_at_specificity_1: 0.9955 - specificity_at_sensitivity_1: 0.9155 - recall_1: 0.9800 - precision_1: 0.8531 - val_loss: 0.3384 - val_accuracy: 0.8758 - val_sensitivity_at_specificity_1: 0.7853 - val_specificity_at_sensitivity_1: 0.8060 - val_recall_1: 0.9729 - val_precision_1: 0.8970\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.90391\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3032 - accuracy: 0.8844 - sensitivity_at_specificity_1: 0.9976 - specificity_at_sensitivity_1: 0.9365 - recall_1: 0.9793 - precision_1: 0.8801 - val_loss: 0.3539 - val_accuracy: 0.8695 - val_sensitivity_at_specificity_1: 0.7986 - val_specificity_at_sensitivity_1: 0.8252 - val_recall_1: 0.9736 - val_precision_1: 0.8899\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.90391\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3328 - accuracy: 0.8726 - sensitivity_at_specificity_1: 0.9985 - specificity_at_sensitivity_1: 0.9160 - recall_1: 0.9792 - precision_1: 0.8651 - val_loss: 0.3672 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.7768 - val_specificity_at_sensitivity_1: 0.8346 - val_recall_1: 0.9651 - val_precision_1: 0.9000\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.90391\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3247 - accuracy: 0.8778 - sensitivity_at_specificity_1: 0.9928 - specificity_at_sensitivity_1: 0.9289 - recall_1: 0.9815 - precision_1: 0.8712 - val_loss: 0.3525 - val_accuracy: 0.8695 - val_sensitivity_at_specificity_1: 0.7936 - val_specificity_at_sensitivity_1: 0.7803 - val_recall_1: 0.9564 - val_precision_1: 0.9037\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.90391\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3132 - accuracy: 0.8788 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9432 - recall_1: 0.9799 - precision_1: 0.8723 - val_loss: 0.3551 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.8065 - val_specificity_at_sensitivity_1: 0.7972 - val_recall_1: 0.9877 - val_precision_1: 0.8899\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.90391\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3310 - accuracy: 0.8761 - sensitivity_at_specificity_1: 0.9869 - specificity_at_sensitivity_1: 0.9171 - recall_1: 0.9885 - precision_1: 0.8652 - val_loss: 0.3508 - val_accuracy: 0.8656 - val_sensitivity_at_specificity_1: 0.7786 - val_specificity_at_sensitivity_1: 0.7970 - val_recall_1: 0.9599 - val_precision_1: 0.8973\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.90391\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3115 - accuracy: 0.8796 - sensitivity_at_specificity_1: 0.9975 - specificity_at_sensitivity_1: 0.9332 - recall_1: 0.9784 - precision_1: 0.8697 - val_loss: 0.3710 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_1: 0.7933 - val_specificity_at_sensitivity_1: 0.7681 - val_recall_1: 0.9562 - val_precision_1: 0.8966\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.90391\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3074 - accuracy: 0.8809 - sensitivity_at_specificity_1: 0.9987 - specificity_at_sensitivity_1: 0.9247 - recall_1: 0.9770 - precision_1: 0.8721 - val_loss: 0.3317 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8253 - val_specificity_at_sensitivity_1: 0.8014 - val_recall_1: 0.9824 - val_precision_1: 0.8909\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.90391\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3322 - accuracy: 0.8764 - sensitivity_at_specificity_1: 0.9911 - specificity_at_sensitivity_1: 0.9094 - recall_1: 0.9810 - precision_1: 0.8689 - val_loss: 0.3131 - val_accuracy: 0.8961 - val_sensitivity_at_specificity_1: 0.8097 - val_specificity_at_sensitivity_1: 0.8217 - val_recall_1: 0.9948 - val_precision_1: 0.9002\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.90391\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3273 - accuracy: 0.8730 - sensitivity_at_specificity_1: 0.9978 - specificity_at_sensitivity_1: 0.9100 - recall_1: 0.9772 - precision_1: 0.8663 - val_loss: 0.3849 - val_accuracy: 0.8609 - val_sensitivity_at_specificity_1: 0.7760 - val_specificity_at_sensitivity_1: 0.8359 - val_recall_1: 0.9444 - val_precision_1: 0.9052\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.90391\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3239 - accuracy: 0.8780 - sensitivity_at_specificity_1: 0.9921 - specificity_at_sensitivity_1: 0.9290 - recall_1: 0.9769 - precision_1: 0.8738 - val_loss: 0.3408 - val_accuracy: 0.8781 - val_sensitivity_at_specificity_1: 0.7839 - val_specificity_at_sensitivity_1: 0.7969 - val_recall_1: 0.9696 - val_precision_1: 0.9023\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.90391\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3334 - accuracy: 0.8615 - sensitivity_at_specificity_1: 0.9975 - specificity_at_sensitivity_1: 0.9156 - recall_1: 0.9739 - precision_1: 0.8569 - val_loss: 0.3618 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.7581 - val_specificity_at_sensitivity_1: 0.8015 - val_recall_1: 0.9539 - val_precision_1: 0.9073\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.90391\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3309 - accuracy: 0.8651 - sensitivity_at_specificity_1: 0.9952 - specificity_at_sensitivity_1: 0.9235 - recall_1: 0.9590 - precision_1: 0.8674 - val_loss: 0.3390 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.7752 - val_specificity_at_sensitivity_1: 0.8248 - val_recall_1: 0.9790 - val_precision_1: 0.8974\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.90391\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3229 - accuracy: 0.8774 - sensitivity_at_specificity_1: 0.9973 - specificity_at_sensitivity_1: 0.9212 - recall_1: 0.9773 - precision_1: 0.8716 - val_loss: 0.3241 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.7806 - val_specificity_at_sensitivity_1: 0.7868 - val_recall_1: 0.9895 - val_precision_1: 0.8956\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.90391\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3504 - accuracy: 0.8612 - sensitivity_at_specificity_1: 0.9946 - specificity_at_sensitivity_1: 0.9087 - recall_1: 0.9850 - precision_1: 0.8484 - val_loss: 0.3281 - val_accuracy: 0.8844 - val_sensitivity_at_specificity_1: 0.8231 - val_specificity_at_sensitivity_1: 0.8261 - val_recall_1: 0.9851 - val_precision_1: 0.8957\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.90391\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3157 - accuracy: 0.8797 - sensitivity_at_specificity_1: 0.9972 - specificity_at_sensitivity_1: 0.8945 - recall_1: 0.9816 - precision_1: 0.8735 - val_loss: 0.3692 - val_accuracy: 0.8602 - val_sensitivity_at_specificity_1: 0.7928 - val_specificity_at_sensitivity_1: 0.8676 - val_recall_1: 0.9476 - val_precision_1: 0.9011\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.90391\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3398 - accuracy: 0.8655 - sensitivity_at_specificity_1: 0.9973 - specificity_at_sensitivity_1: 0.9044 - recall_1: 0.9666 - precision_1: 0.8613 - val_loss: 0.3526 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.7803 - val_specificity_at_sensitivity_1: 0.7881 - val_recall_1: 0.9858 - val_precision_1: 0.8840\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.90391\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3665 - accuracy: 0.8512 - sensitivity_at_specificity_1: 0.9833 - specificity_at_sensitivity_1: 0.8974 - recall_1: 0.9711 - precision_1: 0.8450 - val_loss: 0.3723 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.7841 - val_specificity_at_sensitivity_1: 0.8088 - val_recall_1: 0.9869 - val_precision_1: 0.8967\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.90391\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3179 - accuracy: 0.8837 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9158 - recall_1: 0.9824 - precision_1: 0.8737 - val_loss: 0.3564 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_1: 0.7911 - val_specificity_at_sensitivity_1: 0.8015 - val_recall_1: 0.9545 - val_precision_1: 0.8980\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.90391\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3205 - accuracy: 0.8696 - sensitivity_at_specificity_1: 0.9977 - specificity_at_sensitivity_1: 0.9287 - recall_1: 0.9719 - precision_1: 0.8672 - val_loss: 0.3420 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8091 - val_specificity_at_sensitivity_1: 0.8333 - val_recall_1: 0.9860 - val_precision_1: 0.8937\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.90391\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3225 - accuracy: 0.8747 - sensitivity_at_specificity_1: 0.9973 - specificity_at_sensitivity_1: 0.9270 - recall_1: 0.9885 - precision_1: 0.8618 - val_loss: 0.3258 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.7852 - val_specificity_at_sensitivity_1: 0.8000 - val_recall_1: 0.9755 - val_precision_1: 0.8994\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.90391\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3090 - accuracy: 0.8815 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9239 - recall_1: 0.9789 - precision_1: 0.8751 - val_loss: 0.3277 - val_accuracy: 0.8891 - val_sensitivity_at_specificity_1: 0.7830 - val_specificity_at_sensitivity_1: 0.8394 - val_recall_1: 0.9904 - val_precision_1: 0.8963\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.90391\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3200 - accuracy: 0.8785 - sensitivity_at_specificity_1: 0.9978 - specificity_at_sensitivity_1: 0.9269 - recall_1: 0.9838 - precision_1: 0.8684 - val_loss: 0.3764 - val_accuracy: 0.8500 - val_sensitivity_at_specificity_1: 0.7806 - val_specificity_at_sensitivity_1: 0.8138 - val_recall_1: 0.9480 - val_precision_1: 0.8900\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.90391\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3510 - accuracy: 0.8611 - sensitivity_at_specificity_1: 0.9929 - specificity_at_sensitivity_1: 0.9185 - recall_1: 0.9687 - precision_1: 0.8599 - val_loss: 0.3500 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.7767 - val_specificity_at_sensitivity_1: 0.8116 - val_recall_1: 0.9729 - val_precision_1: 0.8924\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.90391\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3410 - accuracy: 0.8702 - sensitivity_at_specificity_1: 0.9965 - specificity_at_sensitivity_1: 0.9125 - recall_1: 0.9800 - precision_1: 0.8594 - val_loss: 0.3387 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8245 - val_specificity_at_sensitivity_1: 0.8444 - val_recall_1: 0.9799 - val_precision_1: 0.8983\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.90391\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3092 - accuracy: 0.8833 - sensitivity_at_specificity_1: 0.9977 - specificity_at_sensitivity_1: 0.9271 - recall_1: 0.9879 - precision_1: 0.8706 - val_loss: 0.3163 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.8257 - val_specificity_at_sensitivity_1: 0.8261 - val_recall_1: 0.9860 - val_precision_1: 0.8979\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.90391\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3048 - accuracy: 0.8883 - sensitivity_at_specificity_1: 0.9974 - specificity_at_sensitivity_1: 0.9267 - recall_1: 0.9888 - precision_1: 0.8751 - val_loss: 0.3217 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8033 - val_specificity_at_sensitivity_1: 0.7857 - val_recall_1: 0.9749 - val_precision_1: 0.9029\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.90391\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3418 - accuracy: 0.8657 - sensitivity_at_specificity_1: 0.9965 - specificity_at_sensitivity_1: 0.9178 - recall_1: 0.9756 - precision_1: 0.8597 - val_loss: 0.3074 - val_accuracy: 0.8992 - val_sensitivity_at_specificity_1: 0.7998 - val_specificity_at_sensitivity_1: 0.7460 - val_recall_1: 0.9965 - val_precision_1: 0.9020\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.90391\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3258 - accuracy: 0.8771 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9095 - recall_1: 0.9900 - precision_1: 0.8615 - val_loss: 0.3547 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_1: 0.8098 - val_specificity_at_sensitivity_1: 0.8731 - val_recall_1: 0.9503 - val_precision_1: 0.9015\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.90391\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3162 - accuracy: 0.8698 - sensitivity_at_specificity_1: 0.9983 - specificity_at_sensitivity_1: 0.9414 - recall_1: 0.9643 - precision_1: 0.8693 - val_loss: 0.3248 - val_accuracy: 0.8898 - val_sensitivity_at_specificity_1: 0.8359 - val_specificity_at_sensitivity_1: 0.8281 - val_recall_1: 0.9835 - val_precision_1: 0.9028\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.90391\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3250 - accuracy: 0.8695 - sensitivity_at_specificity_1: 0.9940 - specificity_at_sensitivity_1: 0.9263 - recall_1: 0.9766 - precision_1: 0.8623 - val_loss: 0.3258 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.8374 - val_specificity_at_sensitivity_1: 0.8456 - val_recall_1: 0.9878 - val_precision_1: 0.8968\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.90391\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3332 - accuracy: 0.8704 - sensitivity_at_specificity_1: 0.9976 - specificity_at_sensitivity_1: 0.9182 - recall_1: 0.9844 - precision_1: 0.8568 - val_loss: 0.3478 - val_accuracy: 0.8680 - val_sensitivity_at_specificity_1: 0.8000 - val_specificity_at_sensitivity_1: 0.8071 - val_recall_1: 0.9649 - val_precision_1: 0.8950\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.90391\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3426 - accuracy: 0.8649 - sensitivity_at_specificity_1: 0.9975 - specificity_at_sensitivity_1: 0.9044 - recall_1: 0.9744 - precision_1: 0.8592 - val_loss: 0.3479 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.8074 - val_specificity_at_sensitivity_1: 0.8252 - val_recall_1: 0.9754 - val_precision_1: 0.8922\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.90391\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3268 - accuracy: 0.8712 - sensitivity_at_specificity_1: 0.9961 - specificity_at_sensitivity_1: 0.9295 - recall_1: 0.9796 - precision_1: 0.8615 - val_loss: 0.3184 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.8003 - val_specificity_at_sensitivity_1: 0.8047 - val_recall_1: 0.9792 - val_precision_1: 0.9017\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.90391\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3157 - accuracy: 0.8805 - sensitivity_at_specificity_1: 0.9985 - specificity_at_sensitivity_1: 0.9163 - recall_1: 0.9886 - precision_1: 0.8663 - val_loss: 0.3354 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.8320 - val_specificity_at_sensitivity_1: 0.8456 - val_recall_1: 0.9885 - val_precision_1: 0.8873\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.90391\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3158 - accuracy: 0.8766 - sensitivity_at_specificity_1: 0.9955 - specificity_at_sensitivity_1: 0.9268 - recall_1: 0.9831 - precision_1: 0.8679 - val_loss: 0.3119 - val_accuracy: 0.8906 - val_sensitivity_at_specificity_1: 0.7951 - val_specificity_at_sensitivity_1: 0.8271 - val_recall_1: 0.9869 - val_precision_1: 0.9006\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.90391\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3338 - accuracy: 0.8696 - sensitivity_at_specificity_1: 0.9969 - specificity_at_sensitivity_1: 0.9244 - recall_1: 0.9817 - precision_1: 0.8588 - val_loss: 0.3652 - val_accuracy: 0.8609 - val_sensitivity_at_specificity_1: 0.7913 - val_specificity_at_sensitivity_1: 0.8462 - val_recall_1: 0.9461 - val_precision_1: 0.9037\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.90391\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3289 - accuracy: 0.8806 - sensitivity_at_specificity_1: 0.9947 - specificity_at_sensitivity_1: 0.9088 - recall_1: 0.9764 - precision_1: 0.8752 - val_loss: 0.3201 - val_accuracy: 0.8898 - val_sensitivity_at_specificity_1: 0.8106 - val_specificity_at_sensitivity_1: 0.8284 - val_recall_1: 0.9869 - val_precision_1: 0.8998\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.90391\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3333 - accuracy: 0.8771 - sensitivity_at_specificity_1: 0.9970 - specificity_at_sensitivity_1: 0.8953 - recall_1: 0.9829 - precision_1: 0.8670 - val_loss: 0.3274 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8320 - val_specificity_at_sensitivity_1: 0.8394 - val_recall_1: 0.9764 - val_precision_1: 0.9007\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.90391\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3196 - accuracy: 0.8747 - sensitivity_at_specificity_1: 0.9964 - specificity_at_sensitivity_1: 0.9381 - recall_1: 0.9718 - precision_1: 0.8720 - val_loss: 0.3414 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.7790 - val_specificity_at_sensitivity_1: 0.7852 - val_recall_1: 0.9921 - val_precision_1: 0.8945\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.90391\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3176 - accuracy: 0.8826 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.8993 - recall_1: 0.9905 - precision_1: 0.8697 - val_loss: 0.3818 - val_accuracy: 0.8484 - val_sensitivity_at_specificity_1: 0.7951 - val_specificity_at_sensitivity_1: 0.8043 - val_recall_1: 0.9317 - val_precision_1: 0.9017\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.90391\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3114 - accuracy: 0.8750 - sensitivity_at_specificity_1: 0.9981 - specificity_at_sensitivity_1: 0.9359 - recall_1: 0.9692 - precision_1: 0.8754 - val_loss: 0.3186 - val_accuracy: 0.8906 - val_sensitivity_at_specificity_1: 0.7912 - val_specificity_at_sensitivity_1: 0.8095 - val_recall_1: 0.9853 - val_precision_1: 0.9024\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.90391\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3304 - accuracy: 0.8689 - sensitivity_at_specificity_1: 0.9945 - specificity_at_sensitivity_1: 0.9248 - recall_1: 0.9867 - precision_1: 0.8554 - val_loss: 0.3561 - val_accuracy: 0.8602 - val_sensitivity_at_specificity_1: 0.8439 - val_specificity_at_sensitivity_1: 0.8071 - val_recall_1: 0.9561 - val_precision_1: 0.8942\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.90391\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3304 - accuracy: 0.8681 - sensitivity_at_specificity_1: 0.9975 - specificity_at_sensitivity_1: 0.9354 - recall_1: 0.9650 - precision_1: 0.8640 - val_loss: 0.3398 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.7970 - val_specificity_at_sensitivity_1: 0.8102 - val_recall_1: 0.9764 - val_precision_1: 0.8978\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.90391\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2815 - accuracy: 0.8888 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9591 - recall_1: 0.9773 - precision_1: 0.8863 - val_loss: 0.3526 - val_accuracy: 0.8664 - val_sensitivity_at_specificity_1: 0.8128 - val_specificity_at_sensitivity_1: 0.8759 - val_recall_1: 0.9633 - val_precision_1: 0.8951\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.90391\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3126 - accuracy: 0.8771 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9407 - recall_1: 0.9783 - precision_1: 0.8704 - val_loss: 0.3313 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.8016 - val_specificity_at_sensitivity_1: 0.8626 - val_recall_1: 0.9591 - val_precision_1: 0.9033\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.90391\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3273 - accuracy: 0.8760 - sensitivity_at_specificity_1: 0.9949 - specificity_at_sensitivity_1: 0.9207 - recall_1: 0.9812 - precision_1: 0.8676 - val_loss: 0.3333 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.7963 - val_specificity_at_sensitivity_1: 0.8156 - val_recall_1: 0.9895 - val_precision_1: 0.8916\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.90391\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3114 - accuracy: 0.8776 - sensitivity_at_specificity_1: 0.9983 - specificity_at_sensitivity_1: 0.9355 - recall_1: 0.9792 - precision_1: 0.8689 - val_loss: 0.3711 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.8085 - val_specificity_at_sensitivity_1: 0.8092 - val_recall_1: 0.9565 - val_precision_1: 0.9053\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.90391\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3370 - accuracy: 0.8686 - sensitivity_at_specificity_1: 0.9916 - specificity_at_sensitivity_1: 0.9193 - recall_1: 0.9750 - precision_1: 0.8614 - val_loss: 0.3276 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8252 - val_specificity_at_sensitivity_1: 0.8750 - val_recall_1: 0.9790 - val_precision_1: 0.8989\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.90391\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3147 - accuracy: 0.8724 - sensitivity_at_specificity_1: 0.9961 - specificity_at_sensitivity_1: 0.9351 - recall_1: 0.9789 - precision_1: 0.8661 - val_loss: 0.3705 - val_accuracy: 0.8586 - val_sensitivity_at_specificity_1: 0.7967 - val_specificity_at_sensitivity_1: 0.8433 - val_recall_1: 0.9485 - val_precision_1: 0.8991\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.90391\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3122 - accuracy: 0.8752 - sensitivity_at_specificity_1: 0.9963 - specificity_at_sensitivity_1: 0.9412 - recall_1: 0.9690 - precision_1: 0.8744 - val_loss: 0.3573 - val_accuracy: 0.8609 - val_sensitivity_at_specificity_1: 0.8077 - val_specificity_at_sensitivity_1: 0.8015 - val_recall_1: 0.9495 - val_precision_1: 0.9009\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.90391\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3338 - accuracy: 0.8771 - sensitivity_at_specificity_1: 0.9928 - specificity_at_sensitivity_1: 0.8981 - recall_1: 0.9791 - precision_1: 0.8718 - val_loss: 0.3254 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.7908 - val_specificity_at_sensitivity_1: 0.8984 - val_recall_1: 0.9783 - val_precision_1: 0.9038\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.90391\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3229 - accuracy: 0.8686 - sensitivity_at_specificity_1: 0.9932 - specificity_at_sensitivity_1: 0.9314 - recall_1: 0.9706 - precision_1: 0.8678 - val_loss: 0.3173 - val_accuracy: 0.8898 - val_sensitivity_at_specificity_1: 0.8504 - val_specificity_at_sensitivity_1: 0.9051 - val_recall_1: 0.9956 - val_precision_1: 0.8932\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.90391\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3130 - accuracy: 0.8803 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9264 - recall_1: 0.9934 - precision_1: 0.8640 - val_loss: 0.3297 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.7778 - val_specificity_at_sensitivity_1: 0.7883 - val_recall_1: 0.9790 - val_precision_1: 0.8959\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.90391\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3549 - accuracy: 0.8626 - sensitivity_at_specificity_1: 0.9892 - specificity_at_sensitivity_1: 0.9148 - recall_1: 0.9785 - precision_1: 0.8552 - val_loss: 0.3395 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.8270 - val_specificity_at_sensitivity_1: 0.8308 - val_recall_1: 0.9835 - val_precision_1: 0.9012\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.90391\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3019 - accuracy: 0.8894 - sensitivity_at_specificity_1: 0.9991 - specificity_at_sensitivity_1: 0.9426 - recall_1: 0.9825 - precision_1: 0.8812 - val_loss: 0.3496 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.8072 - val_specificity_at_sensitivity_1: 0.8345 - val_recall_1: 0.9667 - val_precision_1: 0.8989\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.90391\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3226 - accuracy: 0.8720 - sensitivity_at_specificity_1: 0.9975 - specificity_at_sensitivity_1: 0.9338 - recall_1: 0.9736 - precision_1: 0.8700 - val_loss: 0.3261 - val_accuracy: 0.8945 - val_sensitivity_at_specificity_1: 0.8293 - val_specificity_at_sensitivity_1: 0.8712 - val_recall_1: 0.9956 - val_precision_1: 0.8979\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.90391\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3299 - accuracy: 0.8738 - sensitivity_at_specificity_1: 0.9974 - specificity_at_sensitivity_1: 0.9304 - recall_1: 0.9956 - precision_1: 0.8552 - val_loss: 0.3260 - val_accuracy: 0.8758 - val_sensitivity_at_specificity_1: 0.8064 - val_specificity_at_sensitivity_1: 0.8359 - val_recall_1: 0.9679 - val_precision_1: 0.9014\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.90391\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3098 - accuracy: 0.8765 - sensitivity_at_specificity_1: 0.9978 - specificity_at_sensitivity_1: 0.9555 - recall_1: 0.9798 - precision_1: 0.8705 - val_loss: 0.3619 - val_accuracy: 0.8719 - val_sensitivity_at_specificity_1: 0.7886 - val_specificity_at_sensitivity_1: 0.8071 - val_recall_1: 0.9693 - val_precision_1: 0.8955\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.90391\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3268 - accuracy: 0.8744 - sensitivity_at_specificity_1: 0.9955 - specificity_at_sensitivity_1: 0.9184 - recall_1: 0.9850 - precision_1: 0.8613 - val_loss: 0.3594 - val_accuracy: 0.8609 - val_sensitivity_at_specificity_1: 0.7887 - val_specificity_at_sensitivity_1: 0.8462 - val_recall_1: 0.9478 - val_precision_1: 0.9023\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.90391\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3290 - accuracy: 0.8698 - sensitivity_at_specificity_1: 0.9977 - specificity_at_sensitivity_1: 0.9213 - recall_1: 0.9752 - precision_1: 0.8617 - val_loss: 0.3471 - val_accuracy: 0.8648 - val_sensitivity_at_specificity_1: 0.8241 - val_specificity_at_sensitivity_1: 0.8613 - val_recall_1: 0.9606 - val_precision_1: 0.8956\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.90391\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2987 - accuracy: 0.8783 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9465 - recall_1: 0.9769 - precision_1: 0.8732 - val_loss: 0.3230 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.7942 - val_specificity_at_sensitivity_1: 0.8421 - val_recall_1: 0.9808 - val_precision_1: 0.8978\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.90391\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2938 - accuracy: 0.8835 - sensitivity_at_specificity_1: 0.9982 - specificity_at_sensitivity_1: 0.9482 - recall_1: 0.9886 - precision_1: 0.8714 - val_loss: 0.3166 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8064 - val_specificity_at_sensitivity_1: 0.7891 - val_recall_1: 0.9748 - val_precision_1: 0.9064\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.90391\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3192 - accuracy: 0.8762 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9400 - recall_1: 0.9806 - precision_1: 0.8644 - val_loss: 0.3656 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_1: 0.7732 - val_specificity_at_sensitivity_1: 0.7752 - val_recall_1: 0.9409 - val_precision_1: 0.9033\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.90391\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3414 - accuracy: 0.8664 - sensitivity_at_specificity_1: 0.9914 - specificity_at_sensitivity_1: 0.9189 - recall_1: 0.9648 - precision_1: 0.8660 - val_loss: 0.3139 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.8272 - val_specificity_at_sensitivity_1: 0.8357 - val_recall_1: 0.9921 - val_precision_1: 0.8913\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.90391\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3223 - accuracy: 0.8709 - sensitivity_at_specificity_1: 0.9955 - specificity_at_sensitivity_1: 0.9286 - recall_1: 0.9840 - precision_1: 0.8596 - val_loss: 0.3541 - val_accuracy: 0.8703 - val_sensitivity_at_specificity_1: 0.8154 - val_specificity_at_sensitivity_1: 0.8243 - val_recall_1: 0.9717 - val_precision_1: 0.8914\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.90391\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3014 - accuracy: 0.8855 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9285 - recall_1: 0.9757 - precision_1: 0.8812 - val_loss: 0.3668 - val_accuracy: 0.8641 - val_sensitivity_at_specificity_1: 0.8040 - val_specificity_at_sensitivity_1: 0.8636 - val_recall_1: 0.9425 - val_precision_1: 0.9092\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.90391\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3040 - accuracy: 0.8817 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9339 - recall_1: 0.9761 - precision_1: 0.8758 - val_loss: 0.3094 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8409 - val_specificity_at_sensitivity_1: 0.8750 - val_recall_1: 0.9869 - val_precision_1: 0.8967\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.90391\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3256 - accuracy: 0.8759 - sensitivity_at_specificity_1: 0.9915 - specificity_at_sensitivity_1: 0.9297 - recall_1: 0.9801 - precision_1: 0.8705 - val_loss: 0.3103 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8155 - val_specificity_at_sensitivity_1: 0.8321 - val_recall_1: 0.9695 - val_precision_1: 0.9013\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.90391\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3090 - accuracy: 0.8851 - sensitivity_at_specificity_1: 0.9981 - specificity_at_sensitivity_1: 0.9373 - recall_1: 0.9817 - precision_1: 0.8727 - val_loss: 0.3335 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.8238 - val_specificity_at_sensitivity_1: 0.8561 - val_recall_1: 0.9816 - val_precision_1: 0.8953\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.90391\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2936 - accuracy: 0.8922 - sensitivity_at_specificity_1: 0.9985 - specificity_at_sensitivity_1: 0.9305 - recall_1: 0.9857 - precision_1: 0.8822 - val_loss: 0.3627 - val_accuracy: 0.8648 - val_sensitivity_at_specificity_1: 0.8149 - val_specificity_at_sensitivity_1: 0.8000 - val_recall_1: 0.9561 - val_precision_1: 0.8986\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.90391\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3272 - accuracy: 0.8785 - sensitivity_at_specificity_1: 0.9983 - specificity_at_sensitivity_1: 0.9117 - recall_1: 0.9806 - precision_1: 0.8700 - val_loss: 0.3295 - val_accuracy: 0.8844 - val_sensitivity_at_specificity_1: 0.8060 - val_specificity_at_sensitivity_1: 0.8014 - val_recall_1: 0.9930 - val_precision_1: 0.8899\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.90391\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3221 - accuracy: 0.8676 - sensitivity_at_specificity_1: 0.9966 - specificity_at_sensitivity_1: 0.9233 - recall_1: 0.9747 - precision_1: 0.8614 - val_loss: 0.3140 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.8258 - val_specificity_at_sensitivity_1: 0.8788 - val_recall_1: 0.9791 - val_precision_1: 0.9021\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.90391\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3176 - accuracy: 0.8770 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9281 - recall_1: 0.9746 - precision_1: 0.8713 - val_loss: 0.3544 - val_accuracy: 0.8609 - val_sensitivity_at_specificity_1: 0.8107 - val_specificity_at_sensitivity_1: 0.8705 - val_recall_1: 0.9544 - val_precision_1: 0.8963\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.90391\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3256 - accuracy: 0.8760 - sensitivity_at_specificity_1: 0.9964 - specificity_at_sensitivity_1: 0.8862 - recall_1: 0.9788 - precision_1: 0.8713 - val_loss: 0.3358 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.8047 - val_specificity_at_sensitivity_1: 0.8112 - val_recall_1: 0.9754 - val_precision_1: 0.8936\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.90391\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3436 - accuracy: 0.8687 - sensitivity_at_specificity_1: 0.9985 - specificity_at_sensitivity_1: 0.9164 - recall_1: 0.9772 - precision_1: 0.8601 - val_loss: 0.3038 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_1: 0.8085 - val_specificity_at_sensitivity_1: 0.8347 - val_recall_1: 0.9845 - val_precision_1: 0.9063\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.90391\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2922 - accuracy: 0.8878 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9409 - recall_1: 0.9831 - precision_1: 0.8787 - val_loss: 0.2965 - val_accuracy: 0.8984 - val_sensitivity_at_specificity_1: 0.8387 - val_specificity_at_sensitivity_1: 0.8268 - val_recall_1: 0.9965 - val_precision_1: 0.9012\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.90391\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2941 - accuracy: 0.8845 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9462 - recall_1: 0.9856 - precision_1: 0.8740 - val_loss: 0.3563 - val_accuracy: 0.8633 - val_sensitivity_at_specificity_1: 0.7680 - val_specificity_at_sensitivity_1: 0.8080 - val_recall_1: 0.9481 - val_precision_1: 0.9050\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.90391\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3111 - accuracy: 0.8884 - sensitivity_at_specificity_1: 0.9979 - specificity_at_sensitivity_1: 0.9347 - recall_1: 0.9722 - precision_1: 0.8855 - val_loss: 0.3601 - val_accuracy: 0.8570 - val_sensitivity_at_specificity_1: 0.7993 - val_specificity_at_sensitivity_1: 0.8358 - val_recall_1: 0.9424 - val_precision_1: 0.9023\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.90391\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3088 - accuracy: 0.8857 - sensitivity_at_specificity_1: 0.9982 - specificity_at_sensitivity_1: 0.9268 - recall_1: 0.9790 - precision_1: 0.8776 - val_loss: 0.3372 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8124 - val_specificity_at_sensitivity_1: 0.8129 - val_recall_1: 0.9798 - val_precision_1: 0.8930\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.90391\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2915 - accuracy: 0.8841 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9395 - recall_1: 0.9850 - precision_1: 0.8742 - val_loss: 0.3366 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.7945 - val_specificity_at_sensitivity_1: 0.8288 - val_recall_1: 0.9832 - val_precision_1: 0.8899\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.90391\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3166 - accuracy: 0.8697 - sensitivity_at_specificity_1: 0.9914 - specificity_at_sensitivity_1: 0.9382 - recall_1: 0.9804 - precision_1: 0.8630 - val_loss: 0.3340 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8141 - val_specificity_at_sensitivity_1: 0.8217 - val_recall_1: 0.9757 - val_precision_1: 0.9056\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.90391\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.3115 - accuracy: 0.8770 - sensitivity_at_specificity_1: 0.9949 - specificity_at_sensitivity_1: 0.9496 - recall_1: 0.9799 - precision_1: 0.8704 - val_loss: 0.3380 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.8062 - val_specificity_at_sensitivity_1: 0.8690 - val_recall_1: 0.9744 - val_precision_1: 0.8905\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.90391\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.3549 - accuracy: 0.8585 - sensitivity_at_specificity_1: 0.9948 - specificity_at_sensitivity_1: 0.9104 - recall_1: 0.9772 - precision_1: 0.8482 - val_loss: 0.3277 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.8298 - val_specificity_at_sensitivity_1: 0.7945 - val_recall_1: 0.9929 - val_precision_1: 0.8866\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.90391\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3103 - accuracy: 0.8757 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9437 - recall_1: 0.9836 - precision_1: 0.8634 - val_loss: 0.3077 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.8504 - val_specificity_at_sensitivity_1: 0.8321 - val_recall_1: 0.9921 - val_precision_1: 0.8936\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.90391\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2980 - accuracy: 0.8908 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9335 - recall_1: 0.9863 - precision_1: 0.8797 - val_loss: 0.3149 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.7990 - val_specificity_at_sensitivity_1: 0.7634 - val_recall_1: 0.9843 - val_precision_1: 0.9005\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.90391\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3182 - accuracy: 0.8800 - sensitivity_at_specificity_1: 0.9966 - specificity_at_sensitivity_1: 0.9278 - recall_1: 0.9837 - precision_1: 0.8686 - val_loss: 0.3468 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.7759 - val_specificity_at_sensitivity_1: 0.7820 - val_recall_1: 0.9677 - val_precision_1: 0.9002\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.90391\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2980 - accuracy: 0.8828 - sensitivity_at_specificity_1: 0.9989 - specificity_at_sensitivity_1: 0.9380 - recall_1: 0.9820 - precision_1: 0.8747 - val_loss: 0.3154 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.8345 - val_specificity_at_sensitivity_1: 0.8261 - val_recall_1: 0.9877 - val_precision_1: 0.8967\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.90391\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3168 - accuracy: 0.8819 - sensitivity_at_specificity_1: 0.9977 - specificity_at_sensitivity_1: 0.9286 - recall_1: 0.9864 - precision_1: 0.8699 - val_loss: 0.3161 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8300 - val_specificity_at_sensitivity_1: 0.8195 - val_recall_1: 0.9869 - val_precision_1: 0.8970\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.90391\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3062 - accuracy: 0.8798 - sensitivity_at_specificity_1: 0.9980 - specificity_at_sensitivity_1: 0.9272 - recall_1: 0.9824 - precision_1: 0.8720 - val_loss: 0.3444 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8093 - val_specificity_at_sensitivity_1: 0.8169 - val_recall_1: 0.9798 - val_precision_1: 0.8927\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.90391\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2995 - accuracy: 0.8816 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9346 - recall_1: 0.9824 - precision_1: 0.8713 - val_loss: 0.3223 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8118 - val_specificity_at_sensitivity_1: 0.8189 - val_recall_1: 0.9835 - val_precision_1: 0.9000\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.90391\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2944 - accuracy: 0.8794 - sensitivity_at_specificity_1: 0.9980 - specificity_at_sensitivity_1: 0.9571 - recall_1: 0.9827 - precision_1: 0.8690 - val_loss: 0.3304 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.8291 - val_specificity_at_sensitivity_1: 0.7931 - val_recall_1: 0.9859 - val_precision_1: 0.8874\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.90391\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2947 - accuracy: 0.8872 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9467 - recall_1: 0.9870 - precision_1: 0.8745 - val_loss: 0.3367 - val_accuracy: 0.8719 - val_sensitivity_at_specificity_1: 0.8391 - val_specificity_at_sensitivity_1: 0.8112 - val_recall_1: 0.9745 - val_precision_1: 0.8914\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.90391\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2862 - accuracy: 0.8837 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9446 - recall_1: 0.9737 - precision_1: 0.8801 - val_loss: 0.3251 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.8077 - val_specificity_at_sensitivity_1: 0.8582 - val_recall_1: 0.9824 - val_precision_1: 0.8945\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.90391\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3130 - accuracy: 0.8849 - sensitivity_at_specificity_1: 0.9993 - specificity_at_sensitivity_1: 0.9228 - recall_1: 0.9852 - precision_1: 0.8737 - val_loss: 0.3386 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.8126 - val_specificity_at_sensitivity_1: 0.7826 - val_recall_1: 0.9764 - val_precision_1: 0.8970\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.90391\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3043 - accuracy: 0.8777 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9383 - recall_1: 0.9670 - precision_1: 0.8761 - val_loss: 0.3346 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8241 - val_specificity_at_sensitivity_1: 0.8112 - val_recall_1: 0.9798 - val_precision_1: 0.8926\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.90391\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.2854 - accuracy: 0.8894 - sensitivity_at_specificity_1: 0.9986 - specificity_at_sensitivity_1: 0.9382 - recall_1: 0.9843 - precision_1: 0.8815 - val_loss: 0.2918 - val_accuracy: 0.9016 - val_sensitivity_at_specificity_1: 0.8267 - val_specificity_at_sensitivity_1: 0.8333 - val_recall_1: 0.9914 - val_precision_1: 0.9084\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.90391\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3009 - accuracy: 0.8851 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9543 - recall_1: 0.9838 - precision_1: 0.8732 - val_loss: 0.3171 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.8133 - val_specificity_at_sensitivity_1: 0.7770 - val_recall_1: 0.9869 - val_precision_1: 0.8958\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.90391\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2736 - accuracy: 0.8884 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9573 - recall_1: 0.9812 - precision_1: 0.8786 - val_loss: 0.3223 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8212 - val_specificity_at_sensitivity_1: 0.8489 - val_recall_1: 0.9860 - val_precision_1: 0.8936\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.90391\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2763 - accuracy: 0.8901 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9478 - recall_1: 0.9803 - precision_1: 0.8841 - val_loss: 0.3322 - val_accuracy: 0.8758 - val_sensitivity_at_specificity_1: 0.8180 - val_specificity_at_sensitivity_1: 0.7956 - val_recall_1: 0.9738 - val_precision_1: 0.8961\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.90391\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.2950 - accuracy: 0.8831 - sensitivity_at_specificity_1: 0.9993 - specificity_at_sensitivity_1: 0.9368 - recall_1: 0.9742 - precision_1: 0.8805 - val_loss: 0.3781 - val_accuracy: 0.8508 - val_sensitivity_at_specificity_1: 0.7650 - val_specificity_at_sensitivity_1: 0.8333 - val_recall_1: 0.9463 - val_precision_1: 0.8921\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.90391\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3231 - accuracy: 0.8702 - sensitivity_at_specificity_1: 0.9966 - specificity_at_sensitivity_1: 0.9349 - recall_1: 0.9724 - precision_1: 0.8641 - val_loss: 0.3170 - val_accuracy: 0.8844 - val_sensitivity_at_specificity_1: 0.8277 - val_specificity_at_sensitivity_1: 0.8168 - val_recall_1: 0.9800 - val_precision_1: 0.9001\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.90391\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2873 - accuracy: 0.8851 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9467 - recall_1: 0.9846 - precision_1: 0.8753 - val_loss: 0.3083 - val_accuracy: 0.8914 - val_sensitivity_at_specificity_1: 0.7965 - val_specificity_at_sensitivity_1: 0.8231 - val_recall_1: 0.9887 - val_precision_1: 0.9002\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.90391\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2946 - accuracy: 0.8944 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9160 - recall_1: 0.9899 - precision_1: 0.8828 - val_loss: 0.3532 - val_accuracy: 0.8594 - val_sensitivity_at_specificity_1: 0.8325 - val_specificity_at_sensitivity_1: 0.8286 - val_recall_1: 0.9509 - val_precision_1: 0.8974\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.90391\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3048 - accuracy: 0.8853 - sensitivity_at_specificity_1: 0.9972 - specificity_at_sensitivity_1: 0.9373 - recall_1: 0.9717 - precision_1: 0.8847 - val_loss: 0.3778 - val_accuracy: 0.8531 - val_sensitivity_at_specificity_1: 0.8176 - val_specificity_at_sensitivity_1: 0.8358 - val_recall_1: 0.9337 - val_precision_1: 0.9052\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.90391\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3143 - accuracy: 0.8741 - sensitivity_at_specificity_1: 0.9975 - specificity_at_sensitivity_1: 0.9379 - recall_1: 0.9651 - precision_1: 0.8751 - val_loss: 0.3282 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8354 - val_specificity_at_sensitivity_1: 0.8551 - val_recall_1: 0.9807 - val_precision_1: 0.8946\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.90391\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3162 - accuracy: 0.8669 - sensitivity_at_specificity_1: 0.9952 - specificity_at_sensitivity_1: 0.9596 - recall_1: 0.9796 - precision_1: 0.8547 - val_loss: 0.3367 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8162 - val_specificity_at_sensitivity_1: 0.7972 - val_recall_1: 0.9859 - val_precision_1: 0.8904\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.90391\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3011 - accuracy: 0.8816 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9413 - recall_1: 0.9798 - precision_1: 0.8766 - val_loss: 0.3337 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.8112 - val_specificity_at_sensitivity_1: 0.8014 - val_recall_1: 0.9842 - val_precision_1: 0.8925\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.90391\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3002 - accuracy: 0.8821 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9554 - recall_1: 0.9756 - precision_1: 0.8756 - val_loss: 0.3521 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.8248 - val_specificity_at_sensitivity_1: 0.8333 - val_recall_1: 0.9754 - val_precision_1: 0.8914\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.90391\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3007 - accuracy: 0.8819 - sensitivity_at_specificity_1: 0.9989 - specificity_at_sensitivity_1: 0.9502 - recall_1: 0.9712 - precision_1: 0.8757 - val_loss: 0.3337 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.8268 - val_specificity_at_sensitivity_1: 0.8321 - val_recall_1: 0.9711 - val_precision_1: 0.8959\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.90391\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2767 - accuracy: 0.8922 - sensitivity_at_specificity_1: 0.9985 - specificity_at_sensitivity_1: 0.9617 - recall_1: 0.9821 - precision_1: 0.8851 - val_loss: 0.3507 - val_accuracy: 0.8648 - val_sensitivity_at_specificity_1: 0.7965 - val_specificity_at_sensitivity_1: 0.7862 - val_recall_1: 0.9700 - val_precision_1: 0.8879\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.90391\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2865 - accuracy: 0.8937 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9403 - recall_1: 0.9902 - precision_1: 0.8778 - val_loss: 0.3161 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8297 - val_specificity_at_sensitivity_1: 0.8370 - val_recall_1: 0.9869 - val_precision_1: 0.8968\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.90391\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2917 - accuracy: 0.8899 - sensitivity_at_specificity_1: 0.9983 - specificity_at_sensitivity_1: 0.9329 - recall_1: 0.9798 - precision_1: 0.8857 - val_loss: 0.3198 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8230 - val_specificity_at_sensitivity_1: 0.8777 - val_recall_1: 0.9816 - val_precision_1: 0.8939\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.90391\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2915 - accuracy: 0.8875 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9367 - recall_1: 0.9868 - precision_1: 0.8766 - val_loss: 0.3378 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.8162 - val_specificity_at_sensitivity_1: 0.8112 - val_recall_1: 0.9815 - val_precision_1: 0.8907\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.90391\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3080 - accuracy: 0.8773 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9405 - recall_1: 0.9779 - precision_1: 0.8686 - val_loss: 0.3212 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.8184 - val_specificity_at_sensitivity_1: 0.8500 - val_recall_1: 0.9781 - val_precision_1: 0.8934\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.90391\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2968 - accuracy: 0.8815 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9561 - recall_1: 0.9826 - precision_1: 0.8679 - val_loss: 0.3006 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_1: 0.8144 - val_specificity_at_sensitivity_1: 0.8346 - val_recall_1: 0.9896 - val_precision_1: 0.9020\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.90391\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2824 - accuracy: 0.8937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9366 - recall_1: 0.9848 - precision_1: 0.8857 - val_loss: 0.3061 - val_accuracy: 0.8844 - val_sensitivity_at_specificity_1: 0.8615 - val_specificity_at_sensitivity_1: 0.8489 - val_recall_1: 0.9895 - val_precision_1: 0.8925\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.90391\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3074 - accuracy: 0.8720 - sensitivity_at_specificity_1: 0.9973 - specificity_at_sensitivity_1: 0.9507 - recall_1: 0.9807 - precision_1: 0.8631 - val_loss: 0.2901 - val_accuracy: 0.9000 - val_sensitivity_at_specificity_1: 0.8214 - val_specificity_at_sensitivity_1: 0.8430 - val_recall_1: 0.9845 - val_precision_1: 0.9121\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.90391\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3151 - accuracy: 0.8745 - sensitivity_at_specificity_1: 0.9981 - specificity_at_sensitivity_1: 0.9309 - recall_1: 0.9804 - precision_1: 0.8650 - val_loss: 0.3232 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.8251 - val_specificity_at_sensitivity_1: 0.8244 - val_recall_1: 0.9791 - val_precision_1: 0.8986\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.90391\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2906 - accuracy: 0.8863 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9373 - recall_1: 0.9815 - precision_1: 0.8781 - val_loss: 0.2990 - val_accuracy: 0.8914 - val_sensitivity_at_specificity_1: 0.8196 - val_specificity_at_sensitivity_1: 0.8268 - val_recall_1: 0.9853 - val_precision_1: 0.9030\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.90391\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2738 - accuracy: 0.8970 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9442 - recall_1: 0.9832 - precision_1: 0.8895 - val_loss: 0.3134 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8205 - val_specificity_at_sensitivity_1: 0.8116 - val_recall_1: 0.9860 - val_precision_1: 0.8972\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.90391\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2899 - accuracy: 0.8835 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9574 - recall_1: 0.9802 - precision_1: 0.8741 - val_loss: 0.3230 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8076 - val_specificity_at_sensitivity_1: 0.8430 - val_recall_1: 0.9664 - val_precision_1: 0.9098\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.90391\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2764 - accuracy: 0.8950 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9555 - recall_1: 0.9745 - precision_1: 0.8910 - val_loss: 0.3022 - val_accuracy: 0.8953 - val_sensitivity_at_specificity_1: 0.8428 - val_specificity_at_sensitivity_1: 0.8033 - val_recall_1: 0.9845 - val_precision_1: 0.9076\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.90391\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3073 - accuracy: 0.8797 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9405 - recall_1: 0.9877 - precision_1: 0.8683 - val_loss: 0.3072 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.8484 - val_specificity_at_sensitivity_1: 0.8489 - val_recall_1: 0.9886 - val_precision_1: 0.8945\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.90391\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2779 - accuracy: 0.8884 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9532 - recall_1: 0.9774 - precision_1: 0.8826 - val_loss: 0.3136 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8075 - val_specificity_at_sensitivity_1: 0.8182 - val_recall_1: 0.9826 - val_precision_1: 0.9002\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.90391\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3026 - accuracy: 0.8792 - sensitivity_at_specificity_1: 0.9989 - specificity_at_sensitivity_1: 0.9456 - recall_1: 0.9757 - precision_1: 0.8718 - val_loss: 0.3264 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.8267 - val_specificity_at_sensitivity_1: 0.8523 - val_recall_1: 0.9912 - val_precision_1: 0.8855\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.90391\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2590 - accuracy: 0.8952 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9598 - recall_1: 0.9854 - precision_1: 0.8853 - val_loss: 0.3248 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.8266 - val_specificity_at_sensitivity_1: 0.8595 - val_recall_1: 0.9629 - val_precision_1: 0.9148\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.90391\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2978 - accuracy: 0.8915 - sensitivity_at_specificity_1: 0.9982 - specificity_at_sensitivity_1: 0.9526 - recall_1: 0.9744 - precision_1: 0.8873 - val_loss: 0.3069 - val_accuracy: 0.8953 - val_sensitivity_at_specificity_1: 0.8256 - val_specificity_at_sensitivity_1: 0.8271 - val_recall_1: 0.9974 - val_precision_1: 0.8973\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.90391\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3184 - accuracy: 0.8698 - sensitivity_at_specificity_1: 0.9982 - specificity_at_sensitivity_1: 0.9459 - recall_1: 0.9897 - precision_1: 0.8544 - val_loss: 0.3561 - val_accuracy: 0.8617 - val_sensitivity_at_specificity_1: 0.8131 - val_specificity_at_sensitivity_1: 0.8219 - val_recall_1: 0.9568 - val_precision_1: 0.8945\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.90391\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3091 - accuracy: 0.8753 - sensitivity_at_specificity_1: 0.9977 - specificity_at_sensitivity_1: 0.9308 - recall_1: 0.9627 - precision_1: 0.8821 - val_loss: 0.3311 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.8242 - val_specificity_at_sensitivity_1: 0.8581 - val_recall_1: 0.9832 - val_precision_1: 0.8876\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.90391\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2834 - accuracy: 0.8942 - sensitivity_at_specificity_1: 0.9980 - specificity_at_sensitivity_1: 0.9410 - recall_1: 0.9839 - precision_1: 0.8854 - val_loss: 0.3188 - val_accuracy: 0.8844 - val_sensitivity_at_specificity_1: 0.8349 - val_specificity_at_sensitivity_1: 0.8298 - val_recall_1: 0.9903 - val_precision_1: 0.8917\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.90391\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2845 - accuracy: 0.8883 - sensitivity_at_specificity_1: 0.9976 - specificity_at_sensitivity_1: 0.9472 - recall_1: 0.9876 - precision_1: 0.8768 - val_loss: 0.3394 - val_accuracy: 0.8672 - val_sensitivity_at_specificity_1: 0.8250 - val_specificity_at_sensitivity_1: 0.8392 - val_recall_1: 0.9587 - val_precision_1: 0.8986\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.90391\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2827 - accuracy: 0.8890 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9561 - recall_1: 0.9713 - precision_1: 0.8875 - val_loss: 0.3372 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.8093 - val_specificity_at_sensitivity_1: 0.8592 - val_recall_1: 0.9736 - val_precision_1: 0.8964\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.90391\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2841 - accuracy: 0.8896 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9656 - recall_1: 0.9804 - precision_1: 0.8808 - val_loss: 0.3473 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_1: 0.8199 - val_specificity_at_sensitivity_1: 0.8239 - val_recall_1: 0.9561 - val_precision_1: 0.8962\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.90391\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2815 - accuracy: 0.8917 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9479 - recall_1: 0.9815 - precision_1: 0.8832 - val_loss: 0.3344 - val_accuracy: 0.8844 - val_sensitivity_at_specificity_1: 0.7785 - val_specificity_at_sensitivity_1: 0.8333 - val_recall_1: 0.9860 - val_precision_1: 0.8951\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.90391\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2984 - accuracy: 0.8822 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9403 - recall_1: 0.9787 - precision_1: 0.8757 - val_loss: 0.3316 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.7981 - val_specificity_at_sensitivity_1: 0.8088 - val_recall_1: 0.9851 - val_precision_1: 0.8980\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.90391\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2797 - accuracy: 0.8957 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9520 - recall_1: 0.9843 - precision_1: 0.8870 - val_loss: 0.3371 - val_accuracy: 0.8891 - val_sensitivity_at_specificity_1: 0.7836 - val_specificity_at_sensitivity_1: 0.7413 - val_recall_1: 0.9938 - val_precision_1: 0.8933\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.90391\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3177 - accuracy: 0.8751 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9333 - recall_1: 0.9799 - precision_1: 0.8643 - val_loss: 1.3933 - val_accuracy: 0.4227 - val_sensitivity_at_specificity_1: 0.6845 - val_specificity_at_sensitivity_1: 0.6549 - val_recall_1: 0.3796 - val_precision_1: 0.9290\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.90391\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.7189 - accuracy: 0.7245 - sensitivity_at_specificity_1: 0.7801 - specificity_at_sensitivity_1: 0.7436 - recall_1: 0.8281 - precision_1: 0.8147 - val_loss: 0.4091 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.4494 - val_specificity_at_sensitivity_1: 0.4545 - val_recall_1: 0.9991 - val_precision_1: 0.8882\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.90391\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5073 - accuracy: 0.7746 - sensitivity_at_specificity_1: 0.7966 - specificity_at_sensitivity_1: 0.7452 - recall_1: 0.9828 - precision_1: 0.7724 - val_loss: 0.4723 - val_accuracy: 0.8609 - val_sensitivity_at_specificity_1: 0.6166 - val_specificity_at_sensitivity_1: 0.6741 - val_recall_1: 0.9476 - val_precision_1: 0.9019\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.90391\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4119 - accuracy: 0.8350 - sensitivity_at_specificity_1: 0.9545 - specificity_at_sensitivity_1: 0.8362 - recall_1: 0.9679 - precision_1: 0.8345 - val_loss: 0.3584 - val_accuracy: 0.8922 - val_sensitivity_at_specificity_1: 0.6449 - val_specificity_at_sensitivity_1: 0.6260 - val_recall_1: 0.9904 - val_precision_1: 0.8996\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.90391\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3999 - accuracy: 0.8308 - sensitivity_at_specificity_1: 0.9563 - specificity_at_sensitivity_1: 0.8839 - recall_1: 0.9698 - precision_1: 0.8261 - val_loss: 0.3922 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.6658 - val_specificity_at_sensitivity_1: 0.7055 - val_recall_1: 0.9753 - val_precision_1: 0.8898\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.90391\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3945 - accuracy: 0.8368 - sensitivity_at_specificity_1: 0.9611 - specificity_at_sensitivity_1: 0.8818 - recall_1: 0.9744 - precision_1: 0.8305 - val_loss: 0.3463 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.7289 - val_specificity_at_sensitivity_1: 0.7153 - val_recall_1: 0.9938 - val_precision_1: 0.8883\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.90391\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3567 - accuracy: 0.8640 - sensitivity_at_specificity_1: 0.9821 - specificity_at_sensitivity_1: 0.8878 - recall_1: 0.9808 - precision_1: 0.8580 - val_loss: 0.3359 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.7838 - val_specificity_at_sensitivity_1: 0.7746 - val_recall_1: 0.9965 - val_precision_1: 0.8901\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.90391\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3444 - accuracy: 0.8728 - sensitivity_at_specificity_1: 0.9946 - specificity_at_sensitivity_1: 0.9089 - recall_1: 0.9852 - precision_1: 0.8615 - val_loss: 0.3273 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_1: 0.7668 - val_specificity_at_sensitivity_1: 0.7710 - val_recall_1: 0.9930 - val_precision_1: 0.8991\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.90391\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3373 - accuracy: 0.8700 - sensitivity_at_specificity_1: 0.9923 - specificity_at_sensitivity_1: 0.9152 - recall_1: 0.9726 - precision_1: 0.8660 - val_loss: 0.3314 - val_accuracy: 0.8922 - val_sensitivity_at_specificity_1: 0.7532 - val_specificity_at_sensitivity_1: 0.7600 - val_recall_1: 0.9844 - val_precision_1: 0.9045\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.90391\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3429 - accuracy: 0.8652 - sensitivity_at_specificity_1: 0.9937 - specificity_at_sensitivity_1: 0.9201 - recall_1: 0.9767 - precision_1: 0.8580 - val_loss: 0.3199 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_1: 0.7906 - val_specificity_at_sensitivity_1: 0.8217 - val_recall_1: 0.9878 - val_precision_1: 0.9031\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.90391\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3392 - accuracy: 0.8662 - sensitivity_at_specificity_1: 0.9943 - specificity_at_sensitivity_1: 0.9344 - recall_1: 0.9737 - precision_1: 0.8606 - val_loss: 0.3723 - val_accuracy: 0.8656 - val_sensitivity_at_specificity_1: 0.7729 - val_specificity_at_sensitivity_1: 0.7917 - val_recall_1: 0.9577 - val_precision_1: 0.8977\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.90391\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3375 - accuracy: 0.8636 - sensitivity_at_specificity_1: 0.9962 - specificity_at_sensitivity_1: 0.9297 - recall_1: 0.9697 - precision_1: 0.8592 - val_loss: 0.3314 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8250 - val_specificity_at_sensitivity_1: 0.8394 - val_recall_1: 0.9746 - val_precision_1: 0.8969\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.90391\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3404 - accuracy: 0.8674 - sensitivity_at_specificity_1: 0.9873 - specificity_at_sensitivity_1: 0.9171 - recall_1: 0.9796 - precision_1: 0.8613 - val_loss: 0.3161 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.7688 - val_specificity_at_sensitivity_1: 0.8080 - val_recall_1: 0.9766 - val_precision_1: 0.9060\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.90391\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3205 - accuracy: 0.8747 - sensitivity_at_specificity_1: 0.9970 - specificity_at_sensitivity_1: 0.9411 - recall_1: 0.9766 - precision_1: 0.8665 - val_loss: 0.3192 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.8179 - val_specificity_at_sensitivity_1: 0.7832 - val_recall_1: 0.9956 - val_precision_1: 0.8906\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.90391\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3467 - accuracy: 0.8658 - sensitivity_at_specificity_1: 0.9961 - specificity_at_sensitivity_1: 0.8964 - recall_1: 0.9783 - precision_1: 0.8550 - val_loss: 0.3315 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8149 - val_specificity_at_sensitivity_1: 0.8143 - val_recall_1: 0.9825 - val_precision_1: 0.8931\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.90391\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3284 - accuracy: 0.8724 - sensitivity_at_specificity_1: 0.9938 - specificity_at_sensitivity_1: 0.9108 - recall_1: 0.9816 - precision_1: 0.8637 - val_loss: 0.3281 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.8098 - val_specificity_at_sensitivity_1: 0.8284 - val_recall_1: 0.9773 - val_precision_1: 0.8982\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.90391\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3091 - accuracy: 0.8771 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9333 - recall_1: 0.9784 - precision_1: 0.8719 - val_loss: 0.3607 - val_accuracy: 0.8570 - val_sensitivity_at_specificity_1: 0.8042 - val_specificity_at_sensitivity_1: 0.8309 - val_recall_1: 0.9432 - val_precision_1: 0.9014\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.90391\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3294 - accuracy: 0.8607 - sensitivity_at_specificity_1: 0.9958 - specificity_at_sensitivity_1: 0.9268 - recall_1: 0.9497 - precision_1: 0.8702 - val_loss: 0.3804 - val_accuracy: 0.8602 - val_sensitivity_at_specificity_1: 0.7570 - val_specificity_at_sensitivity_1: 0.8214 - val_recall_1: 0.9588 - val_precision_1: 0.8922\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.90391\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3311 - accuracy: 0.8706 - sensitivity_at_specificity_1: 0.9964 - specificity_at_sensitivity_1: 0.9017 - recall_1: 0.9767 - precision_1: 0.8649 - val_loss: 0.3237 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.8106 - val_specificity_at_sensitivity_1: 0.7836 - val_recall_1: 0.9895 - val_precision_1: 0.8964\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.90391\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3089 - accuracy: 0.8813 - sensitivity_at_specificity_1: 0.9981 - specificity_at_sensitivity_1: 0.9341 - recall_1: 0.9898 - precision_1: 0.8698 - val_loss: 0.3218 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.8377 - val_specificity_at_sensitivity_1: 0.8429 - val_recall_1: 0.9789 - val_precision_1: 0.8978\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.90391\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2952 - accuracy: 0.8852 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9452 - recall_1: 0.9789 - precision_1: 0.8786 - val_loss: 0.3144 - val_accuracy: 0.8930 - val_sensitivity_at_specificity_1: 0.8037 - val_specificity_at_sensitivity_1: 0.7985 - val_recall_1: 0.9948 - val_precision_1: 0.8969\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.90391\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.2757 - accuracy: 0.9000 - sensitivity_at_specificity_1: 0.9989 - specificity_at_sensitivity_1: 0.9461 - recall_1: 0.9884 - precision_1: 0.8904 - val_loss: 0.3153 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_1: 0.7647 - val_specificity_at_sensitivity_1: 0.8145 - val_recall_1: 0.9827 - val_precision_1: 0.9073\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.90391\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2854 - accuracy: 0.8953 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9487 - recall_1: 0.9883 - precision_1: 0.8830 - val_loss: 0.3344 - val_accuracy: 0.8672 - val_sensitivity_at_specificity_1: 0.8236 - val_specificity_at_sensitivity_1: 0.8630 - val_recall_1: 0.9683 - val_precision_1: 0.8912\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.90391\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2967 - accuracy: 0.8830 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9545 - recall_1: 0.9681 - precision_1: 0.8796 - val_loss: 0.3297 - val_accuracy: 0.8891 - val_sensitivity_at_specificity_1: 0.7663 - val_specificity_at_sensitivity_1: 0.7970 - val_recall_1: 0.9861 - val_precision_1: 0.8998\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.90391\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3024 - accuracy: 0.8875 - sensitivity_at_specificity_1: 0.9980 - specificity_at_sensitivity_1: 0.9253 - recall_1: 0.9832 - precision_1: 0.8795 - val_loss: 0.2977 - val_accuracy: 0.8914 - val_sensitivity_at_specificity_1: 0.8172 - val_specificity_at_sensitivity_1: 0.8522 - val_recall_1: 0.9725 - val_precision_1: 0.9137\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.90391\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3104 - accuracy: 0.8841 - sensitivity_at_specificity_1: 0.9940 - specificity_at_sensitivity_1: 0.9414 - recall_1: 0.9762 - precision_1: 0.8800 - val_loss: 0.3229 - val_accuracy: 0.8922 - val_sensitivity_at_specificity_1: 0.7682 - val_specificity_at_sensitivity_1: 0.8594 - val_recall_1: 0.9870 - val_precision_1: 0.9024\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.90391\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2996 - accuracy: 0.8850 - sensitivity_at_specificity_1: 0.9989 - specificity_at_sensitivity_1: 0.9372 - recall_1: 0.9856 - precision_1: 0.8768 - val_loss: 0.3274 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.8212 - val_specificity_at_sensitivity_1: 0.8273 - val_recall_1: 0.9763 - val_precision_1: 0.8948\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.90391\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2992 - accuracy: 0.8796 - sensitivity_at_specificity_1: 0.9987 - specificity_at_sensitivity_1: 0.9552 - recall_1: 0.9714 - precision_1: 0.8772 - val_loss: 0.3449 - val_accuracy: 0.8695 - val_sensitivity_at_specificity_1: 0.8128 - val_specificity_at_sensitivity_1: 0.8095 - val_recall_1: 0.9541 - val_precision_1: 0.9062\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.90391\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3028 - accuracy: 0.8865 - sensitivity_at_specificity_1: 0.9947 - specificity_at_sensitivity_1: 0.9525 - recall_1: 0.9686 - precision_1: 0.8891 - val_loss: 0.3333 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.7990 - val_specificity_at_sensitivity_1: 0.8235 - val_recall_1: 0.9755 - val_precision_1: 0.8986\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.90391\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2991 - accuracy: 0.8836 - sensitivity_at_specificity_1: 0.9981 - specificity_at_sensitivity_1: 0.9499 - recall_1: 0.9858 - precision_1: 0.8729 - val_loss: 0.3519 - val_accuracy: 0.8664 - val_sensitivity_at_specificity_1: 0.8014 - val_specificity_at_sensitivity_1: 0.8451 - val_recall_1: 0.9649 - val_precision_1: 0.8934\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.90391\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3008 - accuracy: 0.8779 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9616 - recall_1: 0.9762 - precision_1: 0.8715 - val_loss: 0.3273 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.8304 - val_specificity_at_sensitivity_1: 0.8581 - val_recall_1: 0.9753 - val_precision_1: 0.8932\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.90391\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3115 - accuracy: 0.8769 - sensitivity_at_specificity_1: 0.9959 - specificity_at_sensitivity_1: 0.9389 - recall_1: 0.9841 - precision_1: 0.8671 - val_loss: 0.3102 - val_accuracy: 0.8953 - val_sensitivity_at_specificity_1: 0.8203 - val_specificity_at_sensitivity_1: 0.7734 - val_recall_1: 0.9905 - val_precision_1: 0.9027\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.90391\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2926 - accuracy: 0.8861 - sensitivity_at_specificity_1: 0.9971 - specificity_at_sensitivity_1: 0.9464 - recall_1: 0.9861 - precision_1: 0.8756 - val_loss: 0.3381 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.8307 - val_specificity_at_sensitivity_1: 0.8288 - val_recall_1: 0.9674 - val_precision_1: 0.8955\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.90391\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3070 - accuracy: 0.8814 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9332 - recall_1: 0.9699 - precision_1: 0.8782 - val_loss: 0.3270 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.8336 - val_specificity_at_sensitivity_1: 0.8542 - val_recall_1: 0.9850 - val_precision_1: 0.8916\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.90391\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2823 - accuracy: 0.8906 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9435 - recall_1: 0.9867 - precision_1: 0.8800 - val_loss: 0.3326 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.8279 - val_specificity_at_sensitivity_1: 0.8367 - val_recall_1: 0.9726 - val_precision_1: 0.8930\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.90391\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2823 - accuracy: 0.8865 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9678 - recall_1: 0.9776 - precision_1: 0.8773 - val_loss: 0.3284 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.7866 - val_specificity_at_sensitivity_1: 0.7727 - val_recall_1: 0.9747 - val_precision_1: 0.9024\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.90391\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2767 - accuracy: 0.8927 - sensitivity_at_specificity_1: 0.9993 - specificity_at_sensitivity_1: 0.9508 - recall_1: 0.9777 - precision_1: 0.8865 - val_loss: 0.3193 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8182 - val_specificity_at_sensitivity_1: 0.8088 - val_recall_1: 0.9790 - val_precision_1: 0.8960\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.90391\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2688 - accuracy: 0.8951 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9649 - recall_1: 0.9829 - precision_1: 0.8843 - val_loss: 0.3399 - val_accuracy: 0.8719 - val_sensitivity_at_specificity_1: 0.8016 - val_specificity_at_sensitivity_1: 0.8298 - val_recall_1: 0.9701 - val_precision_1: 0.8947\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.90391\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2791 - accuracy: 0.8963 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9455 - recall_1: 0.9804 - precision_1: 0.8906 - val_loss: 0.3145 - val_accuracy: 0.8891 - val_sensitivity_at_specificity_1: 0.8269 - val_specificity_at_sensitivity_1: 0.8309 - val_recall_1: 0.9895 - val_precision_1: 0.8970\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.90391\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2839 - accuracy: 0.8930 - sensitivity_at_specificity_1: 0.9987 - specificity_at_sensitivity_1: 0.9500 - recall_1: 0.9825 - precision_1: 0.8851 - val_loss: 0.3095 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_1: 0.8114 - val_specificity_at_sensitivity_1: 0.7500 - val_recall_1: 0.9827 - val_precision_1: 0.9073\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.90391\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2795 - accuracy: 0.8887 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9549 - recall_1: 0.9735 - precision_1: 0.8829 - val_loss: 0.3184 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.8341 - val_specificity_at_sensitivity_1: 0.8450 - val_recall_1: 0.9809 - val_precision_1: 0.9032\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.90391\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2557 - accuracy: 0.9016 - sensitivity_at_specificity_1: 0.9991 - specificity_at_sensitivity_1: 0.9677 - recall_1: 0.9772 - precision_1: 0.8986 - val_loss: 0.3612 - val_accuracy: 0.8594 - val_sensitivity_at_specificity_1: 0.8169 - val_specificity_at_sensitivity_1: 0.8125 - val_recall_1: 0.9481 - val_precision_1: 0.8990\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.90391\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2747 - accuracy: 0.8891 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9596 - recall_1: 0.9762 - precision_1: 0.8844 - val_loss: 0.3536 - val_accuracy: 0.8594 - val_sensitivity_at_specificity_1: 0.7926 - val_specificity_at_sensitivity_1: 0.8435 - val_recall_1: 0.9585 - val_precision_1: 0.8909\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.90391\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2838 - accuracy: 0.8868 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9597 - recall_1: 0.9680 - precision_1: 0.8876 - val_loss: 0.3192 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8530 - val_specificity_at_sensitivity_1: 0.8472 - val_recall_1: 0.9868 - val_precision_1: 0.8925\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.90391\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2894 - accuracy: 0.8905 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9410 - recall_1: 0.9859 - precision_1: 0.8811 - val_loss: 0.3149 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.8260 - val_specificity_at_sensitivity_1: 0.8456 - val_recall_1: 0.9808 - val_precision_1: 0.8969\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.90391\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3092 - accuracy: 0.8756 - sensitivity_at_specificity_1: 0.9986 - specificity_at_sensitivity_1: 0.9523 - recall_1: 0.9671 - precision_1: 0.8739 - val_loss: 0.3171 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.7974 - val_specificity_at_sensitivity_1: 0.8286 - val_recall_1: 0.9904 - val_precision_1: 0.8946\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.90391\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3030 - accuracy: 0.8804 - sensitivity_at_specificity_1: 0.9983 - specificity_at_sensitivity_1: 0.9347 - recall_1: 0.9776 - precision_1: 0.8753 - val_loss: 0.3159 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.8211 - val_specificity_at_sensitivity_1: 0.8134 - val_recall_1: 0.9825 - val_precision_1: 0.8958\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.90391\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2953 - accuracy: 0.8809 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9529 - recall_1: 0.9786 - precision_1: 0.8725 - val_loss: 0.3550 - val_accuracy: 0.8633 - val_sensitivity_at_specificity_1: 0.8003 - val_specificity_at_sensitivity_1: 0.8496 - val_recall_1: 0.9512 - val_precision_1: 0.9017\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.90391\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3191 - accuracy: 0.8698 - sensitivity_at_specificity_1: 0.9946 - specificity_at_sensitivity_1: 0.9448 - recall_1: 0.9627 - precision_1: 0.8713 - val_loss: 0.3530 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.7688 - val_specificity_at_sensitivity_1: 0.7985 - val_recall_1: 0.9729 - val_precision_1: 0.8999\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.90391\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2996 - accuracy: 0.8865 - sensitivity_at_specificity_1: 0.9969 - specificity_at_sensitivity_1: 0.9430 - recall_1: 0.9840 - precision_1: 0.8777 - val_loss: 0.3274 - val_accuracy: 0.8719 - val_sensitivity_at_specificity_1: 0.8051 - val_specificity_at_sensitivity_1: 0.8382 - val_recall_1: 0.9633 - val_precision_1: 0.9003\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.90391\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2928 - accuracy: 0.8884 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9395 - recall_1: 0.9811 - precision_1: 0.8807 - val_loss: 0.3199 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.7883 - val_specificity_at_sensitivity_1: 0.7727 - val_recall_1: 0.9852 - val_precision_1: 0.8990\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.90391\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3003 - accuracy: 0.8814 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9471 - recall_1: 0.9867 - precision_1: 0.8690 - val_loss: 0.2882 - val_accuracy: 0.8977 - val_sensitivity_at_specificity_1: 0.8467 - val_specificity_at_sensitivity_1: 0.8992 - val_recall_1: 0.9836 - val_precision_1: 0.9107\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.90391\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2616 - accuracy: 0.8945 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9817 - recall_1: 0.9831 - precision_1: 0.8865 - val_loss: 0.3440 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.8164 - val_specificity_at_sensitivity_1: 0.8095 - val_recall_1: 0.9779 - val_precision_1: 0.8900\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.90391\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2837 - accuracy: 0.8854 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9512 - recall_1: 0.9817 - precision_1: 0.8768 - val_loss: 0.3149 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.8266 - val_specificity_at_sensitivity_1: 0.8478 - val_recall_1: 0.9834 - val_precision_1: 0.8984\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.90391\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2810 - accuracy: 0.8834 - sensitivity_at_specificity_1: 0.9983 - specificity_at_sensitivity_1: 0.9714 - recall_1: 0.9741 - precision_1: 0.8798 - val_loss: 0.3145 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8603 - val_specificity_at_sensitivity_1: 0.8658 - val_recall_1: 0.9876 - val_precision_1: 0.8886\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.90391\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3294 - accuracy: 0.8761 - sensitivity_at_specificity_1: 0.9982 - specificity_at_sensitivity_1: 0.9251 - recall_1: 0.9824 - precision_1: 0.8619 - val_loss: 0.3382 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.8322 - val_specificity_at_sensitivity_1: 0.7721 - val_recall_1: 0.9659 - val_precision_1: 0.8998\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.90391\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3007 - accuracy: 0.8784 - sensitivity_at_specificity_1: 0.9982 - specificity_at_sensitivity_1: 0.9498 - recall_1: 0.9706 - precision_1: 0.8724 - val_loss: 0.3371 - val_accuracy: 0.8758 - val_sensitivity_at_specificity_1: 0.7991 - val_specificity_at_sensitivity_1: 0.8207 - val_recall_1: 0.9762 - val_precision_1: 0.8935\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.90391\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2629 - accuracy: 0.8983 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9667 - recall_1: 0.9826 - precision_1: 0.8909 - val_loss: 0.3476 - val_accuracy: 0.8562 - val_sensitivity_at_specificity_1: 0.8288 - val_specificity_at_sensitivity_1: 0.8369 - val_recall_1: 0.9464 - val_precision_1: 0.8976\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.90391\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2736 - accuracy: 0.8950 - sensitivity_at_specificity_1: 0.9991 - specificity_at_sensitivity_1: 0.9513 - recall_1: 0.9701 - precision_1: 0.8973 - val_loss: 0.3139 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.8303 - val_specificity_at_sensitivity_1: 0.8394 - val_recall_1: 0.9860 - val_precision_1: 0.8980\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.90391\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2968 - accuracy: 0.8743 - sensitivity_at_specificity_1: 0.9977 - specificity_at_sensitivity_1: 0.9466 - recall_1: 0.9773 - precision_1: 0.8672 - val_loss: 0.3095 - val_accuracy: 0.8922 - val_sensitivity_at_specificity_1: 0.8463 - val_specificity_at_sensitivity_1: 0.8296 - val_recall_1: 0.9956 - val_precision_1: 0.8955\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.90391\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3109 - accuracy: 0.8794 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9446 - recall_1: 0.9828 - precision_1: 0.8692 - val_loss: 0.3226 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.7847 - val_specificity_at_sensitivity_1: 0.8310 - val_recall_1: 0.9877 - val_precision_1: 0.8928\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.90391\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2675 - accuracy: 0.8914 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9634 - recall_1: 0.9833 - precision_1: 0.8844 - val_loss: 0.3148 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.8271 - val_specificity_at_sensitivity_1: 0.8444 - val_recall_1: 0.9825 - val_precision_1: 0.8986\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.90391\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2898 - accuracy: 0.8849 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9561 - recall_1: 0.9832 - precision_1: 0.8744 - val_loss: 0.2957 - val_accuracy: 0.8984 - val_sensitivity_at_specificity_1: 0.8134 - val_specificity_at_sensitivity_1: 0.8906 - val_recall_1: 0.9913 - val_precision_1: 0.9049\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.90391\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2668 - accuracy: 0.8943 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9643 - recall_1: 0.9825 - precision_1: 0.8861 - val_loss: 0.2889 - val_accuracy: 0.8961 - val_sensitivity_at_specificity_1: 0.8397 - val_specificity_at_sensitivity_1: 0.8016 - val_recall_1: 0.9879 - val_precision_1: 0.9055\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.90391\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2834 - accuracy: 0.8896 - sensitivity_at_specificity_1: 0.9975 - specificity_at_sensitivity_1: 0.9481 - recall_1: 0.9845 - precision_1: 0.8826 - val_loss: 0.3246 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.8163 - val_specificity_at_sensitivity_1: 0.7817 - val_recall_1: 0.9868 - val_precision_1: 0.8913\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.90391\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2712 - accuracy: 0.8911 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9597 - recall_1: 0.9843 - precision_1: 0.8839 - val_loss: 0.3238 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.8301 - val_specificity_at_sensitivity_1: 0.8194 - val_recall_1: 0.9886 - val_precision_1: 0.8941\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.90391\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2676 - accuracy: 0.9007 - sensitivity_at_specificity_1: 0.9986 - specificity_at_sensitivity_1: 0.9582 - recall_1: 0.9829 - precision_1: 0.8912 - val_loss: 0.3191 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.8310 - val_specificity_at_sensitivity_1: 0.8841 - val_recall_1: 0.9799 - val_precision_1: 0.8966\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.90391\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2872 - accuracy: 0.8927 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9430 - recall_1: 0.9886 - precision_1: 0.8808 - val_loss: 0.3341 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.8272 - val_specificity_at_sensitivity_1: 0.7929 - val_recall_1: 0.9807 - val_precision_1: 0.8951\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.90391\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2645 - accuracy: 0.8905 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9698 - recall_1: 0.9780 - precision_1: 0.8868 - val_loss: 0.3463 - val_accuracy: 0.8703 - val_sensitivity_at_specificity_1: 0.8172 - val_specificity_at_sensitivity_1: 0.8521 - val_recall_1: 0.9605 - val_precision_1: 0.9003\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.90391\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2852 - accuracy: 0.8811 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9644 - recall_1: 0.9705 - precision_1: 0.8790 - val_loss: 0.3188 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.8374 - val_specificity_at_sensitivity_1: 0.7984 - val_recall_1: 0.9671 - val_precision_1: 0.9067\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.90391\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2657 - accuracy: 0.8905 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9679 - recall_1: 0.9732 - precision_1: 0.8894 - val_loss: 0.3078 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.8687 - val_specificity_at_sensitivity_1: 0.8759 - val_recall_1: 0.9868 - val_precision_1: 0.8931\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.90391\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2743 - accuracy: 0.8909 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9667 - recall_1: 0.9842 - precision_1: 0.8811 - val_loss: 0.3296 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.7845 - val_specificity_at_sensitivity_1: 0.8060 - val_recall_1: 0.9721 - val_precision_1: 0.9013\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.90391\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2826 - accuracy: 0.8902 - sensitivity_at_specificity_1: 0.9986 - specificity_at_sensitivity_1: 0.9431 - recall_1: 0.9710 - precision_1: 0.8897 - val_loss: 0.3091 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_1: 0.8087 - val_specificity_at_sensitivity_1: 0.7615 - val_recall_1: 0.9913 - val_precision_1: 0.9005\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.90391\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2982 - accuracy: 0.8823 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9456 - recall_1: 0.9869 - precision_1: 0.8697 - val_loss: 0.2951 - val_accuracy: 0.8930 - val_sensitivity_at_specificity_1: 0.8423 - val_specificity_at_sensitivity_1: 0.8333 - val_recall_1: 0.9861 - val_precision_1: 0.9034\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.90391\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2830 - accuracy: 0.8885 - sensitivity_at_specificity_1: 0.9983 - specificity_at_sensitivity_1: 0.9476 - recall_1: 0.9768 - precision_1: 0.8845 - val_loss: 0.3059 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.8509 - val_specificity_at_sensitivity_1: 0.8421 - val_recall_1: 0.9808 - val_precision_1: 0.9029\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.90391\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2845 - accuracy: 0.8936 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9395 - recall_1: 0.9792 - precision_1: 0.8880 - val_loss: 0.3316 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.8358 - val_specificity_at_sensitivity_1: 0.8296 - val_recall_1: 0.9581 - val_precision_1: 0.9074\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.90391\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2771 - accuracy: 0.8839 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9710 - recall_1: 0.9660 - precision_1: 0.8825 - val_loss: 0.3312 - val_accuracy: 0.8719 - val_sensitivity_at_specificity_1: 0.8453 - val_specificity_at_sensitivity_1: 0.8235 - val_recall_1: 0.9633 - val_precision_1: 0.9003\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.90391\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2786 - accuracy: 0.8886 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9612 - recall_1: 0.9776 - precision_1: 0.8822 - val_loss: 0.3437 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.8091 - val_specificity_at_sensitivity_1: 0.7899 - val_recall_1: 0.9641 - val_precision_1: 0.9002\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.90391\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2896 - accuracy: 0.8851 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9452 - recall_1: 0.9773 - precision_1: 0.8787 - val_loss: 0.3154 - val_accuracy: 0.8922 - val_sensitivity_at_specificity_1: 0.8202 - val_specificity_at_sensitivity_1: 0.7910 - val_recall_1: 0.9921 - val_precision_1: 0.8981\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.90391\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2642 - accuracy: 0.8902 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9617 - recall_1: 0.9895 - precision_1: 0.8771 - val_loss: 0.3117 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.8319 - val_specificity_at_sensitivity_1: 0.8681 - val_recall_1: 0.9859 - val_precision_1: 0.8910\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.90391\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2737 - accuracy: 0.8930 - sensitivity_at_specificity_1: 0.9991 - specificity_at_sensitivity_1: 0.9477 - recall_1: 0.9788 - precision_1: 0.8858 - val_loss: 0.3007 - val_accuracy: 0.8961 - val_sensitivity_at_specificity_1: 0.8609 - val_specificity_at_sensitivity_1: 0.8231 - val_recall_1: 0.9922 - val_precision_1: 0.9020\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.90391\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2558 - accuracy: 0.8937 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9707 - recall_1: 0.9787 - precision_1: 0.8876 - val_loss: 0.3467 - val_accuracy: 0.8648 - val_sensitivity_at_specificity_1: 0.8248 - val_specificity_at_sensitivity_1: 0.7917 - val_recall_1: 0.9621 - val_precision_1: 0.8937\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.90391\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2609 - accuracy: 0.8893 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9850 - recall_1: 0.9733 - precision_1: 0.8887 - val_loss: 0.3299 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.8248 - val_specificity_at_sensitivity_1: 0.8125 - val_recall_1: 0.9762 - val_precision_1: 0.8922\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.90391\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2675 - accuracy: 0.8895 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9610 - recall_1: 0.9767 - precision_1: 0.8839 - val_loss: 0.3006 - val_accuracy: 0.8945 - val_sensitivity_at_specificity_1: 0.8615 - val_specificity_at_sensitivity_1: 0.8333 - val_recall_1: 0.9895 - val_precision_1: 0.9023\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.90391\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2811 - accuracy: 0.8879 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9542 - recall_1: 0.9846 - precision_1: 0.8789 - val_loss: 0.3068 - val_accuracy: 0.8914 - val_sensitivity_at_specificity_1: 0.8410 - val_specificity_at_sensitivity_1: 0.8148 - val_recall_1: 0.9921 - val_precision_1: 0.8973\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.90391\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2703 - accuracy: 0.8952 - sensitivity_at_specificity_1: 0.9989 - specificity_at_sensitivity_1: 0.9525 - recall_1: 0.9738 - precision_1: 0.8935 - val_loss: 0.3036 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.8630 - val_specificity_at_sensitivity_1: 0.8507 - val_recall_1: 0.9808 - val_precision_1: 0.9028\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.90391\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2534 - accuracy: 0.8987 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9708 - recall_1: 0.9802 - precision_1: 0.8926 - val_loss: 0.3415 - val_accuracy: 0.8781 - val_sensitivity_at_specificity_1: 0.8372 - val_specificity_at_sensitivity_1: 0.8000 - val_recall_1: 0.9823 - val_precision_1: 0.8909\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.90391\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2677 - accuracy: 0.8955 - sensitivity_at_specificity_1: 0.9993 - specificity_at_sensitivity_1: 0.9598 - recall_1: 0.9823 - precision_1: 0.8877 - val_loss: 0.3023 - val_accuracy: 0.8930 - val_sensitivity_at_specificity_1: 0.8415 - val_specificity_at_sensitivity_1: 0.8761 - val_recall_1: 0.9692 - val_precision_1: 0.9180\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.90391\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2703 - accuracy: 0.8901 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9735 - recall_1: 0.9681 - precision_1: 0.8882 - val_loss: 0.3198 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.8385 - val_specificity_at_sensitivity_1: 0.8227 - val_recall_1: 0.9781 - val_precision_1: 0.8984\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.90391\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2632 - accuracy: 0.8913 - sensitivity_at_specificity_1: 0.9993 - specificity_at_sensitivity_1: 0.9716 - recall_1: 0.9615 - precision_1: 0.8995 - val_loss: 0.2903 - val_accuracy: 0.8977 - val_sensitivity_at_specificity_1: 0.8466 - val_specificity_at_sensitivity_1: 0.8095 - val_recall_1: 0.9913 - val_precision_1: 0.9043\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.90391\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2712 - accuracy: 0.8974 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9629 - recall_1: 0.9882 - precision_1: 0.8825 - val_loss: 0.3479 - val_accuracy: 0.8703 - val_sensitivity_at_specificity_1: 0.8325 - val_specificity_at_sensitivity_1: 0.7945 - val_recall_1: 0.9603 - val_precision_1: 0.9000\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.90391\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2759 - accuracy: 0.8861 - sensitivity_at_specificity_1: 0.9991 - specificity_at_sensitivity_1: 0.9611 - recall_1: 0.9562 - precision_1: 0.8962 - val_loss: 0.3536 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.8047 - val_specificity_at_sensitivity_1: 0.8696 - val_recall_1: 0.9658 - val_precision_1: 0.8975\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.90391\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3049 - accuracy: 0.8783 - sensitivity_at_specificity_1: 0.9947 - specificity_at_sensitivity_1: 0.9533 - recall_1: 0.9734 - precision_1: 0.8743 - val_loss: 0.3377 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.8219 - val_specificity_at_sensitivity_1: 0.8429 - val_recall_1: 0.9658 - val_precision_1: 0.8995\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.90391\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2798 - accuracy: 0.8971 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9482 - recall_1: 0.9749 - precision_1: 0.8958 - val_loss: 0.3119 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.8134 - val_specificity_at_sensitivity_1: 0.8045 - val_recall_1: 0.9843 - val_precision_1: 0.9003\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.90391\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2836 - accuracy: 0.8859 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9401 - recall_1: 0.9742 - precision_1: 0.8802 - val_loss: 0.3231 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8480 - val_specificity_at_sensitivity_1: 0.7407 - val_recall_1: 0.9852 - val_precision_1: 0.8981\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.90391\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2781 - accuracy: 0.8831 - sensitivity_at_specificity_1: 0.9985 - specificity_at_sensitivity_1: 0.9597 - recall_1: 0.9762 - precision_1: 0.8797 - val_loss: 0.3163 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.8468 - val_specificity_at_sensitivity_1: 0.7986 - val_recall_1: 0.9886 - val_precision_1: 0.8941\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.90391\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3039 - accuracy: 0.8768 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9325 - recall_1: 0.9744 - precision_1: 0.8719 - val_loss: 0.3335 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.8316 - val_specificity_at_sensitivity_1: 0.8158 - val_recall_1: 0.9778 - val_precision_1: 0.8888\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.90391\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2784 - accuracy: 0.8799 - sensitivity_at_specificity_1: 0.9993 - specificity_at_sensitivity_1: 0.9613 - recall_1: 0.9661 - precision_1: 0.8792 - val_loss: 0.3379 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.8216 - val_specificity_at_sensitivity_1: 0.8015 - val_recall_1: 0.9539 - val_precision_1: 0.9095\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.90391\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2487 - accuracy: 0.8994 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9746 - recall_1: 0.9692 - precision_1: 0.9009 - val_loss: 0.3484 - val_accuracy: 0.8664 - val_sensitivity_at_specificity_1: 0.8225 - val_specificity_at_sensitivity_1: 0.8028 - val_recall_1: 0.9622 - val_precision_1: 0.8953\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.90391\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2881 - accuracy: 0.8869 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9500 - recall_1: 0.9792 - precision_1: 0.8783 - val_loss: 0.3382 - val_accuracy: 0.8695 - val_sensitivity_at_specificity_1: 0.8060 - val_specificity_at_sensitivity_1: 0.8085 - val_recall_1: 0.9614 - val_precision_1: 0.8990\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.90391\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2749 - accuracy: 0.8933 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9501 - recall_1: 0.9772 - precision_1: 0.8875 - val_loss: 0.3144 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.8375 - val_specificity_at_sensitivity_1: 0.8760 - val_recall_1: 0.9696 - val_precision_1: 0.9073\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.90391\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2652 - accuracy: 0.8960 - sensitivity_at_specificity_1: 0.9986 - specificity_at_sensitivity_1: 0.9680 - recall_1: 0.9693 - precision_1: 0.8962 - val_loss: 0.3203 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.8468 - val_specificity_at_sensitivity_1: 0.8397 - val_recall_1: 0.9652 - val_precision_1: 0.9075\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.90391\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2508 - accuracy: 0.9061 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9667 - recall_1: 0.9789 - precision_1: 0.9040 - val_loss: 0.3511 - val_accuracy: 0.8695 - val_sensitivity_at_specificity_1: 0.8140 - val_specificity_at_sensitivity_1: 0.8548 - val_recall_1: 0.9343 - val_precision_1: 0.9223\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.90391\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3056 - accuracy: 0.8788 - sensitivity_at_specificity_1: 0.9982 - specificity_at_sensitivity_1: 0.9399 - recall_1: 0.9488 - precision_1: 0.8923 - val_loss: 0.3440 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.8306 - val_specificity_at_sensitivity_1: 0.8296 - val_recall_1: 0.9607 - val_precision_1: 0.9016\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.90391\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2657 - accuracy: 0.9020 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9471 - recall_1: 0.9775 - precision_1: 0.9004 - val_loss: 0.3603 - val_accuracy: 0.8648 - val_sensitivity_at_specificity_1: 0.7940 - val_specificity_at_sensitivity_1: 0.8345 - val_recall_1: 0.9483 - val_precision_1: 0.9047\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.90391\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2728 - accuracy: 0.8893 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9580 - recall_1: 0.9695 - precision_1: 0.8906 - val_loss: 0.3020 - val_accuracy: 0.8898 - val_sensitivity_at_specificity_1: 0.8343 - val_specificity_at_sensitivity_1: 0.8504 - val_recall_1: 0.9818 - val_precision_1: 0.9042\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.90391\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2656 - accuracy: 0.9001 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9550 - recall_1: 0.9869 - precision_1: 0.8902 - val_loss: 0.3178 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.8021 - val_specificity_at_sensitivity_1: 0.8271 - val_recall_1: 0.9826 - val_precision_1: 0.8987\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.90391\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2497 - accuracy: 0.9021 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9633 - recall_1: 0.9838 - precision_1: 0.8938 - val_loss: 0.3115 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.7974 - val_specificity_at_sensitivity_1: 0.8231 - val_recall_1: 0.9757 - val_precision_1: 0.8998\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.90391\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2289 - accuracy: 0.9050 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9852 - recall_1: 0.9777 - precision_1: 0.9004 - val_loss: 0.3215 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8256 - val_specificity_at_sensitivity_1: 0.8421 - val_recall_1: 0.9799 - val_precision_1: 0.8985\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.90391\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2788 - accuracy: 0.8851 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9484 - recall_1: 0.9693 - precision_1: 0.8876 - val_loss: 0.3154 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.8578 - val_specificity_at_sensitivity_1: 0.8504 - val_recall_1: 0.9636 - val_precision_1: 0.9092\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.90391\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2855 - accuracy: 0.8925 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9399 - recall_1: 0.9779 - precision_1: 0.8874 - val_loss: 0.3113 - val_accuracy: 0.8906 - val_sensitivity_at_specificity_1: 0.8425 - val_specificity_at_sensitivity_1: 0.8321 - val_recall_1: 0.9921 - val_precision_1: 0.8964\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.90391\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2710 - accuracy: 0.8904 - sensitivity_at_specificity_1: 0.9989 - specificity_at_sensitivity_1: 0.9638 - recall_1: 0.9822 - precision_1: 0.8794 - val_loss: 0.3073 - val_accuracy: 0.8992 - val_sensitivity_at_specificity_1: 0.7965 - val_specificity_at_sensitivity_1: 0.8000 - val_recall_1: 0.9957 - val_precision_1: 0.9023\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.90391\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2586 - accuracy: 0.9032 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9696 - recall_1: 0.9849 - precision_1: 0.8967 - val_loss: 0.3154 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.8285 - val_specificity_at_sensitivity_1: 0.8321 - val_recall_1: 0.9834 - val_precision_1: 0.8985\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.90391\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2717 - accuracy: 0.8871 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9620 - recall_1: 0.9795 - precision_1: 0.8765 - val_loss: 0.3111 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.8462 - val_specificity_at_sensitivity_1: 0.8062 - val_recall_1: 0.9783 - val_precision_1: 0.9051\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.90391\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2300 - accuracy: 0.9100 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9715 - recall_1: 0.9787 - precision_1: 0.9097 - val_loss: 0.3227 - val_accuracy: 0.8758 - val_sensitivity_at_specificity_1: 0.8364 - val_specificity_at_sensitivity_1: 0.8467 - val_recall_1: 0.9676 - val_precision_1: 0.9007\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.90391\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2449 - accuracy: 0.9088 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9591 - recall_1: 0.9766 - precision_1: 0.9077 - val_loss: 0.2913 - val_accuracy: 0.8914 - val_sensitivity_at_specificity_1: 0.8646 - val_specificity_at_sensitivity_1: 0.8438 - val_recall_1: 0.9826 - val_precision_1: 0.9049\n",
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.90391\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2530 - accuracy: 0.8958 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9665 - recall_1: 0.9733 - precision_1: 0.8923 - val_loss: 0.3038 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8407 - val_specificity_at_sensitivity_1: 0.8321 - val_recall_1: 0.9809 - val_precision_1: 0.9016\n",
      "\n",
      "Epoch 00356: val_accuracy did not improve from 0.90391\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2687 - accuracy: 0.8931 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9671 - recall_1: 0.9721 - precision_1: 0.8881 - val_loss: 0.3099 - val_accuracy: 0.8930 - val_sensitivity_at_specificity_1: 0.8396 - val_specificity_at_sensitivity_1: 0.8345 - val_recall_1: 0.9921 - val_precision_1: 0.8984\n",
      "\n",
      "Epoch 00357: val_accuracy did not improve from 0.90391\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.2749 - accuracy: 0.8897 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9688 - recall_1: 0.9822 - precision_1: 0.8770 - val_loss: 0.3487 - val_accuracy: 0.8609 - val_sensitivity_at_specificity_1: 0.8171 - val_specificity_at_sensitivity_1: 0.8613 - val_recall_1: 0.9423 - val_precision_1: 0.9058\n",
      "\n",
      "Epoch 00358: val_accuracy did not improve from 0.90391\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2528 - accuracy: 0.9007 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9657 - recall_1: 0.9682 - precision_1: 0.9030 - val_loss: 0.3256 - val_accuracy: 0.8781 - val_sensitivity_at_specificity_1: 0.8386 - val_specificity_at_sensitivity_1: 0.8429 - val_recall_1: 0.9763 - val_precision_1: 0.8961\n",
      "\n",
      "Epoch 00359: val_accuracy did not improve from 0.90391\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2568 - accuracy: 0.9072 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9517 - recall_1: 0.9876 - precision_1: 0.8970 - val_loss: 0.3520 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.7558 - val_specificity_at_sensitivity_1: 0.7934 - val_recall_1: 0.9569 - val_precision_1: 0.9143\n",
      "\n",
      "Epoch 00360: val_accuracy did not improve from 0.90391\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2711 - accuracy: 0.8840 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9642 - recall_1: 0.9721 - precision_1: 0.8788 - val_loss: 0.3246 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8550 - val_specificity_at_sensitivity_1: 0.8594 - val_recall_1: 0.9523 - val_precision_1: 0.9149\n",
      "\n",
      "Epoch 00361: val_accuracy did not improve from 0.90391\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2669 - accuracy: 0.8887 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9689 - recall_1: 0.9721 - precision_1: 0.8878 - val_loss: 0.3305 - val_accuracy: 0.8695 - val_sensitivity_at_specificity_1: 0.8297 - val_specificity_at_sensitivity_1: 0.8435 - val_recall_1: 0.9726 - val_precision_1: 0.8901\n",
      "\n",
      "Epoch 00362: val_accuracy did not improve from 0.90391\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2555 - accuracy: 0.8994 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9644 - recall_1: 0.9725 - precision_1: 0.8986 - val_loss: 0.3296 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8131 - val_specificity_at_sensitivity_1: 0.8000 - val_recall_1: 0.9721 - val_precision_1: 0.9012\n",
      "\n",
      "Epoch 00363: val_accuracy did not improve from 0.90391\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2792 - accuracy: 0.8868 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9514 - recall_1: 0.9696 - precision_1: 0.8818 - val_loss: 0.3062 - val_accuracy: 0.8938 - val_sensitivity_at_specificity_1: 0.8407 - val_specificity_at_sensitivity_1: 0.8092 - val_recall_1: 0.9800 - val_precision_1: 0.9088\n",
      "\n",
      "Epoch 00364: val_accuracy did not improve from 0.90391\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2693 - accuracy: 0.8874 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9726 - recall_1: 0.9763 - precision_1: 0.8821 - val_loss: 0.3261 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8287 - val_specificity_at_sensitivity_1: 0.8231 - val_recall_1: 0.9591 - val_precision_1: 0.9093\n",
      "\n",
      "Epoch 00365: val_accuracy did not improve from 0.90391\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2297 - accuracy: 0.9146 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9813 - recall_1: 0.9788 - precision_1: 0.9105 - val_loss: 0.3359 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.8254 - val_specificity_at_sensitivity_1: 0.7857 - val_recall_1: 0.9693 - val_precision_1: 0.8984\n",
      "\n",
      "Epoch 00366: val_accuracy did not improve from 0.90391\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2563 - accuracy: 0.9045 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9543 - recall_1: 0.9761 - precision_1: 0.8996 - val_loss: 0.3376 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.8238 - val_specificity_at_sensitivity_1: 0.8966 - val_recall_1: 0.9753 - val_precision_1: 0.8920\n",
      "\n",
      "Epoch 00367: val_accuracy did not improve from 0.90391\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2607 - accuracy: 0.8942 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9725 - recall_1: 0.9711 - precision_1: 0.8955 - val_loss: 0.3256 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.8072 - val_specificity_at_sensitivity_1: 0.8507 - val_recall_1: 0.9616 - val_precision_1: 0.9040\n",
      "\n",
      "Epoch 00368: val_accuracy did not improve from 0.90391\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2488 - accuracy: 0.9041 - sensitivity_at_specificity_1: 0.9989 - specificity_at_sensitivity_1: 0.9750 - recall_1: 0.9803 - precision_1: 0.8991 - val_loss: 0.3386 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.8120 - val_specificity_at_sensitivity_1: 0.8413 - val_recall_1: 0.9515 - val_precision_1: 0.9127\n",
      "\n",
      "Epoch 00369: val_accuracy did not improve from 0.90391\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2685 - accuracy: 0.9030 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9532 - recall_1: 0.9802 - precision_1: 0.8949 - val_loss: 0.3369 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.8102 - val_specificity_at_sensitivity_1: 0.8310 - val_recall_1: 0.9833 - val_precision_1: 0.8945\n",
      "\n",
      "Epoch 00370: val_accuracy did not improve from 0.90391\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2590 - accuracy: 0.8971 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9684 - recall_1: 0.9764 - precision_1: 0.8935 - val_loss: 0.3377 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.8051 - val_specificity_at_sensitivity_1: 0.8014 - val_recall_1: 0.9903 - val_precision_1: 0.8906\n",
      "\n",
      "Epoch 00371: val_accuracy did not improve from 0.90391\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2463 - accuracy: 0.9014 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9727 - recall_1: 0.9872 - precision_1: 0.8910 - val_loss: 0.3359 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.8295 - val_specificity_at_sensitivity_1: 0.8514 - val_recall_1: 0.9761 - val_precision_1: 0.8926\n",
      "\n",
      "Epoch 00372: val_accuracy did not improve from 0.90391\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2446 - accuracy: 0.9089 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9613 - recall_1: 0.9777 - precision_1: 0.9059 - val_loss: 0.2996 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.8466 - val_specificity_at_sensitivity_1: 0.9209 - val_recall_1: 0.9842 - val_precision_1: 0.8955\n",
      "\n",
      "Epoch 00373: val_accuracy did not improve from 0.90391\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2541 - accuracy: 0.8997 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9710 - recall_1: 0.9824 - precision_1: 0.8891 - val_loss: 0.3194 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.8094 - val_specificity_at_sensitivity_1: 0.8309 - val_recall_1: 0.9747 - val_precision_1: 0.9028\n",
      "\n",
      "Epoch 00374: val_accuracy did not improve from 0.90391\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2403 - accuracy: 0.9021 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9743 - recall_1: 0.9738 - precision_1: 0.9001 - val_loss: 0.3259 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.8052 - val_specificity_at_sensitivity_1: 0.8296 - val_recall_1: 0.9782 - val_precision_1: 0.8989\n",
      "\n",
      "Epoch 00375: val_accuracy did not improve from 0.90391\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2459 - accuracy: 0.9013 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9626 - recall_1: 0.9745 - precision_1: 0.9004 - val_loss: 0.3291 - val_accuracy: 0.8680 - val_sensitivity_at_specificity_1: 0.8039 - val_specificity_at_sensitivity_1: 0.8478 - val_recall_1: 0.9632 - val_precision_1: 0.8965\n",
      "\n",
      "Epoch 00376: val_accuracy did not improve from 0.90391\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2532 - accuracy: 0.8992 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9757 - recall_1: 0.9822 - precision_1: 0.8920 - val_loss: 0.3645 - val_accuracy: 0.8586 - val_sensitivity_at_specificity_1: 0.8053 - val_specificity_at_sensitivity_1: 0.8276 - val_recall_1: 0.9507 - val_precision_1: 0.8962\n",
      "\n",
      "Epoch 00377: val_accuracy did not improve from 0.90391\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2550 - accuracy: 0.9009 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9678 - recall_1: 0.9706 - precision_1: 0.9011 - val_loss: 0.3423 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.8325 - val_specificity_at_sensitivity_1: 0.8143 - val_recall_1: 0.9728 - val_precision_1: 0.8958\n",
      "\n",
      "Epoch 00378: val_accuracy did not improve from 0.90391\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2323 - accuracy: 0.9157 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9698 - recall_1: 0.9820 - precision_1: 0.9098 - val_loss: 0.3238 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.8523 - val_specificity_at_sensitivity_1: 0.8676 - val_recall_1: 0.9659 - val_precision_1: 0.9006\n",
      "\n",
      "Epoch 00379: val_accuracy did not improve from 0.90391\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2546 - accuracy: 0.9030 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9677 - recall_1: 0.9787 - precision_1: 0.8989 - val_loss: 0.3225 - val_accuracy: 0.8891 - val_sensitivity_at_specificity_1: 0.7629 - val_specificity_at_sensitivity_1: 0.7883 - val_recall_1: 0.9860 - val_precision_1: 0.8994\n",
      "\n",
      "Epoch 00380: val_accuracy did not improve from 0.90391\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2780 - accuracy: 0.8940 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9468 - recall_1: 0.9793 - precision_1: 0.8867 - val_loss: 0.3328 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.7832 - val_specificity_at_sensitivity_1: 0.8603 - val_recall_1: 0.9650 - val_precision_1: 0.8998\n",
      "\n",
      "Epoch 00381: val_accuracy did not improve from 0.90391\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2417 - accuracy: 0.9090 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9703 - recall_1: 0.9782 - precision_1: 0.9028 - val_loss: 0.3507 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.8045 - val_specificity_at_sensitivity_1: 0.7597 - val_recall_1: 0.9531 - val_precision_1: 0.9134\n",
      "\n",
      "Epoch 00382: val_accuracy did not improve from 0.90391\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2629 - accuracy: 0.9022 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9408 - recall_1: 0.9771 - precision_1: 0.9010 - val_loss: 0.3297 - val_accuracy: 0.8758 - val_sensitivity_at_specificity_1: 0.7684 - val_specificity_at_sensitivity_1: 0.7953 - val_recall_1: 0.9627 - val_precision_1: 0.9054\n",
      "\n",
      "Epoch 00383: val_accuracy did not improve from 0.90391\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2214 - accuracy: 0.9241 - sensitivity_at_specificity_1: 0.9991 - specificity_at_sensitivity_1: 0.9612 - recall_1: 0.9847 - precision_1: 0.9221 - val_loss: 0.3367 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.7833 - val_specificity_at_sensitivity_1: 0.8015 - val_recall_1: 0.9600 - val_precision_1: 0.9026\n",
      "\n",
      "Epoch 00384: val_accuracy did not improve from 0.90391\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2764 - accuracy: 0.8866 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9704 - recall_1: 0.9843 - precision_1: 0.8753 - val_loss: 0.3393 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.8166 - val_specificity_at_sensitivity_1: 0.8593 - val_recall_1: 0.9590 - val_precision_1: 0.9067\n",
      "\n",
      "Epoch 00385: val_accuracy did not improve from 0.90391\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2583 - accuracy: 0.8996 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9545 - recall_1: 0.9772 - precision_1: 0.8954 - val_loss: 0.3919 - val_accuracy: 0.8469 - val_sensitivity_at_specificity_1: 0.7779 - val_specificity_at_sensitivity_1: 0.8298 - val_recall_1: 0.9298 - val_precision_1: 0.9013\n",
      "\n",
      "Epoch 00386: val_accuracy did not improve from 0.90391\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2738 - accuracy: 0.8869 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9536 - recall_1: 0.9560 - precision_1: 0.8945 - val_loss: 0.3295 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.8174 - val_specificity_at_sensitivity_1: 0.8308 - val_recall_1: 0.9696 - val_precision_1: 0.9058\n",
      "\n",
      "Epoch 00387: val_accuracy did not improve from 0.90391\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2538 - accuracy: 0.9044 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9539 - recall_1: 0.9817 - precision_1: 0.8991 - val_loss: 0.3211 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.8211 - val_specificity_at_sensitivity_1: 0.8507 - val_recall_1: 0.9721 - val_precision_1: 0.9006\n",
      "\n",
      "Epoch 00388: val_accuracy did not improve from 0.90391\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2335 - accuracy: 0.9075 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9719 - recall_1: 0.9709 - precision_1: 0.9088 - val_loss: 0.3571 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.8071 - val_specificity_at_sensitivity_1: 0.7733 - val_recall_1: 0.9850 - val_precision_1: 0.8854\n",
      "\n",
      "Epoch 00389: val_accuracy did not improve from 0.90391\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2511 - accuracy: 0.9028 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9707 - recall_1: 0.9905 - precision_1: 0.8929 - val_loss: 0.3228 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.8226 - val_specificity_at_sensitivity_1: 0.8529 - val_recall_1: 0.9808 - val_precision_1: 0.8998\n",
      "\n",
      "Epoch 00390: val_accuracy did not improve from 0.90391\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2536 - accuracy: 0.8989 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9576 - recall_1: 0.9817 - precision_1: 0.8900 - val_loss: 0.3411 - val_accuracy: 0.8703 - val_sensitivity_at_specificity_1: 0.8326 - val_specificity_at_sensitivity_1: 0.8345 - val_recall_1: 0.9632 - val_precision_1: 0.8986\n",
      "\n",
      "Epoch 00391: val_accuracy did not improve from 0.90391\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2573 - accuracy: 0.8985 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9700 - recall_1: 0.9745 - precision_1: 0.8962 - val_loss: 0.3216 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8354 - val_specificity_at_sensitivity_1: 0.8611 - val_recall_1: 0.9815 - val_precision_1: 0.8934\n",
      "\n",
      "Epoch 00392: val_accuracy did not improve from 0.90391\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2552 - accuracy: 0.9034 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9599 - recall_1: 0.9768 - precision_1: 0.8983 - val_loss: 0.3214 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8061 - val_specificity_at_sensitivity_1: 0.8154 - val_recall_1: 0.9696 - val_precision_1: 0.9036\n",
      "\n",
      "Epoch 00393: val_accuracy did not improve from 0.90391\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2374 - accuracy: 0.9024 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9722 - recall_1: 0.9709 - precision_1: 0.9029 - val_loss: 0.3321 - val_accuracy: 0.8758 - val_sensitivity_at_specificity_1: 0.8145 - val_specificity_at_sensitivity_1: 0.8102 - val_recall_1: 0.9676 - val_precision_1: 0.9007\n",
      "\n",
      "Epoch 00394: val_accuracy did not improve from 0.90391\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2446 - accuracy: 0.9063 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9656 - recall_1: 0.9801 - precision_1: 0.9008 - val_loss: 0.3234 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8135 - val_specificity_at_sensitivity_1: 0.8551 - val_recall_1: 0.9755 - val_precision_1: 0.8962\n",
      "\n",
      "Epoch 00395: val_accuracy did not improve from 0.90391\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2398 - accuracy: 0.9023 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9770 - recall_1: 0.9753 - precision_1: 0.9015 - val_loss: 0.3263 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.8287 - val_specificity_at_sensitivity_1: 0.8387 - val_recall_1: 0.9637 - val_precision_1: 0.9139\n",
      "\n",
      "Epoch 00396: val_accuracy did not improve from 0.90391\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2826 - accuracy: 0.8830 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9694 - recall_1: 0.9519 - precision_1: 0.8912 - val_loss: 0.3292 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8073 - val_specificity_at_sensitivity_1: 0.7656 - val_recall_1: 0.9696 - val_precision_1: 0.9067\n",
      "\n",
      "Epoch 00397: val_accuracy did not improve from 0.90391\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2588 - accuracy: 0.8958 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9669 - recall_1: 0.9770 - precision_1: 0.8911 - val_loss: 0.3363 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.7581 - val_specificity_at_sensitivity_1: 0.7786 - val_recall_1: 0.9652 - val_precision_1: 0.9068\n",
      "\n",
      "Epoch 00398: val_accuracy did not improve from 0.90391\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2471 - accuracy: 0.9018 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9759 - recall_1: 0.9711 - precision_1: 0.9035 - val_loss: 0.3025 - val_accuracy: 0.8922 - val_sensitivity_at_specificity_1: 0.7692 - val_specificity_at_sensitivity_1: 0.7886 - val_recall_1: 0.9793 - val_precision_1: 0.9086\n",
      "\n",
      "Epoch 00399: val_accuracy did not improve from 0.90391\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2242 - accuracy: 0.9103 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9804 - recall_1: 0.9842 - precision_1: 0.9016 - val_loss: 0.3499 - val_accuracy: 0.8781 - val_sensitivity_at_specificity_1: 0.8128 - val_specificity_at_sensitivity_1: 0.7817 - val_recall_1: 0.9728 - val_precision_1: 0.8985\n",
      "\n",
      "Epoch 00400: val_accuracy did not improve from 0.90391\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2325 - accuracy: 0.9121 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9839 - recall_1: 0.9787 - precision_1: 0.9104 - val_loss: 0.3193 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.7963 - val_specificity_at_sensitivity_1: 0.8767 - val_recall_1: 0.9938 - val_precision_1: 0.8909\n",
      "\n",
      "Epoch 00401: val_accuracy did not improve from 0.90391\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2579 - accuracy: 0.8980 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9626 - recall_1: 0.9799 - precision_1: 0.8929 - val_loss: 0.3100 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.8538 - val_specificity_at_sensitivity_1: 0.8626 - val_recall_1: 0.9634 - val_precision_1: 0.9096\n",
      "\n",
      "Epoch 00402: val_accuracy did not improve from 0.90391\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2612 - accuracy: 0.8972 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9653 - recall_1: 0.9713 - precision_1: 0.8973 - val_loss: 0.3170 - val_accuracy: 0.8875 - val_sensitivity_at_specificity_1: 0.8149 - val_specificity_at_sensitivity_1: 0.8643 - val_recall_1: 0.9921 - val_precision_1: 0.8934\n",
      "\n",
      "Epoch 00403: val_accuracy did not improve from 0.90391\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2675 - accuracy: 0.8897 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9623 - recall_1: 0.9738 - precision_1: 0.8853 - val_loss: 0.3412 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.7909 - val_specificity_at_sensitivity_1: 0.8029 - val_recall_1: 0.9799 - val_precision_1: 0.8982\n",
      "\n",
      "Epoch 00404: val_accuracy did not improve from 0.90391\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2611 - accuracy: 0.8934 - sensitivity_at_specificity_1: 0.9993 - specificity_at_sensitivity_1: 0.9723 - recall_1: 0.9755 - precision_1: 0.8904 - val_loss: 0.3165 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.8049 - val_specificity_at_sensitivity_1: 0.8409 - val_recall_1: 0.9774 - val_precision_1: 0.9027\n",
      "\n",
      "Epoch 00405: val_accuracy did not improve from 0.90391\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2689 - accuracy: 0.8955 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9713 - recall_1: 0.9702 - precision_1: 0.8918 - val_loss: 0.3337 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.8442 - val_specificity_at_sensitivity_1: 0.8533 - val_recall_1: 0.9823 - val_precision_1: 0.8894\n",
      "\n",
      "Epoch 00406: val_accuracy did not improve from 0.90391\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2355 - accuracy: 0.9138 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9677 - recall_1: 0.9821 - precision_1: 0.9090 - val_loss: 0.2953 - val_accuracy: 0.8953 - val_sensitivity_at_specificity_1: 0.8307 - val_specificity_at_sensitivity_1: 0.8594 - val_recall_1: 0.9852 - val_precision_1: 0.9065\n",
      "\n",
      "Epoch 00407: val_accuracy did not improve from 0.90391\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2449 - accuracy: 0.9019 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9627 - recall_1: 0.9788 - precision_1: 0.8997 - val_loss: 0.3199 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.8182 - val_specificity_at_sensitivity_1: 0.8750 - val_recall_1: 0.9808 - val_precision_1: 0.8998\n",
      "\n",
      "Epoch 00408: val_accuracy did not improve from 0.90391\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2501 - accuracy: 0.9052 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9626 - recall_1: 0.9837 - precision_1: 0.8986 - val_loss: 0.3724 - val_accuracy: 0.8609 - val_sensitivity_at_specificity_1: 0.7956 - val_specificity_at_sensitivity_1: 0.7852 - val_recall_1: 0.9424 - val_precision_1: 0.9060\n",
      "\n",
      "Epoch 00409: val_accuracy did not improve from 0.90391\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2551 - accuracy: 0.9032 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9651 - recall_1: 0.9745 - precision_1: 0.9043 - val_loss: 0.3352 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8142 - val_specificity_at_sensitivity_1: 0.7914 - val_recall_1: 0.9720 - val_precision_1: 0.8987\n",
      "\n",
      "Epoch 00410: val_accuracy did not improve from 0.90391\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2469 - accuracy: 0.9020 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9820 - recall_1: 0.9679 - precision_1: 0.9043 - val_loss: 0.3310 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.8313 - val_specificity_at_sensitivity_1: 0.8162 - val_recall_1: 0.9747 - val_precision_1: 0.8985\n",
      "\n",
      "Epoch 00411: val_accuracy did not improve from 0.90391\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2243 - accuracy: 0.9066 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9850 - recall_1: 0.9858 - precision_1: 0.8965 - val_loss: 0.3457 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.7953 - val_specificity_at_sensitivity_1: 0.8106 - val_recall_1: 0.9643 - val_precision_1: 0.9029\n",
      "\n",
      "Epoch 00412: val_accuracy did not improve from 0.90391\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2413 - accuracy: 0.9036 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9747 - recall_1: 0.9807 - precision_1: 0.8954 - val_loss: 0.3028 - val_accuracy: 0.8891 - val_sensitivity_at_specificity_1: 0.8335 - val_specificity_at_sensitivity_1: 0.8110 - val_recall_1: 0.9792 - val_precision_1: 0.9054\n",
      "\n",
      "Epoch 00413: val_accuracy did not improve from 0.90391\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2527 - accuracy: 0.9039 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9585 - recall_1: 0.9816 - precision_1: 0.8960 - val_loss: 0.3467 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.8227 - val_specificity_at_sensitivity_1: 0.8444 - val_recall_1: 0.9616 - val_precision_1: 0.9025\n",
      "\n",
      "Epoch 00414: val_accuracy did not improve from 0.90391\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2353 - accuracy: 0.9122 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9690 - recall_1: 0.9867 - precision_1: 0.9018 - val_loss: 0.3413 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.7797 - val_specificity_at_sensitivity_1: 0.7868 - val_recall_1: 0.9712 - val_precision_1: 0.8967\n",
      "\n",
      "Epoch 00415: val_accuracy did not improve from 0.90391\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2273 - accuracy: 0.9116 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9800 - recall_1: 0.9763 - precision_1: 0.9093 - val_loss: 0.3523 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_1: 0.8012 - val_specificity_at_sensitivity_1: 0.8043 - val_recall_1: 0.9606 - val_precision_1: 0.8992\n",
      "\n",
      "Epoch 00416: val_accuracy did not improve from 0.90391\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2429 - accuracy: 0.9041 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9702 - recall_1: 0.9741 - precision_1: 0.9023 - val_loss: 0.3076 - val_accuracy: 0.8891 - val_sensitivity_at_specificity_1: 0.8084 - val_specificity_at_sensitivity_1: 0.8485 - val_recall_1: 0.9826 - val_precision_1: 0.9024\n",
      "\n",
      "Epoch 00417: val_accuracy did not improve from 0.90391\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2481 - accuracy: 0.9008 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9765 - recall_1: 0.9754 - precision_1: 0.8996 - val_loss: 0.3563 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.7871 - val_specificity_at_sensitivity_1: 0.8041 - val_recall_1: 0.9832 - val_precision_1: 0.8876\n",
      "\n",
      "Epoch 00418: val_accuracy did not improve from 0.90391\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2432 - accuracy: 0.9002 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9682 - recall_1: 0.9819 - precision_1: 0.8925 - val_loss: 0.3060 - val_accuracy: 0.8945 - val_sensitivity_at_specificity_1: 0.8150 - val_specificity_at_sensitivity_1: 0.8582 - val_recall_1: 0.9930 - val_precision_1: 0.8996\n",
      "\n",
      "Epoch 00419: val_accuracy did not improve from 0.90391\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2505 - accuracy: 0.9029 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9664 - recall_1: 0.9832 - precision_1: 0.8964 - val_loss: 0.2980 - val_accuracy: 0.8961 - val_sensitivity_at_specificity_1: 0.8206 - val_specificity_at_sensitivity_1: 0.8413 - val_recall_1: 0.9887 - val_precision_1: 0.9048\n",
      "\n",
      "Epoch 00420: val_accuracy did not improve from 0.90391\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2522 - accuracy: 0.8965 - sensitivity_at_specificity_1: 0.9987 - specificity_at_sensitivity_1: 0.9709 - recall_1: 0.9852 - precision_1: 0.8848 - val_loss: 0.3417 - val_accuracy: 0.8703 - val_sensitivity_at_specificity_1: 0.7686 - val_specificity_at_sensitivity_1: 0.8148 - val_recall_1: 0.9607 - val_precision_1: 0.9009\n",
      "\n",
      "Epoch 00421: val_accuracy did not improve from 0.90391\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2454 - accuracy: 0.8968 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9767 - recall_1: 0.9638 - precision_1: 0.8981 - val_loss: 0.3706 - val_accuracy: 0.8539 - val_sensitivity_at_specificity_1: 0.7868 - val_specificity_at_sensitivity_1: 0.8168 - val_recall_1: 0.9295 - val_precision_1: 0.9097\n",
      "\n",
      "Epoch 00422: val_accuracy did not improve from 0.90391\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2579 - accuracy: 0.8969 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9734 - recall_1: 0.9596 - precision_1: 0.9031 - val_loss: 0.3602 - val_accuracy: 0.8578 - val_sensitivity_at_specificity_1: 0.8129 - val_specificity_at_sensitivity_1: 0.8355 - val_recall_1: 0.9583 - val_precision_1: 0.8890\n",
      "\n",
      "Epoch 00423: val_accuracy did not improve from 0.90391\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2400 - accuracy: 0.9038 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9630 - recall_1: 0.9648 - precision_1: 0.9118 - val_loss: 0.3477 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.7860 - val_specificity_at_sensitivity_1: 0.8357 - val_recall_1: 0.9719 - val_precision_1: 0.8964\n",
      "\n",
      "Epoch 00424: val_accuracy did not improve from 0.90391\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2387 - accuracy: 0.9026 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9754 - recall_1: 0.9812 - precision_1: 0.8942 - val_loss: 0.3141 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.8097 - val_specificity_at_sensitivity_1: 0.8065 - val_recall_1: 0.9801 - val_precision_1: 0.9042\n",
      "\n",
      "Epoch 00425: val_accuracy did not improve from 0.90391\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2301 - accuracy: 0.9073 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9757 - recall_1: 0.9826 - precision_1: 0.8984 - val_loss: 0.3421 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.8260 - val_specificity_at_sensitivity_1: 0.8446 - val_recall_1: 0.9761 - val_precision_1: 0.8911\n",
      "\n",
      "Epoch 00426: val_accuracy did not improve from 0.90391\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2925 - accuracy: 0.8783 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9552 - recall_1: 0.9627 - precision_1: 0.8797 - val_loss: 0.3343 - val_accuracy: 0.8781 - val_sensitivity_at_specificity_1: 0.7944 - val_specificity_at_sensitivity_1: 0.8102 - val_recall_1: 0.9711 - val_precision_1: 0.9002\n",
      "\n",
      "Epoch 00427: val_accuracy did not improve from 0.90391\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2579 - accuracy: 0.8962 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9733 - recall_1: 0.9722 - precision_1: 0.8908 - val_loss: 0.3128 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8056 - val_specificity_at_sensitivity_1: 0.8359 - val_recall_1: 0.9644 - val_precision_1: 0.9077\n",
      "\n",
      "Epoch 00428: val_accuracy did not improve from 0.90391\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2509 - accuracy: 0.8967 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9760 - recall_1: 0.9705 - precision_1: 0.8962 - val_loss: 0.3162 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.8210 - val_specificity_at_sensitivity_1: 0.8667 - val_recall_1: 0.9677 - val_precision_1: 0.9015\n",
      "\n",
      "Epoch 00429: val_accuracy did not improve from 0.90391\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2448 - accuracy: 0.8993 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9797 - recall_1: 0.9707 - precision_1: 0.9004 - val_loss: 0.3531 - val_accuracy: 0.8664 - val_sensitivity_at_specificity_1: 0.8373 - val_specificity_at_sensitivity_1: 0.8394 - val_recall_1: 0.9484 - val_precision_1: 0.9064\n",
      "\n",
      "Epoch 00430: val_accuracy did not improve from 0.90391\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2742 - accuracy: 0.8783 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9663 - recall_1: 0.9519 - precision_1: 0.8848 - val_loss: 0.3207 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.7677 - val_specificity_at_sensitivity_1: 0.8201 - val_recall_1: 0.9737 - val_precision_1: 0.9003\n",
      "\n",
      "Epoch 00431: val_accuracy did not improve from 0.90391\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2244 - accuracy: 0.9111 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9772 - recall_1: 0.9840 - precision_1: 0.9050 - val_loss: 0.3554 - val_accuracy: 0.8672 - val_sensitivity_at_specificity_1: 0.7947 - val_specificity_at_sensitivity_1: 0.8143 - val_recall_1: 0.9623 - val_precision_1: 0.8962\n",
      "\n",
      "Epoch 00432: val_accuracy did not improve from 0.90391\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2533 - accuracy: 0.9018 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9744 - recall_1: 0.9711 - precision_1: 0.9020 - val_loss: 0.3077 - val_accuracy: 0.8914 - val_sensitivity_at_specificity_1: 0.8307 - val_specificity_at_sensitivity_1: 0.8516 - val_recall_1: 0.9800 - val_precision_1: 0.9068\n",
      "\n",
      "Epoch 00433: val_accuracy did not improve from 0.90391\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2458 - accuracy: 0.9042 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9737 - recall_1: 0.9776 - precision_1: 0.8998 - val_loss: 0.3398 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.8049 - val_specificity_at_sensitivity_1: 0.8503 - val_recall_1: 0.9753 - val_precision_1: 0.8947\n",
      "\n",
      "Epoch 00434: val_accuracy did not improve from 0.90391\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2437 - accuracy: 0.9060 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9682 - recall_1: 0.9785 - precision_1: 0.9023 - val_loss: 0.3485 - val_accuracy: 0.8703 - val_sensitivity_at_specificity_1: 0.7749 - val_specificity_at_sensitivity_1: 0.7836 - val_recall_1: 0.9572 - val_precision_1: 0.9036\n",
      "\n",
      "Epoch 00435: val_accuracy did not improve from 0.90391\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2307 - accuracy: 0.9071 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9740 - recall_1: 0.9736 - precision_1: 0.9057 - val_loss: 0.3359 - val_accuracy: 0.8719 - val_sensitivity_at_specificity_1: 0.8186 - val_specificity_at_sensitivity_1: 0.8201 - val_recall_1: 0.9684 - val_precision_1: 0.8962\n",
      "\n",
      "Epoch 00436: val_accuracy did not improve from 0.90391\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2370 - accuracy: 0.9033 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9760 - recall_1: 0.9745 - precision_1: 0.8994 - val_loss: 0.3412 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8260 - val_specificity_at_sensitivity_1: 0.8521 - val_recall_1: 0.9763 - val_precision_1: 0.8974\n",
      "\n",
      "Epoch 00437: val_accuracy did not improve from 0.90391\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2413 - accuracy: 0.9006 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9744 - recall_1: 0.9728 - precision_1: 0.9012 - val_loss: 0.3249 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.8327 - val_specificity_at_sensitivity_1: 0.8333 - val_recall_1: 0.9868 - val_precision_1: 0.8954\n",
      "\n",
      "Epoch 00438: val_accuracy did not improve from 0.90391\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2250 - accuracy: 0.9090 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9816 - recall_1: 0.9750 - precision_1: 0.9071 - val_loss: 0.3252 - val_accuracy: 0.8891 - val_sensitivity_at_specificity_1: 0.8096 - val_specificity_at_sensitivity_1: 0.8000 - val_recall_1: 0.9895 - val_precision_1: 0.8967\n",
      "\n",
      "Epoch 00439: val_accuracy did not improve from 0.90391\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2219 - accuracy: 0.9103 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9846 - recall_1: 0.9806 - precision_1: 0.9063 - val_loss: 0.3335 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.7962 - val_specificity_at_sensitivity_1: 0.7727 - val_recall_1: 0.9843 - val_precision_1: 0.8990\n",
      "\n",
      "Epoch 00440: val_accuracy did not improve from 0.90391\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2485 - accuracy: 0.9053 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9722 - recall_1: 0.9814 - precision_1: 0.8980 - val_loss: 0.3560 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.7654 - val_specificity_at_sensitivity_1: 0.7394 - val_recall_1: 0.9745 - val_precision_1: 0.8936\n",
      "\n",
      "Epoch 00441: val_accuracy did not improve from 0.90391\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2224 - accuracy: 0.9081 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9846 - recall_1: 0.9789 - precision_1: 0.9024 - val_loss: 0.3437 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.7944 - val_specificity_at_sensitivity_1: 0.8467 - val_recall_1: 0.9685 - val_precision_1: 0.8993\n",
      "\n",
      "Epoch 00442: val_accuracy did not improve from 0.90391\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2389 - accuracy: 0.9046 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9773 - recall_1: 0.9762 - precision_1: 0.9008 - val_loss: 0.3138 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.8024 - val_specificity_at_sensitivity_1: 0.8175 - val_recall_1: 0.9723 - val_precision_1: 0.9078\n",
      "\n",
      "Epoch 00443: val_accuracy did not improve from 0.90391\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2147 - accuracy: 0.9190 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9858 - recall_1: 0.9874 - precision_1: 0.9100 - val_loss: 0.3145 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.8380 - val_specificity_at_sensitivity_1: 0.8768 - val_recall_1: 0.9729 - val_precision_1: 0.9011\n",
      "\n",
      "Epoch 00444: val_accuracy did not improve from 0.90391\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2467 - accuracy: 0.8946 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9760 - recall_1: 0.9733 - precision_1: 0.8924 - val_loss: 0.3593 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.8067 - val_specificity_at_sensitivity_1: 0.8158 - val_recall_1: 0.9823 - val_precision_1: 0.8871\n",
      "\n",
      "Epoch 00445: val_accuracy did not improve from 0.90391\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2344 - accuracy: 0.8990 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9780 - recall_1: 0.9706 - precision_1: 0.9011 - val_loss: 0.3254 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.7743 - val_specificity_at_sensitivity_1: 0.8438 - val_recall_1: 0.9731 - val_precision_1: 0.9070\n",
      "\n",
      "Epoch 00446: val_accuracy did not improve from 0.90391\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2387 - accuracy: 0.9066 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9686 - recall_1: 0.9751 - precision_1: 0.9060 - val_loss: 0.3256 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8453 - val_specificity_at_sensitivity_1: 0.8015 - val_recall_1: 0.9720 - val_precision_1: 0.8989\n",
      "\n",
      "Epoch 00447: val_accuracy did not improve from 0.90391\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2141 - accuracy: 0.9186 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9838 - recall_1: 0.9782 - precision_1: 0.9165 - val_loss: 0.3521 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.8235 - val_specificity_at_sensitivity_1: 0.8571 - val_recall_1: 0.9700 - val_precision_1: 0.8950\n",
      "\n",
      "Epoch 00448: val_accuracy did not improve from 0.90391\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2355 - accuracy: 0.9084 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9636 - recall_1: 0.9741 - precision_1: 0.9068 - val_loss: 0.3386 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.7817 - val_specificity_at_sensitivity_1: 0.8194 - val_recall_1: 0.9762 - val_precision_1: 0.8908\n",
      "\n",
      "Epoch 00449: val_accuracy did not improve from 0.90391\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2296 - accuracy: 0.9138 - sensitivity_at_specificity_1: 0.9992 - specificity_at_sensitivity_1: 0.9736 - recall_1: 0.9809 - precision_1: 0.9076 - val_loss: 0.3640 - val_accuracy: 0.8617 - val_sensitivity_at_specificity_1: 0.8115 - val_specificity_at_sensitivity_1: 0.8207 - val_recall_1: 0.9515 - val_precision_1: 0.8985\n",
      "\n",
      "Epoch 00450: val_accuracy did not improve from 0.90391\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2587 - accuracy: 0.8930 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9780 - recall_1: 0.9710 - precision_1: 0.8933 - val_loss: 0.3224 - val_accuracy: 0.8891 - val_sensitivity_at_specificity_1: 0.8304 - val_specificity_at_sensitivity_1: 0.8099 - val_recall_1: 0.9895 - val_precision_1: 0.8965\n",
      "\n",
      "Epoch 00451: val_accuracy did not improve from 0.90391\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2522 - accuracy: 0.8995 - sensitivity_at_specificity_1: 0.9993 - specificity_at_sensitivity_1: 0.9818 - recall_1: 0.9783 - precision_1: 0.8932 - val_loss: 0.3155 - val_accuracy: 0.8867 - val_sensitivity_at_specificity_1: 0.8172 - val_specificity_at_sensitivity_1: 0.8779 - val_recall_1: 0.9774 - val_precision_1: 0.9042\n",
      "\n",
      "Epoch 00452: val_accuracy did not improve from 0.90391\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2440 - accuracy: 0.9019 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9788 - recall_1: 0.9685 - precision_1: 0.9003 - val_loss: 0.3531 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_1: 0.8106 - val_specificity_at_sensitivity_1: 0.8067 - val_recall_1: 0.9646 - val_precision_1: 0.8891\n",
      "\n",
      "Epoch 00453: val_accuracy did not improve from 0.90391\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2322 - accuracy: 0.9051 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9881 - recall_1: 0.9716 - precision_1: 0.9043 - val_loss: 0.3269 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8156 - val_specificity_at_sensitivity_1: 0.8529 - val_recall_1: 0.9650 - val_precision_1: 0.9042\n",
      "\n",
      "Epoch 00454: val_accuracy did not improve from 0.90391\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2287 - accuracy: 0.9121 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9794 - recall_1: 0.9732 - precision_1: 0.9136 - val_loss: 0.3325 - val_accuracy: 0.8727 - val_sensitivity_at_specificity_1: 0.8002 - val_specificity_at_sensitivity_1: 0.8561 - val_recall_1: 0.9711 - val_precision_1: 0.8950\n",
      "\n",
      "Epoch 00455: val_accuracy did not improve from 0.90391\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2070 - accuracy: 0.9166 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9874 - recall_1: 0.9776 - precision_1: 0.9169 - val_loss: 0.3426 - val_accuracy: 0.8734 - val_sensitivity_at_specificity_1: 0.8083 - val_specificity_at_sensitivity_1: 0.8252 - val_recall_1: 0.9613 - val_precision_1: 0.9026\n",
      "\n",
      "Epoch 00456: val_accuracy did not improve from 0.90391\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2371 - accuracy: 0.8965 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9818 - recall_1: 0.9677 - precision_1: 0.8984 - val_loss: 0.3327 - val_accuracy: 0.8844 - val_sensitivity_at_specificity_1: 0.8339 - val_specificity_at_sensitivity_1: 0.8015 - val_recall_1: 0.9790 - val_precision_1: 0.9003\n",
      "\n",
      "Epoch 00457: val_accuracy did not improve from 0.90391\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2559 - accuracy: 0.8970 - sensitivity_at_specificity_1: 0.9988 - specificity_at_sensitivity_1: 0.9778 - recall_1: 0.9793 - precision_1: 0.8913 - val_loss: 0.3464 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.7594 - val_specificity_at_sensitivity_1: 0.7589 - val_recall_1: 0.9895 - val_precision_1: 0.8937\n",
      "\n",
      "Epoch 00458: val_accuracy did not improve from 0.90391\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2481 - accuracy: 0.8973 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9779 - recall_1: 0.9670 - precision_1: 0.8985 - val_loss: 0.3348 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.7895 - val_specificity_at_sensitivity_1: 0.8519 - val_recall_1: 0.9843 - val_precision_1: 0.8959\n",
      "\n",
      "Epoch 00459: val_accuracy did not improve from 0.90391\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2234 - accuracy: 0.9176 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9698 - recall_1: 0.9850 - precision_1: 0.9108 - val_loss: 0.3411 - val_accuracy: 0.8781 - val_sensitivity_at_specificity_1: 0.7895 - val_specificity_at_sensitivity_1: 0.8071 - val_recall_1: 0.9789 - val_precision_1: 0.8942\n",
      "\n",
      "Epoch 00460: val_accuracy did not improve from 0.90391\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2046 - accuracy: 0.9136 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9883 - recall_1: 0.9783 - precision_1: 0.9095 - val_loss: 0.3377 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.7727 - val_specificity_at_sensitivity_1: 0.8382 - val_recall_1: 0.9668 - val_precision_1: 0.9043\n",
      "\n",
      "Epoch 00461: val_accuracy did not improve from 0.90391\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2377 - accuracy: 0.9086 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9676 - recall_1: 0.9768 - precision_1: 0.9055 - val_loss: 0.3673 - val_accuracy: 0.8641 - val_sensitivity_at_specificity_1: 0.8231 - val_specificity_at_sensitivity_1: 0.8043 - val_recall_1: 0.9466 - val_precision_1: 0.9054\n",
      "\n",
      "Epoch 00462: val_accuracy did not improve from 0.90391\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2293 - accuracy: 0.9148 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9752 - recall_1: 0.9721 - precision_1: 0.9172 - val_loss: 0.3596 - val_accuracy: 0.8625 - val_sensitivity_at_specificity_1: 0.8160 - val_specificity_at_sensitivity_1: 0.8705 - val_recall_1: 0.9474 - val_precision_1: 0.9031\n",
      "\n",
      "Epoch 00463: val_accuracy did not improve from 0.90391\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2264 - accuracy: 0.9137 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9819 - recall_1: 0.9734 - precision_1: 0.9153 - val_loss: 0.3348 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.8109 - val_specificity_at_sensitivity_1: 0.8333 - val_recall_1: 0.9667 - val_precision_1: 0.8968\n",
      "\n",
      "Epoch 00464: val_accuracy did not improve from 0.90391\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2428 - accuracy: 0.8967 - sensitivity_at_specificity_1: 0.9972 - specificity_at_sensitivity_1: 0.9860 - recall_1: 0.9724 - precision_1: 0.8955 - val_loss: 0.3386 - val_accuracy: 0.8742 - val_sensitivity_at_specificity_1: 0.7961 - val_specificity_at_sensitivity_1: 0.8592 - val_recall_1: 0.9754 - val_precision_1: 0.8930\n",
      "\n",
      "Epoch 00465: val_accuracy did not improve from 0.90391\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2530 - accuracy: 0.9034 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9581 - recall_1: 0.9763 - precision_1: 0.8990 - val_loss: 0.3212 - val_accuracy: 0.8883 - val_sensitivity_at_specificity_1: 0.8050 - val_specificity_at_sensitivity_1: 0.8321 - val_recall_1: 0.9869 - val_precision_1: 0.8986\n",
      "\n",
      "Epoch 00466: val_accuracy did not improve from 0.90391\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2349 - accuracy: 0.9095 - sensitivity_at_specificity_1: 0.9997 - specificity_at_sensitivity_1: 0.9790 - recall_1: 0.9778 - precision_1: 0.9070 - val_loss: 0.3648 - val_accuracy: 0.8672 - val_sensitivity_at_specificity_1: 0.7557 - val_specificity_at_sensitivity_1: 0.8239 - val_recall_1: 0.9631 - val_precision_1: 0.8954\n",
      "\n",
      "Epoch 00467: val_accuracy did not improve from 0.90391\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2404 - accuracy: 0.9065 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9735 - recall_1: 0.9708 - precision_1: 0.9068 - val_loss: 0.3601 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.7701 - val_specificity_at_sensitivity_1: 0.8309 - val_recall_1: 0.9598 - val_precision_1: 0.9022\n",
      "\n",
      "Epoch 00468: val_accuracy did not improve from 0.90391\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2211 - accuracy: 0.9073 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9865 - recall_1: 0.9711 - precision_1: 0.9082 - val_loss: 0.3370 - val_accuracy: 0.8758 - val_sensitivity_at_specificity_1: 0.8070 - val_specificity_at_sensitivity_1: 0.8444 - val_recall_1: 0.9616 - val_precision_1: 0.9054\n",
      "\n",
      "Epoch 00469: val_accuracy did not improve from 0.90391\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2392 - accuracy: 0.9061 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9792 - recall_1: 0.9703 - precision_1: 0.9065 - val_loss: 0.3531 - val_accuracy: 0.8695 - val_sensitivity_at_specificity_1: 0.7821 - val_specificity_at_sensitivity_1: 0.8451 - val_recall_1: 0.9666 - val_precision_1: 0.8950\n",
      "\n",
      "Epoch 00470: val_accuracy did not improve from 0.90391\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2241 - accuracy: 0.9085 - sensitivity_at_specificity_1: 0.9990 - specificity_at_sensitivity_1: 0.9861 - recall_1: 0.9717 - precision_1: 0.9101 - val_loss: 0.3703 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.7988 - val_specificity_at_sensitivity_1: 0.8089 - val_recall_1: 0.9795 - val_precision_1: 0.8857\n",
      "\n",
      "Epoch 00471: val_accuracy did not improve from 0.90391\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2227 - accuracy: 0.9099 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9847 - recall_1: 0.9821 - precision_1: 0.9046 - val_loss: 0.3450 - val_accuracy: 0.8664 - val_sensitivity_at_specificity_1: 0.8156 - val_specificity_at_sensitivity_1: 0.8162 - val_recall_1: 0.9519 - val_precision_1: 0.9037\n",
      "\n",
      "Epoch 00472: val_accuracy did not improve from 0.90391\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2202 - accuracy: 0.9153 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9890 - recall_1: 0.9779 - precision_1: 0.9123 - val_loss: 0.3389 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.7647 - val_specificity_at_sensitivity_1: 0.8321 - val_recall_1: 0.9764 - val_precision_1: 0.8971\n",
      "\n",
      "Epoch 00473: val_accuracy did not improve from 0.90391\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2202 - accuracy: 0.9127 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9740 - recall_1: 0.9796 - precision_1: 0.9112 - val_loss: 0.3131 - val_accuracy: 0.8906 - val_sensitivity_at_specificity_1: 0.7934 - val_specificity_at_sensitivity_1: 0.8438 - val_recall_1: 0.9809 - val_precision_1: 0.9054\n",
      "\n",
      "Epoch 00474: val_accuracy did not improve from 0.90391\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2213 - accuracy: 0.9036 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9895 - recall_1: 0.9755 - precision_1: 0.8989 - val_loss: 0.3409 - val_accuracy: 0.8844 - val_sensitivity_at_specificity_1: 0.8074 - val_specificity_at_sensitivity_1: 0.7899 - val_recall_1: 0.9842 - val_precision_1: 0.8963\n",
      "\n",
      "Epoch 00475: val_accuracy did not improve from 0.90391\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2159 - accuracy: 0.9164 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9823 - recall_1: 0.9812 - precision_1: 0.9117 - val_loss: 0.3134 - val_accuracy: 0.8898 - val_sensitivity_at_specificity_1: 0.7728 - val_specificity_at_sensitivity_1: 0.8268 - val_recall_1: 0.9827 - val_precision_1: 0.9035\n",
      "\n",
      "Epoch 00476: val_accuracy did not improve from 0.90391\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2124 - accuracy: 0.9100 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9851 - recall_1: 0.9773 - precision_1: 0.9085 - val_loss: 0.3455 - val_accuracy: 0.8680 - val_sensitivity_at_specificity_1: 0.8154 - val_specificity_at_sensitivity_1: 0.8321 - val_recall_1: 0.9571 - val_precision_1: 0.9012\n",
      "\n",
      "Epoch 00477: val_accuracy did not improve from 0.90391\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2282 - accuracy: 0.9148 - sensitivity_at_specificity_1: 0.9994 - specificity_at_sensitivity_1: 0.9861 - recall_1: 0.9677 - precision_1: 0.9198 - val_loss: 0.3752 - val_accuracy: 0.8602 - val_sensitivity_at_specificity_1: 0.7415 - val_specificity_at_sensitivity_1: 0.7638 - val_recall_1: 0.9324 - val_precision_1: 0.9141\n",
      "\n",
      "Epoch 00478: val_accuracy did not improve from 0.90391\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2370 - accuracy: 0.9050 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9739 - recall_1: 0.9511 - precision_1: 0.9184 - val_loss: 0.3605 - val_accuracy: 0.8687 - val_sensitivity_at_specificity_1: 0.7544 - val_specificity_at_sensitivity_1: 0.8088 - val_recall_1: 0.9607 - val_precision_1: 0.8993\n",
      "\n",
      "Epoch 00479: val_accuracy did not improve from 0.90391\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2161 - accuracy: 0.9101 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9880 - recall_1: 0.9731 - precision_1: 0.9115 - val_loss: 0.3498 - val_accuracy: 0.8820 - val_sensitivity_at_specificity_1: 0.7721 - val_specificity_at_sensitivity_1: 0.8129 - val_recall_1: 0.9772 - val_precision_1: 0.8992\n",
      "\n",
      "Epoch 00480: val_accuracy did not improve from 0.90391\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2181 - accuracy: 0.9175 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9808 - recall_1: 0.9834 - precision_1: 0.9121 - val_loss: 0.3567 - val_accuracy: 0.8664 - val_sensitivity_at_specificity_1: 0.8187 - val_specificity_at_sensitivity_1: 0.8261 - val_recall_1: 0.9545 - val_precision_1: 0.9016\n",
      "\n",
      "Epoch 00481: val_accuracy did not improve from 0.90391\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2147 - accuracy: 0.9080 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9904 - recall_1: 0.9716 - precision_1: 0.9062 - val_loss: 0.3326 - val_accuracy: 0.8766 - val_sensitivity_at_specificity_1: 0.8049 - val_specificity_at_sensitivity_1: 0.8367 - val_recall_1: 0.9815 - val_precision_1: 0.8903\n",
      "\n",
      "Epoch 00482: val_accuracy did not improve from 0.90391\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2163 - accuracy: 0.9172 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9678 - recall_1: 0.9825 - precision_1: 0.9127 - val_loss: 0.3592 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.7891 - val_specificity_at_sensitivity_1: 0.7958 - val_recall_1: 0.9745 - val_precision_1: 0.8965\n",
      "\n",
      "Epoch 00483: val_accuracy did not improve from 0.90391\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2330 - accuracy: 0.9057 - sensitivity_at_specificity_1: 0.9984 - specificity_at_sensitivity_1: 0.9884 - recall_1: 0.9711 - precision_1: 0.9043 - val_loss: 0.3665 - val_accuracy: 0.8641 - val_sensitivity_at_specificity_1: 0.7683 - val_specificity_at_sensitivity_1: 0.7919 - val_recall_1: 0.9655 - val_precision_1: 0.8900\n",
      "\n",
      "Epoch 00484: val_accuracy did not improve from 0.90391\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2151 - accuracy: 0.9188 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9703 - recall_1: 0.9819 - precision_1: 0.9136 - val_loss: 0.3425 - val_accuracy: 0.8773 - val_sensitivity_at_specificity_1: 0.8212 - val_specificity_at_sensitivity_1: 0.8489 - val_recall_1: 0.9658 - val_precision_1: 0.9033\n",
      "\n",
      "Epoch 00485: val_accuracy did not improve from 0.90391\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2012 - accuracy: 0.9189 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9908 - recall_1: 0.9768 - precision_1: 0.9187 - val_loss: 0.3772 - val_accuracy: 0.8750 - val_sensitivity_at_specificity_1: 0.7762 - val_specificity_at_sensitivity_1: 0.7931 - val_recall_1: 0.9762 - val_precision_1: 0.8928\n",
      "\n",
      "Epoch 00486: val_accuracy did not improve from 0.90391\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2195 - accuracy: 0.9161 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9783 - recall_1: 0.9826 - precision_1: 0.9111 - val_loss: 0.3381 - val_accuracy: 0.8797 - val_sensitivity_at_specificity_1: 0.8246 - val_specificity_at_sensitivity_1: 0.8000 - val_recall_1: 0.9623 - val_precision_1: 0.9081\n",
      "\n",
      "Epoch 00487: val_accuracy did not improve from 0.90391\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2009 - accuracy: 0.9196 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9855 - recall_1: 0.9752 - precision_1: 0.9218 - val_loss: 0.3315 - val_accuracy: 0.8859 - val_sensitivity_at_specificity_1: 0.8257 - val_specificity_at_sensitivity_1: 0.8261 - val_recall_1: 0.9781 - val_precision_1: 0.9023\n",
      "\n",
      "Epoch 00488: val_accuracy did not improve from 0.90391\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2168 - accuracy: 0.9077 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9853 - recall_1: 0.9735 - precision_1: 0.9055 - val_loss: 0.3389 - val_accuracy: 0.8852 - val_sensitivity_at_specificity_1: 0.7880 - val_specificity_at_sensitivity_1: 0.8062 - val_recall_1: 0.9713 - val_precision_1: 0.9075\n",
      "\n",
      "Epoch 00489: val_accuracy did not improve from 0.90391\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2197 - accuracy: 0.9088 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9739 - recall_1: 0.9711 - precision_1: 0.9102 - val_loss: 0.3439 - val_accuracy: 0.8711 - val_sensitivity_at_specificity_1: 0.8072 - val_specificity_at_sensitivity_1: 0.8561 - val_recall_1: 0.9571 - val_precision_1: 0.9040\n",
      "\n",
      "Epoch 00490: val_accuracy did not improve from 0.90391\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2140 - accuracy: 0.9198 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9788 - recall_1: 0.9799 - precision_1: 0.9174 - val_loss: 0.3460 - val_accuracy: 0.8805 - val_sensitivity_at_specificity_1: 0.7647 - val_specificity_at_sensitivity_1: 0.7583 - val_recall_1: 0.9569 - val_precision_1: 0.9151\n",
      "\n",
      "Epoch 00491: val_accuracy did not improve from 0.90391\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2229 - accuracy: 0.9096 - sensitivity_at_specificity_1: 0.9995 - specificity_at_sensitivity_1: 0.9818 - recall_1: 0.9703 - precision_1: 0.9089 - val_loss: 0.3361 - val_accuracy: 0.8828 - val_sensitivity_at_specificity_1: 0.8021 - val_specificity_at_sensitivity_1: 0.8188 - val_recall_1: 0.9799 - val_precision_1: 0.8981\n",
      "\n",
      "Epoch 00492: val_accuracy did not improve from 0.90391\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1994 - accuracy: 0.9257 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9864 - recall_1: 0.9826 - precision_1: 0.9211 - val_loss: 0.3247 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.8210 - val_specificity_at_sensitivity_1: 0.8217 - val_recall_1: 0.9652 - val_precision_1: 0.9084\n",
      "\n",
      "Epoch 00493: val_accuracy did not improve from 0.90391\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2010 - accuracy: 0.9196 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9894 - recall_1: 0.9717 - precision_1: 0.9231 - val_loss: 0.3623 - val_accuracy: 0.8813 - val_sensitivity_at_specificity_1: 0.7986 - val_specificity_at_sensitivity_1: 0.7899 - val_recall_1: 0.9781 - val_precision_1: 0.8979\n",
      "\n",
      "Epoch 00494: val_accuracy did not improve from 0.90391\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2094 - accuracy: 0.9097 - sensitivity_at_specificity_1: 0.9998 - specificity_at_sensitivity_1: 0.9876 - recall_1: 0.9780 - precision_1: 0.9065 - val_loss: 0.3444 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.8115 - val_specificity_at_sensitivity_1: 0.8358 - val_recall_1: 0.9773 - val_precision_1: 0.9010\n",
      "\n",
      "Epoch 00495: val_accuracy did not improve from 0.90391\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2153 - accuracy: 0.9196 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9838 - recall_1: 0.9787 - precision_1: 0.9154 - val_loss: 0.3477 - val_accuracy: 0.8789 - val_sensitivity_at_specificity_1: 0.8075 - val_specificity_at_sensitivity_1: 0.7727 - val_recall_1: 0.9686 - val_precision_1: 0.9033\n",
      "\n",
      "Epoch 00496: val_accuracy did not improve from 0.90391\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2183 - accuracy: 0.9104 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9875 - recall_1: 0.9751 - precision_1: 0.9108 - val_loss: 0.3393 - val_accuracy: 0.8844 - val_sensitivity_at_specificity_1: 0.8147 - val_specificity_at_sensitivity_1: 0.7647 - val_recall_1: 0.9738 - val_precision_1: 0.9042\n",
      "\n",
      "Epoch 00497: val_accuracy did not improve from 0.90391\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2141 - accuracy: 0.9105 - sensitivity_at_specificity_1: 0.9999 - specificity_at_sensitivity_1: 0.9912 - recall_1: 0.9720 - precision_1: 0.9099 - val_loss: 0.3320 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.8016 - val_specificity_at_sensitivity_1: 0.8095 - val_recall_1: 0.9567 - val_precision_1: 0.9177\n",
      "\n",
      "Epoch 00498: val_accuracy did not improve from 0.90391\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2038 - accuracy: 0.9257 - sensitivity_at_specificity_1: 1.0000 - specificity_at_sensitivity_1: 0.9861 - recall_1: 0.9701 - precision_1: 0.9355 - val_loss: 0.3844 - val_accuracy: 0.8719 - val_sensitivity_at_specificity_1: 0.7553 - val_specificity_at_sensitivity_1: 0.7071 - val_recall_1: 0.9658 - val_precision_1: 0.8980\n",
      "\n",
      "Epoch 00499: val_accuracy did not improve from 0.90391\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2306 - accuracy: 0.9072 - sensitivity_at_specificity_1: 0.9996 - specificity_at_sensitivity_1: 0.9797 - recall_1: 0.9719 - precision_1: 0.9067 - val_loss: 0.3352 - val_accuracy: 0.8836 - val_sensitivity_at_specificity_1: 0.8043 - val_specificity_at_sensitivity_1: 0.7846 - val_recall_1: 0.9687 - val_precision_1: 0.9079\n",
      "\n",
      "Epoch 00500: val_accuracy did not improve from 0.90391\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"ECG_Spectrogram_Model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=10,  \n",
    "      epochs=500,\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=5, \n",
    "      callbacks = [callbacks,checkpoint]\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziBnKWqmBU4q"
   },
   "source": [
    "**Performance Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCdS_0U65A0-",
    "outputId": "9c98cd44-cb57-4102-d99f-d0157487053a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Training_Accuracy\u001b[38;5;241m=\u001b[39m\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m Validation_Accuracy\u001b[38;5;241m=\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m Validation_Specificity\u001b[38;5;241m=\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_specificity_at_sensitivity\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "Training_Accuracy=history.history['accuracy']\n",
    "Validation_Accuracy=history.history['val_accuracy']\n",
    "Validation_Specificity=history.history['val_specificity_at_sensitivity']\n",
    "Validation_Sensitivity=history.history['val_sensitivity_at_specificity']\n",
    "Validation_Recall=history.history['val_recall']\n",
    "Validation_Precision=history.history['val_precision']\n",
    "Validation_Loss=history.history['val_loss']\n",
    "\n",
    "print(\"Training Accuracy: \",max(Training_Accuracy))\n",
    "print(\"Validation Accuracy: \",max(Validation_Accuracy))\n",
    "print(\"Validation Specificity: \",max(Validation_Specificity))\n",
    "print(\"Validation Sensitivity: \",max(Validation_Sensitivity))\n",
    "print(\"Validation Recall: \",max(Validation_Recall))\n",
    "print(\"Validation Precision: \",max(Validation_Precision))\n",
    "print(\"Validation Loss: \",min(Validation_Loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gn0ZuIN3BX5q"
   },
   "source": [
    "**Accuracy Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "kLqjG2X-vdLj",
    "outputId": "829b53c7-259a-4505-9536-19736a31212c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSHo3r2SBZr3"
   },
   "source": [
    "**Loss Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "SBSAyVfivvHX",
    "outputId": "235e7648-464f-4e22-ea07-e7f477356a1a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7e88OLey6Bgd"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
